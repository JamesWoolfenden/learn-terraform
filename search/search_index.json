{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Learn Terraform By James Woolfenden What is Terraform Terraform is a language and tool for creating infrastructure via a technique called Infrastructure as Code. This is an example of an AWS instance, know as a resource, called \"web\" described in Terraform with 4 properties set: resource \"aws_instance\" \"web\" { ami = data . aws_ami . xenial . id instance_type = \"t2.micro\" tags = var . common_tags key_name = aws_key_pair . ssh . key_name } What it means The first line starts with Resource , this declares the type of object, in this case a resource, alternatives include module, data or variable. \"aws_instance\" is the type of resource, in this case an instance or EC2 Virtual Machine. \"web\" this is just the object name, the name is up to you. The brackets are a fairly typical declaration of an object, the opening must be on the first line. ami = data.aws_ami.xenial.id The property ami is set to data.aws_ami.xenial.id , data means its a data resource, of type aws_ami that's been called xenial and supply the property id . instance_type=\"t2.micro\" The property instance_type has been hard-coded to the string value. tags = var.common_tags The tags property has been set to var.common_tags , which is a declared variable called common_tags. Then when Terraform is run, it will check and create the resource if it's not existing already. If it's different, it will fix the drift in the object to make it as the specification. The tool The Terraform tool is written in Go-lang, and available for many platforms as a single executable binary, you can find the source hosted on Github here: Terraform , it is being actively developed and there are very regular updates to its core changelog and to it's providers : AWS and it's changelog or GCP and its changelog Current Terraform This site focuses on how to use the free edition and features of the Open source tool and Terraform Cloud. Unless called out, all AWS infrastructure will be provisioned in just one AWS region. Rationale Terraform is a second generation DevOps tool, it is designed to help you provision infrastructure. Templates are designed in Hashicorp Configuration Language (HCL) to describe how your infrastructure should be, and can be used to create and model your infrastructure, as well as being part of your Configuration Management Tool-chain. Alternatives In no particular order: Puppet and Chef These are the old guard or the v1.0 CM Tools, lots of agents and lots of set-up. Ansible No Servers and No Agents. A very useful tool for configuration and in combination with Packer and Terraform. CloudFoundry Salt Stack More popular the otherside of the Atlantic, very rare in London/SE. Cloudformation Popular with some AWS Consultants. Pulumi If you want to code your infrastructure in a language you already know, this is for you, with support for Python and JS. Great for small teams with no specialised infra experience and if you can't get your head around the declarative approach of Terraform, this ones for you. Your own scripts Probably won't makes sense to even you six months later, god forbid you have use someone elses or they yours. The Console Well that's not DevOps is it.","title":"Home"},{"location":"#learn-terraform","text":"By James Woolfenden","title":"Learn Terraform"},{"location":"#what-is-terraform","text":"Terraform is a language and tool for creating infrastructure via a technique called Infrastructure as Code. This is an example of an AWS instance, know as a resource, called \"web\" described in Terraform with 4 properties set: resource \"aws_instance\" \"web\" { ami = data . aws_ami . xenial . id instance_type = \"t2.micro\" tags = var . common_tags key_name = aws_key_pair . ssh . key_name }","title":"What is Terraform"},{"location":"#what-it-means","text":"The first line starts with Resource , this declares the type of object, in this case a resource, alternatives include module, data or variable. \"aws_instance\" is the type of resource, in this case an instance or EC2 Virtual Machine. \"web\" this is just the object name, the name is up to you. The brackets are a fairly typical declaration of an object, the opening must be on the first line. ami = data.aws_ami.xenial.id The property ami is set to data.aws_ami.xenial.id , data means its a data resource, of type aws_ami that's been called xenial and supply the property id . instance_type=\"t2.micro\" The property instance_type has been hard-coded to the string value. tags = var.common_tags The tags property has been set to var.common_tags , which is a declared variable called common_tags. Then when Terraform is run, it will check and create the resource if it's not existing already. If it's different, it will fix the drift in the object to make it as the specification.","title":"What it means"},{"location":"#the-tool","text":"The Terraform tool is written in Go-lang, and available for many platforms as a single executable binary, you can find the source hosted on Github here: Terraform , it is being actively developed and there are very regular updates to its core changelog and to it's providers : AWS and it's changelog or GCP and its changelog Current Terraform This site focuses on how to use the free edition and features of the Open source tool and Terraform Cloud. Unless called out, all AWS infrastructure will be provisioned in just one AWS region.","title":"The tool"},{"location":"#rationale","text":"Terraform is a second generation DevOps tool, it is designed to help you provision infrastructure. Templates are designed in Hashicorp Configuration Language (HCL) to describe how your infrastructure should be, and can be used to create and model your infrastructure, as well as being part of your Configuration Management Tool-chain.","title":"Rationale"},{"location":"#alternatives","text":"In no particular order:","title":"Alternatives"},{"location":"#puppet-and-chef","text":"These are the old guard or the v1.0 CM Tools, lots of agents and lots of set-up.","title":"Puppet and Chef"},{"location":"#ansible","text":"No Servers and No Agents. A very useful tool for configuration and in combination with Packer and Terraform.","title":"Ansible"},{"location":"#cloudfoundry","text":"","title":"CloudFoundry"},{"location":"#salt-stack","text":"More popular the otherside of the Atlantic, very rare in London/SE.","title":"Salt Stack"},{"location":"#cloudformation","text":"Popular with some AWS Consultants.","title":"Cloudformation"},{"location":"#pulumi","text":"If you want to code your infrastructure in a language you already know, this is for you, with support for Python and JS. Great for small teams with no specialised infra experience and if you can't get your head around the declarative approach of Terraform, this ones for you.","title":"Pulumi"},{"location":"#your-own-scripts","text":"Probably won't makes sense to even you six months later, god forbid you have use someone elses or they yours.","title":"Your own scripts"},{"location":"#the-console","text":"Well that's not DevOps is it.","title":"The Console"},{"location":"about/","text":"About Author: James Woolfenden LinkedIn Bio I'm currently working as a Principal for Slalom and based out of London. I have a bit of experience in the DevOps field, I have worked for a number of consultancies directly and indirectly. This is the second of series on Learning about DevOps. Why This is small run through of using Hashicorp Terraform. As a consultant I frequently have to train developers and \"DevOps\" Engineers how, why and when to use it. I started using Terraform from around version 0.5, I was on a Greenfield AWS project and was really struggling with Cloudformation and its tooling. I asked a question on Linkedin on what others were using and the steers I got were Terraform or Ansible. I achieved more in the day after than in the previous week. Hopefully you'll find this book useful. If it's missing or wrong in anyway, log an Issue or even submit a PR. Each Chapter also contains a copy of the code the chapter tries to teach you how to create. I originally wrote this for the pre 0.11 Terraform and I hopefully updated everything to 0.12 and all the samples should work.","title":"About"},{"location":"about/#about","text":"","title":"About"},{"location":"about/#author-james-woolfenden","text":"LinkedIn","title":"Author: James Woolfenden"},{"location":"about/#bio","text":"I'm currently working as a Principal for Slalom and based out of London. I have a bit of experience in the DevOps field, I have worked for a number of consultancies directly and indirectly. This is the second of series on Learning about DevOps.","title":"Bio"},{"location":"about/#why","text":"This is small run through of using Hashicorp Terraform. As a consultant I frequently have to train developers and \"DevOps\" Engineers how, why and when to use it. I started using Terraform from around version 0.5, I was on a Greenfield AWS project and was really struggling with Cloudformation and its tooling. I asked a question on Linkedin on what others were using and the steers I got were Terraform or Ansible. I achieved more in the day after than in the previous week. Hopefully you'll find this book useful. If it's missing or wrong in anyway, log an Issue or even submit a PR. Each Chapter also contains a copy of the code the chapter tries to teach you how to create. I originally wrote this for the pre 0.11 Terraform and I hopefully updated everything to 0.12 and all the samples should work.","title":"Why"},{"location":"adv-state/","text":"State Moving to Terraform Remote State Up to now all the examples have created a local state file, terraform.tfstate . If you are a lone developer operator then this could suffice, but if you lose that file or need to co-operate with other developers on changes a different approach is required. Local State Have a look at the Terraform code you applied in the previous chapters, along with the files you wrote, you will see a file called terraform.tfstate . Open it your editor, being careful not to change a thing. { \"version\": 4, \"terraform_version\": \"0.12.10\", \"serial\": 2, \"lineage\": \"a20fb43f-c6e8-d766-37d1-dd9af05f7a7e\", \"outputs\": { \"availablity_zones\": { \"value\": [ \"eu-west-1a\", \"eu-west-1b\", \"eu-west-1c\" ], \"type\": [ \"list\", \"string\" ] } }, \"resources\": [ { \"mode\": \"data\", \"type\": \"aws_availability_zones\", \"name\": \"available\", \"provider\": \"provider.aws\", \"instances\": [ { \"schema_version\": 0, \"attributes\": { \"blacklisted_names\": null, \"blacklisted_zone_ids\": null, \"id\": \"2019-11-06 14:17:11.2174491 +0000 UTC\", \"names\": [ \"eu-west-1a\", \"eu-west-1b\", \"eu-west-1c\" ], \"state\": \"available\", \"zone_ids\": [ \"euw1-az3\", \"euw1-az1\", \"euw1-az2\" ] } } ] }, { \"mode\": \"data\", \"type\": \"aws_caller_identity\", \"name\": \"current\", \"provider\": \"provider.aws\", \"instances\": [ { \"schema_version\": 0, \"attributes\": { \"account_id\": \"111111111111\", \"arn\": \"arn:aws:iam::111111111111:user/jameswoolfenden\", \"id\": \"2019-11-06 14:17:11.5923975 +0000 UTC\", \"user_id\": \"AAAAAAAAAAAAAAAAA\" } } ] } ] } Re-apply the Terraform(This just to check that all is still working) $ Terraform apply ... After the apply is finished, rename the file terraform.tfstate to terraform.tfstate.old . Now try to re-apply the same Terraform. If the sample you used created infrastructure you'll now see an error showing that it failed. Lots of issues about resource existing? That's easily fixed by reverting your re-naming. So losing your terraform.tfstate file isn't great. That file is also best not left on your machine or on any server, plus it might have information you don't want shared. If you ever want to automate or cooperate on infrastructure you must have a better solution. The easiest way to solve this, in the cloud, is the use of a \"State bucket\". A State bucket might make you think of AWS but the same principal applies to Azure and GCP. AWS State Bucket For each AWS account you use Terraform with create a remote backend to store Terraform state. Create folder and add module.statebucket.tf . module statebucket { source = \"JamesWoolfenden/statebucket/aws\" version = \"0.2.25\" common_tags = var . common_tags } ``` and a ** provider . aws . tf** ``` terraform provider \"aws\" { region = \"eu-west-1\" version = \"2.31\" } ``` Run this once and it will create your state bucket named \"${data.aws_caller_identity.current.account_id}-terraform-state\" . Run it a second time and the state for creating the buckets is stored in the bucket by writing its own **remote . state . tf** ``` terraform terraform { backend \"s3\" { encrypt = true bucket = \"1232141412-terraform-state\" key = \"state-bucket/terraform.tfstate\" dynamodb_table = \"dynamodb-state-lock\" region = \"eu-west-1\" } } Locking and unlock state buckets When you add a state bucket you should also enable locking. Locking is prevent clashes, when 2 developers/processes try to modify the same resource at the same time. Should someone else be running your terraform at the same time via a state bucket you might see: Error: Error locking state: Error acquiring the state lock: The process cannot access the file because another process has locked a portion of the file. Lock Info: ID: 0e9bffe0-b181-c7ce-7155-beddbc24d829 Path: terraform.tfstate Operation: OperationTypePlan Who: james.woolfenden@23043-5510 Version: 0 .11.11 Created: 2019 -03-18 22 :21:55.075742 +0000 UTC Info: Then you should wait until this pln/apply is over. This can also occur if a lock was not released, If a previous run crashed or was cancelled then the lock maybe not be released? You can then force an unlock, if you have locked your self then the forst step is kill any orphaned Terraform processes. $ terraform force-unlock 0e9bffe0-b181-c7ce-7155-beddbc24d829 ... Terraform acquires a state lock to protect the state from being written by multiple users at the same time. Please resolve the issue above and try again. For most commands, you can disable locking with the \"-lock=false\" flag, but this is not recommended. Versioning on the AWS bucket Versioning on the S3 bucket is enable by the properties in aws_s3_bucket.statebucket.tf versioning { enabled = true mfa_delete = true } GCP and Azure You can do a similar things with the other providers Terraform Cloud state Sign up for a Terraform Cloud account and Create an organisation, and set up a workspace. You can have multiple workspaces per repository: Each workspace requires Authentication. In your code Add or update your terraform.tf file to include: terraform { backend \"remote\" { hostname = \"app.terraform.io\" organization = \"wolf\" workspaces { name = \"terraform-aws-codebuild-exampleA-tfe\" } } } Recovering and importing State If you need to recreate or import existing infrastructure there a three main ways:- Terraform import Most resources support the import keyword, this is the oldest method and is the slowest: terraform import aws_s3_bucket.whosebucketisitanyway whosebucketisitanyway By itself will fail with: Error: resource address \"aws_s3_bucket.whosebucketisitanyway\" does not exist in the configuration. Before importing this resource, please create its configuration in the root module. For example: resource \"aws_s3_bucket\" \"whosebucketisitanyway\" { # (resource arguments) } So you will need to make the file aws_s3_bucket.whosebucketisitanyway.tf to successfully associate it. resource \"aws_s3_bucket\" \"whosebucketisitanyway\" { } But you will notice that your still need to update your resource to match your actual state. $ terraform plan Refreshing Terraform state in-memory prior to plan... The refreshed state will be used to calculate this plan, but will not be persisted to local or remote state storage. aws_s3_bucket.whosebucketisitanyway: Refreshing state... [id=whosebucketisitanyway] ------------------------------------------------------------------------ An execution plan has been generated and is shown below. Resource actions are indicated with the following symbols: ~ update in-place Terraform will perform the following actions: # aws_s3_bucket.whosebucketisitanyway will be updated in-place ~ resource \"aws_s3_bucket\" \"whosebucketisitanyway\" { + acl = \"private\" arn = \"arn:aws:s3:::whosebucketisitanyway\" bucket = \"whosebucketisitanyway\" bucket_domain_name = \"whosebucketisitanyway.s3.amazonaws.com\" bucket_regional_domain_name = \"whosebucketisitanyway.s3.eu-west-1.amazonaws.com\" + force_destroy = false hosted_zone_id = \"Z1BKCTXD74EZPE\" id = \"whosebucketisitanyway\" region = \"eu-west-1\" request_payer = \"BucketOwner\" tags = {} versioning { enabled = false mfa_delete = false } } Plan: 0 to add, 1 to change, 0 to destroy. Terraforming You'll need to install this. Terraforming can help with existing AWS infrastructure to generate the template. $ aws s3 mb s3://whosebucketisitanyway make_bucket: whosebucketisitanyway $ aws s3 ls 2019 -10-12 12 :01:30 whosebucketisitanyway $ terraforming s3 resource \"aws_s3_bucket\" \"whosebucketisitanyway\" { bucket = \"whosebucketisitanyway\" acl = \"private\" } or the missing state: $ terraforming s3 --tfstate { \"version\": 1, \"serial\": 1, \"modules\": [ { \"path\": [ \"root\" ], \"outputs\": { }, \"resources\": { \"aws_s3_bucket.whosebucketisitanyway\": { \"type\": \"aws_s3_bucket\", \"primary\": { \"id\": \"whosebucketisitanyway\", \"attributes\": { \"acl\": \"private\", \"bucket\": \"whosebucketisitanyway\", \"force_destroy\": \"false\", \"id\": \"whosebucketisitanyway\", \"policy\": \"\" } } } } } ] } Terraformer You'll need to install this, from https://github.com/GoogleCloudPlatform/terraformer/releases/latest It supports GCP, AWS or a number of other resources. It generates the templates and the state file on a resource type basis. This is a more sophisticated tool and has support for many more providers. You will need to have set-up the providers already. terraformer import aws --resources=s3 --regions=eu-west-1 2019/10/12 14:01:16 aws importing region eu-west-1 2019/10/12 14:01:16 aws importing... s3 2019/10/12 14:01:17 [TRACE] GRPCProvider: GetSchema 2019/10/12 14:01:17 [TRACE] GRPCProvider: Configure 2019/10/12 14:01:19 [TRACE] GRPCProvider: GetSchema 2019/10/12 14:01:19 [TRACE] GRPCProvider: GetSchema 2019/10/12 14:01:20 [TRACE] GRPCProvider: Configure 2019/10/12 14:01:21 Refreshing state... aws_s3_bucket.whosebucketisitanyway 2019/10/12 14:01:21 [TRACE] GRPCProvider: GetSchema 2019/10/12 14:01:21 [TRACE] GRPCProvider: ReadResource 2019/10/12 14:01:24 aws Connecting.... 2019/10/12 14:01:24 aws save s3 2019/10/12 14:01:24 [DEBUG] New state was assigned lineage \"4b60793a-54f0-acf6-7e9a-89242e7feb84\" 2019/10/12 14:01:24 aws save tfstate for s3 This will make everything you need: $ ls generated/aws/s3/eu-west-1 -l total 4 -rwxrwxrwx 1 jim jim 106 Oct 12 14:32 outputs.tf -rwxrwxrwx 1 jim jim 65 Oct 12 14:32 provider.tf -rwxrwxrwx 1 jim jim 394 Oct 12 14:32 s3_bucket.tf -rwxrwxrwx 1 jim jim 2460 Oct 12 14:32 terraform.tfstate This is great but you'll have to refactor the reosurce ids to objects names and merge the resource types. You'll also need to merge the state files, be careful. You can use https://github.com/mmalecki/terraform-state-merge to merge.","title":"Advanced State"},{"location":"adv-state/#state","text":"","title":"State"},{"location":"adv-state/#moving-to-terraform-remote-state","text":"Up to now all the examples have created a local state file, terraform.tfstate . If you are a lone developer operator then this could suffice, but if you lose that file or need to co-operate with other developers on changes a different approach is required.","title":"Moving to Terraform Remote State"},{"location":"adv-state/#local-state","text":"Have a look at the Terraform code you applied in the previous chapters, along with the files you wrote, you will see a file called terraform.tfstate . Open it your editor, being careful not to change a thing. { \"version\": 4, \"terraform_version\": \"0.12.10\", \"serial\": 2, \"lineage\": \"a20fb43f-c6e8-d766-37d1-dd9af05f7a7e\", \"outputs\": { \"availablity_zones\": { \"value\": [ \"eu-west-1a\", \"eu-west-1b\", \"eu-west-1c\" ], \"type\": [ \"list\", \"string\" ] } }, \"resources\": [ { \"mode\": \"data\", \"type\": \"aws_availability_zones\", \"name\": \"available\", \"provider\": \"provider.aws\", \"instances\": [ { \"schema_version\": 0, \"attributes\": { \"blacklisted_names\": null, \"blacklisted_zone_ids\": null, \"id\": \"2019-11-06 14:17:11.2174491 +0000 UTC\", \"names\": [ \"eu-west-1a\", \"eu-west-1b\", \"eu-west-1c\" ], \"state\": \"available\", \"zone_ids\": [ \"euw1-az3\", \"euw1-az1\", \"euw1-az2\" ] } } ] }, { \"mode\": \"data\", \"type\": \"aws_caller_identity\", \"name\": \"current\", \"provider\": \"provider.aws\", \"instances\": [ { \"schema_version\": 0, \"attributes\": { \"account_id\": \"111111111111\", \"arn\": \"arn:aws:iam::111111111111:user/jameswoolfenden\", \"id\": \"2019-11-06 14:17:11.5923975 +0000 UTC\", \"user_id\": \"AAAAAAAAAAAAAAAAA\" } } ] } ] } Re-apply the Terraform(This just to check that all is still working) $ Terraform apply ... After the apply is finished, rename the file terraform.tfstate to terraform.tfstate.old . Now try to re-apply the same Terraform. If the sample you used created infrastructure you'll now see an error showing that it failed. Lots of issues about resource existing? That's easily fixed by reverting your re-naming. So losing your terraform.tfstate file isn't great. That file is also best not left on your machine or on any server, plus it might have information you don't want shared. If you ever want to automate or cooperate on infrastructure you must have a better solution. The easiest way to solve this, in the cloud, is the use of a \"State bucket\". A State bucket might make you think of AWS but the same principal applies to Azure and GCP.","title":"Local State"},{"location":"adv-state/#aws-state-bucket","text":"For each AWS account you use Terraform with create a remote backend to store Terraform state. Create folder and add module.statebucket.tf . module statebucket { source = \"JamesWoolfenden/statebucket/aws\" version = \"0.2.25\" common_tags = var . common_tags } ``` and a ** provider . aws . tf** ``` terraform provider \"aws\" { region = \"eu-west-1\" version = \"2.31\" } ``` Run this once and it will create your state bucket named \"${data.aws_caller_identity.current.account_id}-terraform-state\" . Run it a second time and the state for creating the buckets is stored in the bucket by writing its own **remote . state . tf** ``` terraform terraform { backend \"s3\" { encrypt = true bucket = \"1232141412-terraform-state\" key = \"state-bucket/terraform.tfstate\" dynamodb_table = \"dynamodb-state-lock\" region = \"eu-west-1\" } }","title":"AWS State Bucket"},{"location":"adv-state/#locking-and-unlock-state-buckets","text":"When you add a state bucket you should also enable locking. Locking is prevent clashes, when 2 developers/processes try to modify the same resource at the same time. Should someone else be running your terraform at the same time via a state bucket you might see: Error: Error locking state: Error acquiring the state lock: The process cannot access the file because another process has locked a portion of the file. Lock Info: ID: 0e9bffe0-b181-c7ce-7155-beddbc24d829 Path: terraform.tfstate Operation: OperationTypePlan Who: james.woolfenden@23043-5510 Version: 0 .11.11 Created: 2019 -03-18 22 :21:55.075742 +0000 UTC Info: Then you should wait until this pln/apply is over. This can also occur if a lock was not released, If a previous run crashed or was cancelled then the lock maybe not be released? You can then force an unlock, if you have locked your self then the forst step is kill any orphaned Terraform processes. $ terraform force-unlock 0e9bffe0-b181-c7ce-7155-beddbc24d829 ... Terraform acquires a state lock to protect the state from being written by multiple users at the same time. Please resolve the issue above and try again. For most commands, you can disable locking with the \"-lock=false\" flag, but this is not recommended.","title":"Locking and unlock state buckets"},{"location":"adv-state/#versioning-on-the-aws-bucket","text":"Versioning on the S3 bucket is enable by the properties in aws_s3_bucket.statebucket.tf versioning { enabled = true mfa_delete = true }","title":"Versioning on the AWS bucket"},{"location":"adv-state/#gcp-and-azure","text":"You can do a similar things with the other providers","title":"GCP and Azure"},{"location":"adv-state/#terraform-cloud-state","text":"Sign up for a Terraform Cloud account and Create an organisation, and set up a workspace. You can have multiple workspaces per repository: Each workspace requires Authentication. In your code Add or update your terraform.tf file to include: terraform { backend \"remote\" { hostname = \"app.terraform.io\" organization = \"wolf\" workspaces { name = \"terraform-aws-codebuild-exampleA-tfe\" } } }","title":"Terraform Cloud state"},{"location":"adv-state/#recovering-and-importing-state","text":"If you need to recreate or import existing infrastructure there a three main ways:-","title":"Recovering and importing State"},{"location":"adv-state/#terraform-import","text":"Most resources support the import keyword, this is the oldest method and is the slowest: terraform import aws_s3_bucket.whosebucketisitanyway whosebucketisitanyway By itself will fail with: Error: resource address \"aws_s3_bucket.whosebucketisitanyway\" does not exist in the configuration. Before importing this resource, please create its configuration in the root module. For example: resource \"aws_s3_bucket\" \"whosebucketisitanyway\" { # (resource arguments) } So you will need to make the file aws_s3_bucket.whosebucketisitanyway.tf to successfully associate it. resource \"aws_s3_bucket\" \"whosebucketisitanyway\" { } But you will notice that your still need to update your resource to match your actual state. $ terraform plan Refreshing Terraform state in-memory prior to plan... The refreshed state will be used to calculate this plan, but will not be persisted to local or remote state storage. aws_s3_bucket.whosebucketisitanyway: Refreshing state... [id=whosebucketisitanyway] ------------------------------------------------------------------------ An execution plan has been generated and is shown below. Resource actions are indicated with the following symbols: ~ update in-place Terraform will perform the following actions: # aws_s3_bucket.whosebucketisitanyway will be updated in-place ~ resource \"aws_s3_bucket\" \"whosebucketisitanyway\" { + acl = \"private\" arn = \"arn:aws:s3:::whosebucketisitanyway\" bucket = \"whosebucketisitanyway\" bucket_domain_name = \"whosebucketisitanyway.s3.amazonaws.com\" bucket_regional_domain_name = \"whosebucketisitanyway.s3.eu-west-1.amazonaws.com\" + force_destroy = false hosted_zone_id = \"Z1BKCTXD74EZPE\" id = \"whosebucketisitanyway\" region = \"eu-west-1\" request_payer = \"BucketOwner\" tags = {} versioning { enabled = false mfa_delete = false } } Plan: 0 to add, 1 to change, 0 to destroy.","title":"Terraform import"},{"location":"adv-state/#terraforming","text":"You'll need to install this. Terraforming can help with existing AWS infrastructure to generate the template. $ aws s3 mb s3://whosebucketisitanyway make_bucket: whosebucketisitanyway $ aws s3 ls 2019 -10-12 12 :01:30 whosebucketisitanyway $ terraforming s3 resource \"aws_s3_bucket\" \"whosebucketisitanyway\" { bucket = \"whosebucketisitanyway\" acl = \"private\" } or the missing state: $ terraforming s3 --tfstate { \"version\": 1, \"serial\": 1, \"modules\": [ { \"path\": [ \"root\" ], \"outputs\": { }, \"resources\": { \"aws_s3_bucket.whosebucketisitanyway\": { \"type\": \"aws_s3_bucket\", \"primary\": { \"id\": \"whosebucketisitanyway\", \"attributes\": { \"acl\": \"private\", \"bucket\": \"whosebucketisitanyway\", \"force_destroy\": \"false\", \"id\": \"whosebucketisitanyway\", \"policy\": \"\" } } } } } ] }","title":"Terraforming"},{"location":"adv-state/#terraformer","text":"You'll need to install this, from https://github.com/GoogleCloudPlatform/terraformer/releases/latest It supports GCP, AWS or a number of other resources. It generates the templates and the state file on a resource type basis. This is a more sophisticated tool and has support for many more providers. You will need to have set-up the providers already. terraformer import aws --resources=s3 --regions=eu-west-1 2019/10/12 14:01:16 aws importing region eu-west-1 2019/10/12 14:01:16 aws importing... s3 2019/10/12 14:01:17 [TRACE] GRPCProvider: GetSchema 2019/10/12 14:01:17 [TRACE] GRPCProvider: Configure 2019/10/12 14:01:19 [TRACE] GRPCProvider: GetSchema 2019/10/12 14:01:19 [TRACE] GRPCProvider: GetSchema 2019/10/12 14:01:20 [TRACE] GRPCProvider: Configure 2019/10/12 14:01:21 Refreshing state... aws_s3_bucket.whosebucketisitanyway 2019/10/12 14:01:21 [TRACE] GRPCProvider: GetSchema 2019/10/12 14:01:21 [TRACE] GRPCProvider: ReadResource 2019/10/12 14:01:24 aws Connecting.... 2019/10/12 14:01:24 aws save s3 2019/10/12 14:01:24 [DEBUG] New state was assigned lineage \"4b60793a-54f0-acf6-7e9a-89242e7feb84\" 2019/10/12 14:01:24 aws save tfstate for s3 This will make everything you need: $ ls generated/aws/s3/eu-west-1 -l total 4 -rwxrwxrwx 1 jim jim 106 Oct 12 14:32 outputs.tf -rwxrwxrwx 1 jim jim 65 Oct 12 14:32 provider.tf -rwxrwxrwx 1 jim jim 394 Oct 12 14:32 s3_bucket.tf -rwxrwxrwx 1 jim jim 2460 Oct 12 14:32 terraform.tfstate This is great but you'll have to refactor the reosurce ids to objects names and merge the resource types. You'll also need to merge the state files, be careful. You can use https://github.com/mmalecki/terraform-state-merge to merge.","title":"Terraformer"},{"location":"aws-alb/","text":"Creating an Application load balancer (ALB) with Terraform Use scaffold to create aws_alb $ scaffold aws_alb git clone --depth = 1 git@github.com:JamesWoolfenden/tf-scaffold.git aws_alb Cloning into 'aws_alb' ... remote: Enumerating objects: 11 , done . remote: Counting objects: 100 % ( 11 /11 ) , done . remote: Compressing objects: 100 % ( 8 /8 ) , done . remote: Total 11 ( delta 0 ) , reused 6 ( delta 0 ) , pack-reused 0 Receiving objects: 100 % ( 11 /11 ) , done . Then we can add an ALB using the aws_lb resource. resource \"aws_lb\" \"apploadbalancer\" { name = \"app-load-balancer\" load_balancer_type = \"application\" tags = var . common_tags } Extras: TODO:Set-up a listener TODO:addinstances","title":"Application"},{"location":"aws-alb/#creating-an-application-load-balancer-alb-with-terraform","text":"Use scaffold to create aws_alb $ scaffold aws_alb git clone --depth = 1 git@github.com:JamesWoolfenden/tf-scaffold.git aws_alb Cloning into 'aws_alb' ... remote: Enumerating objects: 11 , done . remote: Counting objects: 100 % ( 11 /11 ) , done . remote: Compressing objects: 100 % ( 8 /8 ) , done . remote: Total 11 ( delta 0 ) , reused 6 ( delta 0 ) , pack-reused 0 Receiving objects: 100 % ( 11 /11 ) , done . Then we can add an ALB using the aws_lb resource. resource \"aws_lb\" \"apploadbalancer\" { name = \"app-load-balancer\" load_balancer_type = \"application\" tags = var . common_tags } Extras: TODO:Set-up a listener TODO:addinstances","title":"Creating an Application load balancer (ALB) with Terraform"},{"location":"aws-autoscaling/","text":"AutoScaling Groups Autoscaling aims to maintain available resource inline with demands on those resources. This is horizontal scaling (Number of instances) not vertical (more tin/ram) and is is either scale out (increasing) scaling in (reduction) or to maintaining a resource level (launching new instances if failures occur). There are now two ways to configure an Autoscaling Group in AWS. Launch configuration This is the older way, create aws_launch_configuration.web.tf as below: resource \"aws_launch_configuration\" \"web\" { name = \"web_config\" image_id = data . aws_ami . xenial . id instance_type = \"t2.micro\" } If the properties in a launch configuration look familar, its because they are used replace the aws_instance resoure, when combined with an Autoscaling group aws_autoscaling_group.web.tf . resource \"aws_autoscaling_group\" \"web\" { availability_zones = [ \"eu-west-1a\" ] desired_capacity = 1 max_size = 1 min_size = 1 launch_configuration = aws_launch_configuration . web . id } Replacing one resource for two might not seem like an obvious gain, but functional it's big, now should you lose the instance a new one will be started automatically. A launch configuration can be used as a foundational component of a blue-green deployment strategy. Typically this can be achieved by updating the AMI of the Launch config, and then Scaling out and then In, this action removes the oldest EC2 instance. Launch template Launch templates are the new way, being almost identical to Launch configuration but with more support for parameters and support for multiple versions. For our terraform example, swap out the launch configuration and add aws_launch_template.web.tf : resource \"aws_launch_template\" \"web\" { name_prefix = \"web\" image_id = data . aws_ami . xenial . id instance_type = \"t2.micro\" } Together with a small change to the scaling group. resource \"aws_autoscaling_group\" \"web\" { availability_zones = [ \"eu-west-1a\" ] desired_capacity = 1 max_size = 1 min_size = 1 launch_template { id = aws_launch_template . web . id version = \"$$Latest\" } } TODO:extract numbers to tfvars modify and reapply Autoscaling Policy resource \"aws_autoscaling_policy\" \"defaultmetrics\" { name = \"web-default-scaling\" scaling_adjustment = 4 adjustment_type = \"ChangeInCapacity\" cooldown = 300 autoscaling_group_name = aws_autoscaling_group . web . name } There's nothing very \"smart\" or reactive here yet. I'd like increase or decrease the capacity of the web tier in response to application performance metric. TODO:scaling no point scaling down paid for instances if not reserved? EC2 instance custom Metrics - cpu utilisation from hypervisor, io bound? Autoscaling groups for other objects Links https://docs.aws.amazon.com/autoscaling/ec2/userguide/AutoScalingGroup.html https://www.terraform.io/docs/providers/aws/r/autoscaling_policy.html","title":"AWS"},{"location":"aws-autoscaling/#autoscaling-groups","text":"Autoscaling aims to maintain available resource inline with demands on those resources. This is horizontal scaling (Number of instances) not vertical (more tin/ram) and is is either scale out (increasing) scaling in (reduction) or to maintaining a resource level (launching new instances if failures occur). There are now two ways to configure an Autoscaling Group in AWS.","title":"AutoScaling Groups"},{"location":"aws-autoscaling/#launch-configuration","text":"This is the older way, create aws_launch_configuration.web.tf as below: resource \"aws_launch_configuration\" \"web\" { name = \"web_config\" image_id = data . aws_ami . xenial . id instance_type = \"t2.micro\" } If the properties in a launch configuration look familar, its because they are used replace the aws_instance resoure, when combined with an Autoscaling group aws_autoscaling_group.web.tf . resource \"aws_autoscaling_group\" \"web\" { availability_zones = [ \"eu-west-1a\" ] desired_capacity = 1 max_size = 1 min_size = 1 launch_configuration = aws_launch_configuration . web . id } Replacing one resource for two might not seem like an obvious gain, but functional it's big, now should you lose the instance a new one will be started automatically. A launch configuration can be used as a foundational component of a blue-green deployment strategy. Typically this can be achieved by updating the AMI of the Launch config, and then Scaling out and then In, this action removes the oldest EC2 instance.","title":"Launch configuration"},{"location":"aws-autoscaling/#launch-template","text":"Launch templates are the new way, being almost identical to Launch configuration but with more support for parameters and support for multiple versions. For our terraform example, swap out the launch configuration and add aws_launch_template.web.tf : resource \"aws_launch_template\" \"web\" { name_prefix = \"web\" image_id = data . aws_ami . xenial . id instance_type = \"t2.micro\" } Together with a small change to the scaling group. resource \"aws_autoscaling_group\" \"web\" { availability_zones = [ \"eu-west-1a\" ] desired_capacity = 1 max_size = 1 min_size = 1 launch_template { id = aws_launch_template . web . id version = \"$$Latest\" } } TODO:extract numbers to tfvars modify and reapply","title":"Launch template"},{"location":"aws-autoscaling/#autoscaling-policy","text":"resource \"aws_autoscaling_policy\" \"defaultmetrics\" { name = \"web-default-scaling\" scaling_adjustment = 4 adjustment_type = \"ChangeInCapacity\" cooldown = 300 autoscaling_group_name = aws_autoscaling_group . web . name } There's nothing very \"smart\" or reactive here yet. I'd like increase or decrease the capacity of the web tier in response to application performance metric. TODO:scaling no point scaling down paid for instances if not reserved? EC2 instance custom Metrics - cpu utilisation from hypervisor, io bound?","title":"Autoscaling Policy"},{"location":"aws-autoscaling/#autoscaling-groups-for-other-objects","text":"","title":"Autoscaling groups for other objects"},{"location":"aws-autoscaling/#links","text":"https://docs.aws.amazon.com/autoscaling/ec2/userguide/AutoScalingGroup.html https://www.terraform.io/docs/providers/aws/r/autoscaling_policy.html","title":"Links"},{"location":"aws-cloudwatch/","text":"Cloudwatch TODO Logs Add agent Setting Metrics Add agent Default metrics from hypervisor Cloudwatch events from resource \"aws_cloudwatch_event_rule\" \"eventrule\" { description = \"An Amazon CloudWatch Event rule has been created by AWS CodeCommit for the following repository: ${aws_codecommit_repository.repo.arn}.\" is_enabled = true event_pattern = <<PATTERN { \"source\" : [ \"aws.codecommit\" ], \"resources\" : [ \"${aws_codecommit_repository.repo.arn}\" ], \"detail-type\" : [ \"CodeCommit Pull Request State Change\" , \"CodeCommit Comment on Pull Request\" , \"CodeCommit Comment on Commit\" ] } PATTERN } event target resource \"aws_cloudwatch_event_target\" \"target\" { target_id = \"codecommit_notification\" rule = aws_cloudwatch_event_rule . eventrule . name arn = aws_sns_topic . notification . arn input_path = \"$.detail.notificationBody\" } Note https://github.com/JamesWoolfenden/terraform-aws-cloudwatch-s3","title":"Cloudwatch"},{"location":"aws-cloudwatch/#cloudwatch","text":"TODO","title":"Cloudwatch"},{"location":"aws-cloudwatch/#logs","text":"Add agent Setting","title":"Logs"},{"location":"aws-cloudwatch/#metrics","text":"Add agent Default metrics from hypervisor","title":"Metrics"},{"location":"aws-cloudwatch/#cloudwatch-events","text":"from resource \"aws_cloudwatch_event_rule\" \"eventrule\" { description = \"An Amazon CloudWatch Event rule has been created by AWS CodeCommit for the following repository: ${aws_codecommit_repository.repo.arn}.\" is_enabled = true event_pattern = <<PATTERN { \"source\" : [ \"aws.codecommit\" ], \"resources\" : [ \"${aws_codecommit_repository.repo.arn}\" ], \"detail-type\" : [ \"CodeCommit Pull Request State Change\" , \"CodeCommit Comment on Pull Request\" , \"CodeCommit Comment on Commit\" ] } PATTERN }","title":"Cloudwatch events"},{"location":"aws-cloudwatch/#event-target","text":"resource \"aws_cloudwatch_event_target\" \"target\" { target_id = \"codecommit_notification\" rule = aws_cloudwatch_event_rule . eventrule . name arn = aws_sns_topic . notification . arn input_path = \"$.detail.notificationBody\" } Note https://github.com/JamesWoolfenden/terraform-aws-cloudwatch-s3","title":"event target"},{"location":"aws-codecommit/","text":"Code Commit AWS Codecommit is a managed Git service with your AWS account. It supports Git features such as PR's and integrates with IAM. You can use an existing module or write your own. This module combines IAM groups with Cloudwatch events and SNS to trigger on every change and can be set to branch protect a given branch. The core resource is aws_codecommit_repository.repo.tf resource \"aws_codecommit_repository\" \"repo\" { repository_name = var . repository_name description = var . repository_name default_branch = var . default_branch } Create a new Respository from scratch Create a new folder aws_codecommit Add a module reference module.codecommit.tf module \"codecommit\" { source = \"JamesWoolfenden/codecommit/aws\" version = \"0.2.53\" repository_name = var . repository_name } Add your variables.tf with: variable \"repository_name\" { type = string description = \"The name of your GIT repository\" } Add these additional outputs to a outputs.tf : output \"clone_url_https\" { value = module . codecommit . clone_url_https } output \"clone_url_ssh\" { value = module . codecommit . clone_url_ssh } And a property file with main.auto.tfvars repository_name = \"Valyria\" Put this all together with: terraform init terraform apply Note https://registry.terraform.io/modules/JamesWoolfenden/codecommit/aws/0.2.53","title":"CodeCommit"},{"location":"aws-codecommit/#code-commit","text":"AWS Codecommit is a managed Git service with your AWS account. It supports Git features such as PR's and integrates with IAM. You can use an existing module or write your own. This module combines IAM groups with Cloudwatch events and SNS to trigger on every change and can be set to branch protect a given branch. The core resource is aws_codecommit_repository.repo.tf resource \"aws_codecommit_repository\" \"repo\" { repository_name = var . repository_name description = var . repository_name default_branch = var . default_branch }","title":"Code Commit"},{"location":"aws-codecommit/#create-a-new-respository-from-scratch","text":"Create a new folder aws_codecommit Add a module reference module.codecommit.tf module \"codecommit\" { source = \"JamesWoolfenden/codecommit/aws\" version = \"0.2.53\" repository_name = var . repository_name } Add your variables.tf with: variable \"repository_name\" { type = string description = \"The name of your GIT repository\" } Add these additional outputs to a outputs.tf : output \"clone_url_https\" { value = module . codecommit . clone_url_https } output \"clone_url_ssh\" { value = module . codecommit . clone_url_ssh } And a property file with main.auto.tfvars repository_name = \"Valyria\" Put this all together with: terraform init terraform apply Note https://registry.terraform.io/modules/JamesWoolfenden/codecommit/aws/0.2.53","title":"Create a new Respository from scratch"},{"location":"aws-dns/","text":"Managing DNS with Terraform TODO AWS Route53 Hosted zones Health checks Traffic policies Policy records Registering domains VPC endpoints inbound outbound Rules add route53 to alb example basic DNS other features of Route53 cross region load balancing","title":"Route 53"},{"location":"aws-dns/#managing-dns-with-terraform","text":"TODO","title":"Managing DNS with Terraform"},{"location":"aws-dns/#aws-route53","text":"","title":"AWS Route53"},{"location":"aws-dns/#hosted-zones","text":"","title":"Hosted zones"},{"location":"aws-dns/#health-checks","text":"","title":"Health checks"},{"location":"aws-dns/#traffic-policies","text":"","title":"Traffic policies"},{"location":"aws-dns/#policy-records","text":"","title":"Policy records"},{"location":"aws-dns/#registering-domains","text":"","title":"Registering domains"},{"location":"aws-dns/#vpc-endpoints","text":"","title":"VPC endpoints"},{"location":"aws-dns/#inbound","text":"","title":"inbound"},{"location":"aws-dns/#outbound","text":"","title":"outbound"},{"location":"aws-dns/#rules","text":"add route53 to alb example basic DNS other features of Route53 cross region load balancing","title":"Rules"},{"location":"aws-ecr/","text":"Elastic Container Registry Create a folder and add module.ecr.tf : module ecr { source = \"github.com/JamesWoolfenden/terraform-aws-ecr\" version = \"0.2.22\" name = var . name repositorypolicy = data . aws_iam_policy_document . allowlocals . json } and a repository policy data \"aws_iam_policy_document\" \"allowlocals\" { statement { sid = \"AllowPushPull\" actions = [ \"ecr:GetDownloadUrlForLayer\" , \"ecr:BatchGetImage\" , \"ecr:BatchCheckLayerAvailability\" , \"ecr:PutImage\" , \"ecr:InitiateLayerUpload\" , \"ecr:UploadLayerPart\" , \"ecr:CompleteLayerUpload\" , ] principals { type = \"AWS\" identifiers = [ \"arn:aws:iam::${data.aws_caller_identity.current.account_id}:root\" ] } } } The above policy allows any user from its own account have access. This module has a full example to follow: https://github.com/JamesWoolfenden/terraform-aws-ecr/tree/master/example/exampleA Note Following https://github.com/JamesWoolfenden/terraform-aws-ecr","title":"ECR"},{"location":"aws-ecr/#elastic-container-registry","text":"Create a folder and add module.ecr.tf : module ecr { source = \"github.com/JamesWoolfenden/terraform-aws-ecr\" version = \"0.2.22\" name = var . name repositorypolicy = data . aws_iam_policy_document . allowlocals . json } and a repository policy data \"aws_iam_policy_document\" \"allowlocals\" { statement { sid = \"AllowPushPull\" actions = [ \"ecr:GetDownloadUrlForLayer\" , \"ecr:BatchGetImage\" , \"ecr:BatchCheckLayerAvailability\" , \"ecr:PutImage\" , \"ecr:InitiateLayerUpload\" , \"ecr:UploadLayerPart\" , \"ecr:CompleteLayerUpload\" , ] principals { type = \"AWS\" identifiers = [ \"arn:aws:iam::${data.aws_caller_identity.current.account_id}:root\" ] } } } The above policy allows any user from its own account have access. This module has a full example to follow: https://github.com/JamesWoolfenden/terraform-aws-ecr/tree/master/example/exampleA Note Following https://github.com/JamesWoolfenden/terraform-aws-ecr","title":"Elastic Container Registry"},{"location":"aws-ecs/","text":"Elastic Container Service","title":"ECS"},{"location":"aws-ecs/#elastic-container-service","text":"","title":"Elastic Container Service"},{"location":"aws-iam/","text":"Managing IAM with Terraform AWS IAM - Identity Access Management Json based roles, user and policies. This is the authentication scheme at the heart of AWS. Create a policy with HEREDOC IAM policies can be added via the console either using the AWS wizards or as JSON files. You can add a Json policy in directly to your terraform policy if you use a HEREDOC. A Heredoc allows you to paste in a multiline string. aws_iam_policy.heredoc.tf below is an example of using a Heredoc in a policy statement. resource \"aws_iam_policy\" \"heredoc\" { name = \"heredoc_policy\" path = \"/\" description = \"An example policy\" policy = <<HEREDOC { \"Version\": \"2012-10-17\" , \"Statement\" : [ { \"Action\" : [ \"ec2:*\" ], \"Effect\": \"Allow\" , \"Resource\": \"*\" } ] } HEREDOC } This will create a managed but unattached IAM policy. Create a scaffold iam_policy and make the policy $ scaffold iam_policy git clone --depth = 1 git@github.com:JamesWoolfenden/tf-scaffold.git iam_policy Cloning into 'iam_policy' ... remote: Enumerating objects: 11 , done . remote: Counting objects: 100 % ( 11 /11 ) , done . remote: Compressing objects: 100 % ( 8 /8 ) , done . remote: Total 11 ( delta 0 ) , reused 6 ( delta 0 ) , pack-reused 0 Receiving objects: 100 % ( 11 /11 ) , done . You can check the policy creation in UI or via the cli. $ aws iam get-policy --policy-arn arn:aws:iam::122121221:policy/heredoc_policy { \"Policy\" : { \"PolicyName\" : \"heredoc_policy\" , \"PolicyId\" : \"xxxxxxxxxxxxxxx\" , \"Arn\" : \"arn:aws:iam::122121221:policy/heredoc_policy\" , \"Path\" : \"/\" , \"DefaultVersionId\" : \"v1\" , \"AttachmentCount\" : 0 , \"PermissionsBoundaryUsageCount\" : 0 , \"IsAttachable\" : true, \"Description\" : \"An example policy\" , \"CreateDate\" : \"2019-04-06T22:05:51Z\" , \"UpdateDate\" : \"2019-04-06T22:05:51Z\" } } That's the old way of making a policy, you can now use data resources to build policies in Terraform. The previous example can rewritten with a data.aws_iam_policy_document data resource. Now delete your state file. Add data.aws_policy_document.heredoc.tf data \"aws_iam_policy_document\" \"heredoc\" { statement { actions = [ \"ec2:*\" , ] resources = [ \"*\" , ] } } And modify the policy resource to use this data resource. resource \"aws_iam_policy\" \"heredoc\" { name = \"heredoc_policy\" path = \"/\" description = \"An example policy\" policy = \"${data.aws_iam_policy_document.heredoc.json}\" } and reimport the existing policy into the modified policy $terraform import aws_iam_policy.heredoc arn:aws:iam::122121212:policy/heredoc_policy and then re-plan. This should come back saying the policy is identical. You can also use templates to create your policies but the data resource is the easiest way. Trust relationship Allows other accounts to access resources in your account https://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles_create_for-user.html This policy attached to a role allows ECS containers to talk to the ecs-tasks endpoint: data \"aws_iam_policy_document\" \"assume_role_policy\" { statement { actions = [ \"sts:AssumeRole\" ] principals { type = \"Service\" identifiers = [ \"ecs-tasks.amazonaws.com\" ] } } } Attaching policy to a role When you use policies you might hear a lot about 2 types of policies: Unmanaged/inline policy Inline policies are child objects of a role or user, and don't count in your account limit. They are good for creating policies that are not for re-use. A policy with a single responsibility or use. In Terraform you can use an aws_iam_role_policy resource to create an inline policy on a role: resource \"aws_iam_role_policy\" \"inline_policy\" { name = \"AWSCodePipelineServiceRole-${data.aws_region.current.name}-${var.name}\" role = aws_iam_role . pipeline . id policy = <<POLICY { .... } You can still use a data.aws_iam_policy_document . Managed Policy Managed policies have to be attached to users or groups, and go be attached to multiple IAM roles or users. resource \"aws_iam_policy\" \"pipeline\" { name = \"AWSCodePipelineServiceRole-${data.aws_region.current.name}-${var.name}\" description = var . description path = var . policypath policy = <<POLICY { .... } This policy still isn't associated or attached to your role. A policy is attached with an aws_iam_role_policy_attachment resource. resource \"aws_iam_role_policy_attachment\" \"pipeline\" { role = aws_iam_role . pipeline . name policy_arn = aws_iam_policy . pipeline . arn } Issues with attaching policies Attaching a user to a group inline policy on a role/group Create a role Assuming a role Instance profiles Tip Seeing the changes in a policy Before Terraform 0.12, when you Terraform planned it was very difficult to be sure that there was any change, the output was unlear. ~ module.codebuild.aws_iam_role_policy.codebuild_policy policy: \"{\\n \\\"Version\\\": \\\"2012-10-17\\\",\\n \\\"Statement\\\": [\\n {\\n \\\"Sid\\\": \\\"\\\",\\n \\\"Effect\\\": \\\"Allow\\\",\\n \\\"Action\\\": \\\"*\\\",\\n \\\"Resource\\\": [\\n \\\"arn:aws:s3:::aws-lexbot-handler-553700203877-artifacts/*\\\",\\n \\\"arn:aws:s3:::aws-lexbot-handler-553700203877-artifacts\\\"\\n ]\\n },\\n {\\n \\\"Sid\\\": \\\"\\\",\\n \\\"Effect\\\": \\\"Allow\\\",\\n \\\"Action\\\": \\\"codebuild:*\\\",\\n \\\"Resource\\\": \\\"arn:aws:codebuild:eu-west-1:553700203877:project/aws-lexbot-handler\\\"\\n },\\n {\\n \\\"Sid\\\": \\\"\\\",\\n \\\"Effect\\\": \\\"Allow\\\",\\n \\\"Action\\\": [\\n \\\"ssm:PutParameter\\\",\\n \\\"ssm:GetParameters\\\"\\n ],\\n \\\"Resource\\\": \\\"*\\\"\\n },\\n {\\n \\\"Sid\\\": \\\"\\\",\\n \\\"Effect\\\": \\\"Allow\\\",\\n \\\"Action\\\": [\\n \\\"logs:PutLogEvents\\\",\\n \\\"logs:CreateLogStream\\\",\\n \\\"logs:CreateLogGroup\\\"\\n ],\\n \\\"Resource\\\": \\\"*\\\"\\n },\\n {\\n \\\"Sid\\\": \\\"\\\",\\n \\\"Effect\\\": \\\"Allow\\\",\\n \\\"Action\\\": [\\n \\\"iam:PassRole\\\",\\n \\\"iam:ListRoles\\\"\\n ],\\n \\\"Resource\\\": \\\"*\\\"\\n }\\n ]\\n}\" = > \"{\\n \\\"Version\\\": \\\"2012-10-17\\\",\\n \\\"Statement\\\": [\\n {\\n \\\"Sid\\\": \\\"\\\",\\n \\\"Effect\\\": \\\"Allow\\\",\\n \\\"Action\\\": \\\"*\\\", \\n \\\"Resource\\\": [\\n \\\"arn:aws:s3:::aws-lexbot-handler-553700203877-artifacts/*\\\",\\n \\\"arn:aws:s3:::aws-lexbot-handler-553700203877-artifacts\\\"\\n ]\\n },\\n {\\n \\\"Sid\\\": \\\"\\\",\\n \\\"Effect\\\": \\\"Allow\\\",\\n \\\"Action\\\": \\\"codebuild:*\\\",\\n \\\"Resource\\\": \\\"*\\\"\\n },\\n {\\n \\\"Sid\\\": \\\"\\\",\\n \\\"Effect\\\": \\\"Allow\\\",\\n \\\"Action\\\": \\\"ecr:*\\\",\\n \\\"Resource\\\": \\\"*\\\"\\n },\\n {\\n \\\"Sid\\\": \\\"\\\",\\n \\\"Effect\\\": \\\"Allow\\\",\\n \\\"Action\\\": [\\n \\\"ssm:PutParameter\\\",\\n \\\"ssm:GetParameters\\\"\\n ],\\n \\\"Resource\\\": \\\"*\\\"\\n },\\n {\\n \\\"Sid\\\": \\\"\\\",\\n \\\"Effect\\\": \\\"Allow\\\",\\n \\\"Action\\\": [\\n \\\"logs:PutLogEvents\\\",\\n \\\"logs:CreateLogStream\\\",\\n \\\"logs:CreateLogGroup\\\"\\n ],\\n \\\"Resource\\\": \\\"*\\\"\\n },\\n {\\n \\\"Sid\\\": \\\"\\\",\\n \\\"Effect\\\": \\\"Allow\\\",\\n \\\"Action\\\": [\\n \\\"iam:PassRole\\\",\\n \\\"iam:ListRoles\\\"\\n ],\\n \\\"Resource\\\": \\\"*\\\"\\n }\\n ]\\n}\" There aren't actually any differences. Well it takes a bit of effort with a prettifier to be sure. Extras assume roles and remote_state todo assume roles and provider todo","title":"AWS"},{"location":"aws-iam/#managing-iam-with-terraform","text":"","title":"Managing IAM with Terraform"},{"location":"aws-iam/#aws-iam-identity-access-management","text":"Json based roles, user and policies. This is the authentication scheme at the heart of AWS.","title":"AWS IAM - Identity Access Management"},{"location":"aws-iam/#create-a-policy-with-heredoc","text":"IAM policies can be added via the console either using the AWS wizards or as JSON files. You can add a Json policy in directly to your terraform policy if you use a HEREDOC. A Heredoc allows you to paste in a multiline string. aws_iam_policy.heredoc.tf below is an example of using a Heredoc in a policy statement. resource \"aws_iam_policy\" \"heredoc\" { name = \"heredoc_policy\" path = \"/\" description = \"An example policy\" policy = <<HEREDOC { \"Version\": \"2012-10-17\" , \"Statement\" : [ { \"Action\" : [ \"ec2:*\" ], \"Effect\": \"Allow\" , \"Resource\": \"*\" } ] } HEREDOC } This will create a managed but unattached IAM policy. Create a scaffold iam_policy and make the policy $ scaffold iam_policy git clone --depth = 1 git@github.com:JamesWoolfenden/tf-scaffold.git iam_policy Cloning into 'iam_policy' ... remote: Enumerating objects: 11 , done . remote: Counting objects: 100 % ( 11 /11 ) , done . remote: Compressing objects: 100 % ( 8 /8 ) , done . remote: Total 11 ( delta 0 ) , reused 6 ( delta 0 ) , pack-reused 0 Receiving objects: 100 % ( 11 /11 ) , done . You can check the policy creation in UI or via the cli. $ aws iam get-policy --policy-arn arn:aws:iam::122121221:policy/heredoc_policy { \"Policy\" : { \"PolicyName\" : \"heredoc_policy\" , \"PolicyId\" : \"xxxxxxxxxxxxxxx\" , \"Arn\" : \"arn:aws:iam::122121221:policy/heredoc_policy\" , \"Path\" : \"/\" , \"DefaultVersionId\" : \"v1\" , \"AttachmentCount\" : 0 , \"PermissionsBoundaryUsageCount\" : 0 , \"IsAttachable\" : true, \"Description\" : \"An example policy\" , \"CreateDate\" : \"2019-04-06T22:05:51Z\" , \"UpdateDate\" : \"2019-04-06T22:05:51Z\" } } That's the old way of making a policy, you can now use data resources to build policies in Terraform. The previous example can rewritten with a data.aws_iam_policy_document data resource. Now delete your state file. Add data.aws_policy_document.heredoc.tf data \"aws_iam_policy_document\" \"heredoc\" { statement { actions = [ \"ec2:*\" , ] resources = [ \"*\" , ] } } And modify the policy resource to use this data resource. resource \"aws_iam_policy\" \"heredoc\" { name = \"heredoc_policy\" path = \"/\" description = \"An example policy\" policy = \"${data.aws_iam_policy_document.heredoc.json}\" } and reimport the existing policy into the modified policy $terraform import aws_iam_policy.heredoc arn:aws:iam::122121212:policy/heredoc_policy and then re-plan. This should come back saying the policy is identical. You can also use templates to create your policies but the data resource is the easiest way.","title":"Create a policy with HEREDOC"},{"location":"aws-iam/#trust-relationship","text":"Allows other accounts to access resources in your account https://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles_create_for-user.html This policy attached to a role allows ECS containers to talk to the ecs-tasks endpoint: data \"aws_iam_policy_document\" \"assume_role_policy\" { statement { actions = [ \"sts:AssumeRole\" ] principals { type = \"Service\" identifiers = [ \"ecs-tasks.amazonaws.com\" ] } } }","title":"Trust relationship"},{"location":"aws-iam/#attaching-policy-to-a-role","text":"When you use policies you might hear a lot about 2 types of policies: Unmanaged/inline policy Inline policies are child objects of a role or user, and don't count in your account limit. They are good for creating policies that are not for re-use. A policy with a single responsibility or use. In Terraform you can use an aws_iam_role_policy resource to create an inline policy on a role: resource \"aws_iam_role_policy\" \"inline_policy\" { name = \"AWSCodePipelineServiceRole-${data.aws_region.current.name}-${var.name}\" role = aws_iam_role . pipeline . id policy = <<POLICY { .... } You can still use a data.aws_iam_policy_document . Managed Policy Managed policies have to be attached to users or groups, and go be attached to multiple IAM roles or users. resource \"aws_iam_policy\" \"pipeline\" { name = \"AWSCodePipelineServiceRole-${data.aws_region.current.name}-${var.name}\" description = var . description path = var . policypath policy = <<POLICY { .... } This policy still isn't associated or attached to your role. A policy is attached with an aws_iam_role_policy_attachment resource. resource \"aws_iam_role_policy_attachment\" \"pipeline\" { role = aws_iam_role . pipeline . name policy_arn = aws_iam_policy . pipeline . arn } Issues with attaching policies","title":"Attaching policy to a role"},{"location":"aws-iam/#attaching-a-user-to-a-group","text":"","title":"Attaching a user to a group"},{"location":"aws-iam/#inline-policy-on-a-rolegroup","text":"Create a role","title":"inline policy on a role/group"},{"location":"aws-iam/#assuming-a-role","text":"","title":"Assuming a role"},{"location":"aws-iam/#instance-profiles","text":"Tip Seeing the changes in a policy Before Terraform 0.12, when you Terraform planned it was very difficult to be sure that there was any change, the output was unlear. ~ module.codebuild.aws_iam_role_policy.codebuild_policy policy: \"{\\n \\\"Version\\\": \\\"2012-10-17\\\",\\n \\\"Statement\\\": [\\n {\\n \\\"Sid\\\": \\\"\\\",\\n \\\"Effect\\\": \\\"Allow\\\",\\n \\\"Action\\\": \\\"*\\\",\\n \\\"Resource\\\": [\\n \\\"arn:aws:s3:::aws-lexbot-handler-553700203877-artifacts/*\\\",\\n \\\"arn:aws:s3:::aws-lexbot-handler-553700203877-artifacts\\\"\\n ]\\n },\\n {\\n \\\"Sid\\\": \\\"\\\",\\n \\\"Effect\\\": \\\"Allow\\\",\\n \\\"Action\\\": \\\"codebuild:*\\\",\\n \\\"Resource\\\": \\\"arn:aws:codebuild:eu-west-1:553700203877:project/aws-lexbot-handler\\\"\\n },\\n {\\n \\\"Sid\\\": \\\"\\\",\\n \\\"Effect\\\": \\\"Allow\\\",\\n \\\"Action\\\": [\\n \\\"ssm:PutParameter\\\",\\n \\\"ssm:GetParameters\\\"\\n ],\\n \\\"Resource\\\": \\\"*\\\"\\n },\\n {\\n \\\"Sid\\\": \\\"\\\",\\n \\\"Effect\\\": \\\"Allow\\\",\\n \\\"Action\\\": [\\n \\\"logs:PutLogEvents\\\",\\n \\\"logs:CreateLogStream\\\",\\n \\\"logs:CreateLogGroup\\\"\\n ],\\n \\\"Resource\\\": \\\"*\\\"\\n },\\n {\\n \\\"Sid\\\": \\\"\\\",\\n \\\"Effect\\\": \\\"Allow\\\",\\n \\\"Action\\\": [\\n \\\"iam:PassRole\\\",\\n \\\"iam:ListRoles\\\"\\n ],\\n \\\"Resource\\\": \\\"*\\\"\\n }\\n ]\\n}\" = > \"{\\n \\\"Version\\\": \\\"2012-10-17\\\",\\n \\\"Statement\\\": [\\n {\\n \\\"Sid\\\": \\\"\\\",\\n \\\"Effect\\\": \\\"Allow\\\",\\n \\\"Action\\\": \\\"*\\\", \\n \\\"Resource\\\": [\\n \\\"arn:aws:s3:::aws-lexbot-handler-553700203877-artifacts/*\\\",\\n \\\"arn:aws:s3:::aws-lexbot-handler-553700203877-artifacts\\\"\\n ]\\n },\\n {\\n \\\"Sid\\\": \\\"\\\",\\n \\\"Effect\\\": \\\"Allow\\\",\\n \\\"Action\\\": \\\"codebuild:*\\\",\\n \\\"Resource\\\": \\\"*\\\"\\n },\\n {\\n \\\"Sid\\\": \\\"\\\",\\n \\\"Effect\\\": \\\"Allow\\\",\\n \\\"Action\\\": \\\"ecr:*\\\",\\n \\\"Resource\\\": \\\"*\\\"\\n },\\n {\\n \\\"Sid\\\": \\\"\\\",\\n \\\"Effect\\\": \\\"Allow\\\",\\n \\\"Action\\\": [\\n \\\"ssm:PutParameter\\\",\\n \\\"ssm:GetParameters\\\"\\n ],\\n \\\"Resource\\\": \\\"*\\\"\\n },\\n {\\n \\\"Sid\\\": \\\"\\\",\\n \\\"Effect\\\": \\\"Allow\\\",\\n \\\"Action\\\": [\\n \\\"logs:PutLogEvents\\\",\\n \\\"logs:CreateLogStream\\\",\\n \\\"logs:CreateLogGroup\\\"\\n ],\\n \\\"Resource\\\": \\\"*\\\"\\n },\\n {\\n \\\"Sid\\\": \\\"\\\",\\n \\\"Effect\\\": \\\"Allow\\\",\\n \\\"Action\\\": [\\n \\\"iam:PassRole\\\",\\n \\\"iam:ListRoles\\\"\\n ],\\n \\\"Resource\\\": \\\"*\\\"\\n }\\n ]\\n}\" There aren't actually any differences. Well it takes a bit of effort with a prettifier to be sure.","title":"Instance profiles"},{"location":"aws-iam/#extras","text":"assume roles and remote_state todo assume roles and provider todo","title":"Extras"},{"location":"aws-instance/","text":"Creating an EC2 Instance Make an instance in a public subnet Open your shell again and get a new scaffold: scaffold aws_instance add aws_instance.web.tf to the new scaffold. resource \"aws_instance\" \"web\" { ami = \"ami-12345678\" instance_type = \"t2.micro\" tags = var . common_tags } Rather than hard-coding the AMI like above, a better and more maintainable way it to get the latest AMI made of that type: Adding an ami data source is a better way, like this one for ubuntu xenial data.aws_ami.xenial.tf : data \"aws_ami\" \"xenial\" { most_recent = true owners = [ \"099720109477\" ] filter { name = \"name\" values = [ \"ubuntu/images/*ubuntu-xenial-16.04-amd64-server-*\" ] } filter { name = \"root-device-type\" values = [ \"ebs\" ] } filter { name = \"virtualization-type\" values = [ \"hvm\" ] } } Then update the AMI reference in aws_instance to: ami = data . aws_ami . xenial . id If you apply now the latest xenial AMI will start, and as just about every other property isn't specified it will use the defaults for VPC, Subnet and Security Group. + aws_instance . web id: <computed> ami: \"ami-01bc69b830b49f729\" arn: <computed> associate_public_ip_address: <computed> availability_zone: <computed> cpu_core_count: <computed> cpu_threads_per_core: <computed> ebs_block_device . #: <computed> ephemeral_block_device . #: <computed> get_password_data: \"false\" host_id: <computed> instance_state: <computed> instance_type: \"t2.micro\" ipv 6 _address_count: <computed> ipv 6 _addresses . #: <computed> key_name: <computed> network_interface . #: <computed> network_interface_id: <computed> password_data: <computed> placement_group: <computed> primary_network_interface_id: <computed> private_dns: <computed> private_ip: <computed> public_dns: <computed> public_ip: <computed> root_block_device . #: <computed> security_groups . #: <computed> source_dest_check: \"true\" subnet_id: <computed> tags . %: \"1\" tags . createdby: \"Terraform\" tenancy: <computed> volume_tags . %: <computed> vpc_security_group_ids . #: <computed> Specify an SSH key The currently provisioned instance has no access as no SSH key was specified, you can manually upload your ssh key to AWS or automatically provision one. Create an SSH key by adding tls_private_key.ssh.tf resource \"tls_private_key\" \"ssh\" { algorithm = \"RSA\" rsa_bits = \"2048\" } and add a new provider for tls provider.tls.tf : provider tls { version = \"2.1.1\" } Add the generated key to AWS with aws_key_pair.ssh.tf resource \"aws_key_pair\" \"ssh\" { key_name = \"id_rsa\" public_key = tls_private_key . ssh . public_key_openssh } To SSH in you'll need the private key, get the key pair with local_file.ssh-key.tf : resource \"local_file\" \"pem-private\" { content = tls_private_key . ssh . private_key_pem filename = \"${path.cwd}/id_rsa\" } resource \"local_file\" \"ssh-public\" { content = tls_private_key . ssh . public_key_openssh filename = \"${path.cwd}/id_rsa.pub\" } This needs a provider for file provider.local.tf : provider local { version = \"1.4\" } Update the aws_instance resource to link to the new key: resource aws_instance web { ami = data . aws_ami . xenial . id instance_type = \"t2.micro\" tags = var . common_tags key_name = aws_key_pair . ssh . key_name } And a Secruity group that allows access: resource aws_security_group ssh { name = \"allow-ssh\" ingress { cidr_blocks = [ \"0.0.0.0/0\" ] from_port = 22 to_port = 22 protocol = \"tcp\" } egress { from_port = 0 to_port = 0 protocol = \"-1\" cidr_blocks = [ \"0.0.0.0/0\" ] } } Warning In the ingress I use a CIDR of \"0.0.0.0/0\", which is wide open to the world. Id normally restrict this my own IP. You could also make the Ingress group optional and deprovision it all together at a later date. and finally add update outputs.tf to get the public to get the Public ip to SSH into. output public_ip { value = aws_instance . web . public_ip } Apply the above changes: See the created key files id_rsa and id_rsa.pub and test by SSHing into new instance. $ ls -l total 32 -rwxrwxrwx 1 jim jim 406 Oct 22 10 : 13 Makefile -rwxrwxrwx 1 jim jim 2701 Oct 22 10 : 13 README . md -rwxrwxrwx 1 jim jim 46 Oct 22 10 : 13 aws_instance . auto . tfvars -rwxrwxrwx 1 jim jim 189 Nov 5 14 : 15 aws_instance . web . tf -rwxrwxrwx 1 jim jim 114 Nov 5 14 : 01 aws_key_pair . ssh . tf -rwxrwxrwx 1 jim jim 289 Nov 5 14 : 14 aws_security . ssh . tf -rwxrwxrwx 1 jim jim 345 Oct 22 10 : 13 data . aws_ami . xenial . tf -rwxrwxrwx 1 jim jim 1675 Nov 5 14 : 23 id_rsa -rwxrwxrwx 1 jim jim 381 Nov 5 14 : 23 id_rsa . pub -rwxrwxrwx 1 jim jim 260 Nov 5 14 : 01 local_file . ssh-key . tf -rwxrwxrwx 1 jim jim 35 Oct 22 10 : 13 main . tf -rwxrwxrwx 1 jim jim 59 Nov 5 14 : 21 outputs . tf -rwxrwxrwx 1 jim jim 68 Nov 5 10 : 17 provider . aws . tf -rwxrwxrwx 1 jim jim 38 Nov 5 14 : 13 provider . local . tf -rwxrwxrwx 1 jim jim 38 Nov 5 13 : 57 provider . tls . tf -rwxrwxrwx 1 jim jim 15355 Nov 5 14 : 24 terraform . tfstate -rwxrwxrwx 1 jim jim 5920 Nov 5 14 : 23 terraform . tfstate . backup -rwxrwxrwx 1 jim jim 80 Nov 5 13 : 44 tls_private_key . ssh . tf -rwxrwxrwx 1 jim jim 120 Oct 22 10 : 13 variables . tf Warning Do not add keys to Git Info Run \"Terraform destroy\" to cleanup.","title":"AWS"},{"location":"aws-instance/#creating-an-ec2-instance","text":"","title":"Creating an EC2 Instance"},{"location":"aws-instance/#make-an-instance-in-a-public-subnet","text":"Open your shell again and get a new scaffold: scaffold aws_instance add aws_instance.web.tf to the new scaffold. resource \"aws_instance\" \"web\" { ami = \"ami-12345678\" instance_type = \"t2.micro\" tags = var . common_tags } Rather than hard-coding the AMI like above, a better and more maintainable way it to get the latest AMI made of that type: Adding an ami data source is a better way, like this one for ubuntu xenial data.aws_ami.xenial.tf : data \"aws_ami\" \"xenial\" { most_recent = true owners = [ \"099720109477\" ] filter { name = \"name\" values = [ \"ubuntu/images/*ubuntu-xenial-16.04-amd64-server-*\" ] } filter { name = \"root-device-type\" values = [ \"ebs\" ] } filter { name = \"virtualization-type\" values = [ \"hvm\" ] } } Then update the AMI reference in aws_instance to: ami = data . aws_ami . xenial . id If you apply now the latest xenial AMI will start, and as just about every other property isn't specified it will use the defaults for VPC, Subnet and Security Group. + aws_instance . web id: <computed> ami: \"ami-01bc69b830b49f729\" arn: <computed> associate_public_ip_address: <computed> availability_zone: <computed> cpu_core_count: <computed> cpu_threads_per_core: <computed> ebs_block_device . #: <computed> ephemeral_block_device . #: <computed> get_password_data: \"false\" host_id: <computed> instance_state: <computed> instance_type: \"t2.micro\" ipv 6 _address_count: <computed> ipv 6 _addresses . #: <computed> key_name: <computed> network_interface . #: <computed> network_interface_id: <computed> password_data: <computed> placement_group: <computed> primary_network_interface_id: <computed> private_dns: <computed> private_ip: <computed> public_dns: <computed> public_ip: <computed> root_block_device . #: <computed> security_groups . #: <computed> source_dest_check: \"true\" subnet_id: <computed> tags . %: \"1\" tags . createdby: \"Terraform\" tenancy: <computed> volume_tags . %: <computed> vpc_security_group_ids . #: <computed>","title":"Make an instance in a public subnet"},{"location":"aws-instance/#specify-an-ssh-key","text":"The currently provisioned instance has no access as no SSH key was specified, you can manually upload your ssh key to AWS or automatically provision one. Create an SSH key by adding tls_private_key.ssh.tf resource \"tls_private_key\" \"ssh\" { algorithm = \"RSA\" rsa_bits = \"2048\" } and add a new provider for tls provider.tls.tf : provider tls { version = \"2.1.1\" } Add the generated key to AWS with aws_key_pair.ssh.tf resource \"aws_key_pair\" \"ssh\" { key_name = \"id_rsa\" public_key = tls_private_key . ssh . public_key_openssh } To SSH in you'll need the private key, get the key pair with local_file.ssh-key.tf : resource \"local_file\" \"pem-private\" { content = tls_private_key . ssh . private_key_pem filename = \"${path.cwd}/id_rsa\" } resource \"local_file\" \"ssh-public\" { content = tls_private_key . ssh . public_key_openssh filename = \"${path.cwd}/id_rsa.pub\" } This needs a provider for file provider.local.tf : provider local { version = \"1.4\" } Update the aws_instance resource to link to the new key: resource aws_instance web { ami = data . aws_ami . xenial . id instance_type = \"t2.micro\" tags = var . common_tags key_name = aws_key_pair . ssh . key_name } And a Secruity group that allows access: resource aws_security_group ssh { name = \"allow-ssh\" ingress { cidr_blocks = [ \"0.0.0.0/0\" ] from_port = 22 to_port = 22 protocol = \"tcp\" } egress { from_port = 0 to_port = 0 protocol = \"-1\" cidr_blocks = [ \"0.0.0.0/0\" ] } } Warning In the ingress I use a CIDR of \"0.0.0.0/0\", which is wide open to the world. Id normally restrict this my own IP. You could also make the Ingress group optional and deprovision it all together at a later date. and finally add update outputs.tf to get the public to get the Public ip to SSH into. output public_ip { value = aws_instance . web . public_ip } Apply the above changes: See the created key files id_rsa and id_rsa.pub and test by SSHing into new instance. $ ls -l total 32 -rwxrwxrwx 1 jim jim 406 Oct 22 10 : 13 Makefile -rwxrwxrwx 1 jim jim 2701 Oct 22 10 : 13 README . md -rwxrwxrwx 1 jim jim 46 Oct 22 10 : 13 aws_instance . auto . tfvars -rwxrwxrwx 1 jim jim 189 Nov 5 14 : 15 aws_instance . web . tf -rwxrwxrwx 1 jim jim 114 Nov 5 14 : 01 aws_key_pair . ssh . tf -rwxrwxrwx 1 jim jim 289 Nov 5 14 : 14 aws_security . ssh . tf -rwxrwxrwx 1 jim jim 345 Oct 22 10 : 13 data . aws_ami . xenial . tf -rwxrwxrwx 1 jim jim 1675 Nov 5 14 : 23 id_rsa -rwxrwxrwx 1 jim jim 381 Nov 5 14 : 23 id_rsa . pub -rwxrwxrwx 1 jim jim 260 Nov 5 14 : 01 local_file . ssh-key . tf -rwxrwxrwx 1 jim jim 35 Oct 22 10 : 13 main . tf -rwxrwxrwx 1 jim jim 59 Nov 5 14 : 21 outputs . tf -rwxrwxrwx 1 jim jim 68 Nov 5 10 : 17 provider . aws . tf -rwxrwxrwx 1 jim jim 38 Nov 5 14 : 13 provider . local . tf -rwxrwxrwx 1 jim jim 38 Nov 5 13 : 57 provider . tls . tf -rwxrwxrwx 1 jim jim 15355 Nov 5 14 : 24 terraform . tfstate -rwxrwxrwx 1 jim jim 5920 Nov 5 14 : 23 terraform . tfstate . backup -rwxrwxrwx 1 jim jim 80 Nov 5 13 : 44 tls_private_key . ssh . tf -rwxrwxrwx 1 jim jim 120 Oct 22 10 : 13 variables . tf Warning Do not add keys to Git Info Run \"Terraform destroy\" to cleanup.","title":"Specify an SSH key"},{"location":"aws-rds/","text":"Creating an Relation Database Service (RDS) instance with Terraform RDS is one of the managed database services on AWS, many of the most common relational databases can be easily provisioned via RDS, including MySQL, Oracle and SQL Server. Getting Started Again we start with a new Scaffold. $ scaffold RDS-starter git clone --depth=1 git@github.com:JamesWoolfenden/tf-scaffold.git RDS-starter Cloning into 'RDS-starter'... remote: Enumerating objects: 11, done. remote: Counting objects: 100% (11/11), done. remote: Compressing objects: 100% (8/8), done. remote: Total 11 (delta 0), reused 6 (delta 0), pack-reused 0 Receiving objects: 100% (11/11), done. Now that you have the scaffold you can add your components. Provision a basic RDS instance Add this RDS resource to RDS-starter as aws_db_instance.employee.tf resource \"aws_db_instance\" \"employee\" { allocated_storage = 20 storage_type = \"gp2\" engine = \"mysql\" engine_version = \"5.7\" instance_class = \"db.t2.micro\" name = \"mydb\" skip_final_snapshot = true publicly_accessible = false username = \"Sleepycat\" password = \"thr33littlew0rds\" parameter_group_name = \"default.mysql5.7\" } And try out the template: $ terraform plan An execution plan has been generated and is shown below. Resource actions are indicated with the following symbols: + create Terraform will perform the following actions: + aws_db_instance.employee id: <computed> address: <computed> allocated_storage: \"20\" apply_immediately: <computed> arn: <computed> auto_minor_version_upgrade: \"true\" availability_zone: <computed> backup_retention_period: <computed> backup_window: <computed> ca_cert_identifier: <computed> character_set_name: <computed> copy_tags_to_snapshot: \"false\" db_subnet_group_name: <computed> endpoint: <computed> engine: \"mysql\" engine_version: \"5.7\" hosted_zone_id: <computed> identifier: <computed> identifier_prefix: <computed> instance_class: \"db.t2.micro\" kms_key_id: <computed> license_model: <computed> maintenance_window: <computed> monitoring_interval: \"0\" monitoring_role_arn: <computed> multi_az: <computed> name: \"employee\" option_group_name: <computed> parameter_group_name: \"default.mysql5.7\" password: <sensitive> port: <computed> publicly_accessible: \"false\" replicas.#: <computed> resource_id: <computed> skip_final_snapshot: \"false\" status: <computed> storage_type: \"gp2\" timezone: <computed> username: \"Sleepycat\" vpc_security_group_ids.#: <computed> Plan: 1 to add, 0 to change, 0 to destroy. Before you apply add an output to outputs.tf output \"endpoint\" { value = aws_db_instance . employee . endpoint } Applying that should succeed, mine took around 4mins in my testing, and finally the output of the DBs endpoint: endpoint = employee . ch 6 wpf 7 x 4 jbf . eu-west- 1 . rds . amazonaws . com: 3306 There are a large number of properties other than the ones we have supplied, so many defaults are being assumed. So far we haven't specified the VPC or even a Subnet. Provisioning will add your DB instance in with many of the defaults. Terraform displays that the instance has been provisioned, but we do need to verify. Testing DB Instance Get will need to get the client MySQL tools installed: choco install mysql-cli or brew install mysql Now connecting to the instance is the proof: $ mysql -h employee.ch6wpf7x4jbf.eu-west-1.rds.amazonaws.com -P 3306 -u Sleepycat -p Enter password: **************** Welcome to the MySQL monitor. Commands end with ; or \\g. Your MySQL connection id is 6 Server version: 5.7.23 Source distribution Copyright (c) 2000, 2018, Oracle and/or its affiliates. All rights reserved. Oracle is a registered trademark of Oracle Corporation and/or its affiliates. Other names may be trademarks of their respective owners. Type 'help;' or '\\h' for help. Type '\\c' to clear the current input statement. mysql> Now you have a connected SQL prompt so you can run your now SQL against the db. Warning Earlier I set a property - publicly_accessible=\"true\" that made your db public, we wouldn't normally allow a db to be public. Multiple DBs How can I provision 2 databases of the same type? This is done by using the count variable and adding it to your resource: count = \"2\" Additionally you will need to change the name so that it can be unique. name = \"employee${count.index}\" When you plan again, it now raises this issue: * output . endpoint: Resource 'aws_db_instance . employee' not found for variable 'aws_db_instance . employee . endpoint' This is because aws_db_instance.employee is now a list, the output reference now needs to support the blat array reference like this: aws_db_instance.employee.*.endpoint Now try plan again and you'll find this plans just fine but it but you'll see that it will make 2 databases instances. Links Sample data from https://dev.mysql.com/doc/employee/en/employees-installation.html Terraform RDS https://www.terraform.io/docs/providers/aws/r/db_instance.html AWS RDS terraform module example https://github.com/terraform-aws-modules/terraform-aws-rds/tree/master/examples/complete-mysql Warning Delete you DB's and Clusters after you've finished as they cost \u00a3\u00a3\u00a3\u00a3","title":"RDS"},{"location":"aws-rds/#creating-an-relation-database-service-rds-instance-with-terraform","text":"RDS is one of the managed database services on AWS, many of the most common relational databases can be easily provisioned via RDS, including MySQL, Oracle and SQL Server.","title":"Creating an Relation Database Service (RDS) instance with Terraform"},{"location":"aws-rds/#getting-started","text":"Again we start with a new Scaffold. $ scaffold RDS-starter git clone --depth=1 git@github.com:JamesWoolfenden/tf-scaffold.git RDS-starter Cloning into 'RDS-starter'... remote: Enumerating objects: 11, done. remote: Counting objects: 100% (11/11), done. remote: Compressing objects: 100% (8/8), done. remote: Total 11 (delta 0), reused 6 (delta 0), pack-reused 0 Receiving objects: 100% (11/11), done. Now that you have the scaffold you can add your components.","title":"Getting Started"},{"location":"aws-rds/#provision-a-basic-rds-instance","text":"Add this RDS resource to RDS-starter as aws_db_instance.employee.tf resource \"aws_db_instance\" \"employee\" { allocated_storage = 20 storage_type = \"gp2\" engine = \"mysql\" engine_version = \"5.7\" instance_class = \"db.t2.micro\" name = \"mydb\" skip_final_snapshot = true publicly_accessible = false username = \"Sleepycat\" password = \"thr33littlew0rds\" parameter_group_name = \"default.mysql5.7\" } And try out the template: $ terraform plan An execution plan has been generated and is shown below. Resource actions are indicated with the following symbols: + create Terraform will perform the following actions: + aws_db_instance.employee id: <computed> address: <computed> allocated_storage: \"20\" apply_immediately: <computed> arn: <computed> auto_minor_version_upgrade: \"true\" availability_zone: <computed> backup_retention_period: <computed> backup_window: <computed> ca_cert_identifier: <computed> character_set_name: <computed> copy_tags_to_snapshot: \"false\" db_subnet_group_name: <computed> endpoint: <computed> engine: \"mysql\" engine_version: \"5.7\" hosted_zone_id: <computed> identifier: <computed> identifier_prefix: <computed> instance_class: \"db.t2.micro\" kms_key_id: <computed> license_model: <computed> maintenance_window: <computed> monitoring_interval: \"0\" monitoring_role_arn: <computed> multi_az: <computed> name: \"employee\" option_group_name: <computed> parameter_group_name: \"default.mysql5.7\" password: <sensitive> port: <computed> publicly_accessible: \"false\" replicas.#: <computed> resource_id: <computed> skip_final_snapshot: \"false\" status: <computed> storage_type: \"gp2\" timezone: <computed> username: \"Sleepycat\" vpc_security_group_ids.#: <computed> Plan: 1 to add, 0 to change, 0 to destroy. Before you apply add an output to outputs.tf output \"endpoint\" { value = aws_db_instance . employee . endpoint } Applying that should succeed, mine took around 4mins in my testing, and finally the output of the DBs endpoint: endpoint = employee . ch 6 wpf 7 x 4 jbf . eu-west- 1 . rds . amazonaws . com: 3306 There are a large number of properties other than the ones we have supplied, so many defaults are being assumed. So far we haven't specified the VPC or even a Subnet. Provisioning will add your DB instance in with many of the defaults. Terraform displays that the instance has been provisioned, but we do need to verify.","title":"Provision a basic RDS instance"},{"location":"aws-rds/#testing-db-instance","text":"Get will need to get the client MySQL tools installed: choco install mysql-cli or brew install mysql Now connecting to the instance is the proof: $ mysql -h employee.ch6wpf7x4jbf.eu-west-1.rds.amazonaws.com -P 3306 -u Sleepycat -p Enter password: **************** Welcome to the MySQL monitor. Commands end with ; or \\g. Your MySQL connection id is 6 Server version: 5.7.23 Source distribution Copyright (c) 2000, 2018, Oracle and/or its affiliates. All rights reserved. Oracle is a registered trademark of Oracle Corporation and/or its affiliates. Other names may be trademarks of their respective owners. Type 'help;' or '\\h' for help. Type '\\c' to clear the current input statement. mysql> Now you have a connected SQL prompt so you can run your now SQL against the db.","title":"Testing DB Instance"},{"location":"aws-rds/#warning","text":"Earlier I set a property - publicly_accessible=\"true\" that made your db public, we wouldn't normally allow a db to be public.","title":"Warning"},{"location":"aws-rds/#multiple-dbs","text":"How can I provision 2 databases of the same type? This is done by using the count variable and adding it to your resource: count = \"2\" Additionally you will need to change the name so that it can be unique. name = \"employee${count.index}\" When you plan again, it now raises this issue: * output . endpoint: Resource 'aws_db_instance . employee' not found for variable 'aws_db_instance . employee . endpoint' This is because aws_db_instance.employee is now a list, the output reference now needs to support the blat array reference like this: aws_db_instance.employee.*.endpoint Now try plan again and you'll find this plans just fine but it but you'll see that it will make 2 databases instances.","title":"Multiple DBs"},{"location":"aws-rds/#links","text":"Sample data from https://dev.mysql.com/doc/employee/en/employees-installation.html Terraform RDS https://www.terraform.io/docs/providers/aws/r/db_instance.html AWS RDS terraform module example https://github.com/terraform-aws-modules/terraform-aws-rds/tree/master/examples/complete-mysql Warning Delete you DB's and Clusters after you've finished as they cost \u00a3\u00a3\u00a3\u00a3","title":"Links"},{"location":"aws-s3/","text":"Creating an S3 bucket with Terraform One of the oldest components of AWS - S3 is easily provisionable. Starting off with a new scaffold: $scaffold aws_bucket and then add aws_s3_bucket.Hyacinth.tf resource \"aws_s3_bucket\" \"hyacinth\" { bucket = \"hyacinth-bucket\" acl = \"private\" tags = var . common_tags } And Apply. You can easily check its creation with the AWS cli, or the console if you must. $aws s3 ls hyacinth-bucket Nothing else will be seen as the bucket is currently empty. An S3 bucket comes with a large number of configuration possibilities, from hosting a website to data lake. But there is one type of S3 bucket that we always need on an AWS Terraform project, and that's a State bucket. Making a State bucket Replace the contents of the S3 Terraform file from the previous step, with: resource \"aws_s3_bucket\" \"statebucket\" { bucket = \"${data.aws_caller_identity.current.account_id}-terraform-state\" acl = \"private\" force_destroy = \"false\" versioning { enabled = true mfa_delete = true } tags = var . common_tags } Note Notice that this is a private bucket and that it has versioning and delete protection. Add the file data.aws_caller_identity.current.tf to return the AWS account number. data \"aws_caller_identity\" \"current\" {} and the file aws_dynamodb_table.dynamodb-state-lock.tf , to help stop concurrent writes. resource \"aws_dynamodb_table\" \"dynamodb-state-lock\" { name = \"dynamodb-state-lock\" hash_key = \"LockID\" read_capacity = 20 write_capacity = 20 point_in_time-recovery = enabled attribute { name = \"LockID\" type = \"S\" } tags = var . common_tags } With that applied, you will have an S3 locking and versioned Terraform State bucket, that you use for all your work. In this account. Don't share state buckets across accounts. DO NOT To fully implement you also need to add a reference file to all of your templates call it remote_state.tf , by using your account number and region, this bucket be different, it will be unique on a account basis. The property \"key\" must be different on every template. terraform { backend \"s3\" { encrypt = true bucket = \"${account_number}-terraform-state\" key = \"state-bucket/terraform.tfstate\" dynamodb_table = \"dynamodb-state-lock\" region = \"eu-west-1\" } } Managing globally unique names prefix with account number can always friendly name endpoint in DNS Note AWS Statebucket GCP Statebucket Azure Statebucket","title":"S3"},{"location":"aws-s3/#creating-an-s3-bucket-with-terraform","text":"One of the oldest components of AWS - S3 is easily provisionable. Starting off with a new scaffold: $scaffold aws_bucket and then add aws_s3_bucket.Hyacinth.tf resource \"aws_s3_bucket\" \"hyacinth\" { bucket = \"hyacinth-bucket\" acl = \"private\" tags = var . common_tags } And Apply. You can easily check its creation with the AWS cli, or the console if you must. $aws s3 ls hyacinth-bucket Nothing else will be seen as the bucket is currently empty. An S3 bucket comes with a large number of configuration possibilities, from hosting a website to data lake. But there is one type of S3 bucket that we always need on an AWS Terraform project, and that's a State bucket.","title":"Creating an S3 bucket with Terraform"},{"location":"aws-s3/#making-a-state-bucket","text":"Replace the contents of the S3 Terraform file from the previous step, with: resource \"aws_s3_bucket\" \"statebucket\" { bucket = \"${data.aws_caller_identity.current.account_id}-terraform-state\" acl = \"private\" force_destroy = \"false\" versioning { enabled = true mfa_delete = true } tags = var . common_tags } Note Notice that this is a private bucket and that it has versioning and delete protection. Add the file data.aws_caller_identity.current.tf to return the AWS account number. data \"aws_caller_identity\" \"current\" {} and the file aws_dynamodb_table.dynamodb-state-lock.tf , to help stop concurrent writes. resource \"aws_dynamodb_table\" \"dynamodb-state-lock\" { name = \"dynamodb-state-lock\" hash_key = \"LockID\" read_capacity = 20 write_capacity = 20 point_in_time-recovery = enabled attribute { name = \"LockID\" type = \"S\" } tags = var . common_tags } With that applied, you will have an S3 locking and versioned Terraform State bucket, that you use for all your work. In this account. Don't share state buckets across accounts. DO NOT To fully implement you also need to add a reference file to all of your templates call it remote_state.tf , by using your account number and region, this bucket be different, it will be unique on a account basis. The property \"key\" must be different on every template. terraform { backend \"s3\" { encrypt = true bucket = \"${account_number}-terraform-state\" key = \"state-bucket/terraform.tfstate\" dynamodb_table = \"dynamodb-state-lock\" region = \"eu-west-1\" } }","title":"Making a State bucket"},{"location":"aws-s3/#managing-globally-unique-names","text":"prefix with account number can always friendly name endpoint in DNS Note AWS Statebucket GCP Statebucket Azure Statebucket","title":"Managing globally unique names"},{"location":"aws-subnet/","text":"Creating a Subnet in AWS The Terraform below is almost the most minimal Terraform configuration to create one subnet. A subnet is a division of a VPC in one Availability Zone. There is therefore a dependency to a VPC & its vpc_id and it has a smaller CIDR block, here, of 256 IPs. Add this file aws_subnet.main.tf to your existing terraform in aws_vpc . resource \"aws_subnet\" \"main\" { vpc_id = aws_vpc . main . id cidr_block = \"10.0.1.0/24\" tags = var . common_tags } $ terraform apply ... Making one just one subnet is an unusual activity, as is not specifying the AvailabilityZone it is in or the Routes. It is more common to see (if your in a 3 zone region) a Private and Public Subnet for each availability zone in a Region. How many Availability Zones are there in this region? You could hard-code this a variable and put the strings in your Terraform.tfvars, fortunately there's a better dynamic way. Add data.tf to aws_vpc template. data \"aws_availability_zones\" \"available\" {} This data object captures a list of the availability zones in your current region. This can be used in other templates: data . aws_availability_zones . available . names Now lets replace the previous subnet file with: aws_subnets.public.tf resource \"aws_subnet\" \"public\" { count = length ( data . aws_availability_zones . available . names ) vpc_id = aws_vpc . main . id cidr_block = local . public_cidrs [ count . index ] availability_zone = data . aws_availability_zones . available . names [ count . index ] tags = merge ( var . common_tags , map ( \"Type\", \"Public\" ) } and add: locals.tf locals { public_cidrs = [ \"${cidrsubnet(\"${var.cidr}\", 3, 0)}\", \"${cidrsubnet(\"${var.cidr}\", 3, 1)}\", \"${cidrsubnet(\"${var.cidr}\", 3, 2)}\" ] } And Append variables.tf with: variable \"cidr\" { default = \"10.0.0.0/16\" } And update the vpc object to use the cidr variable cidr_block = var . cidr That's quite and lot different and dropped a whole heap of new stuff, so time for a review: Count count = length ( data . aws_availability_zones . available . names ) This makes as many of the object aws_subnet.public as length(data.aws_availability_zones.available.names) evaluates to. That'll depends on how many Availability Zones are in your region, but it'll probably be 3. Locals What is a local? You can't currently set the value of a variable as something dynamic or for that matter one that's calculated, but you can achieve the same thing with a local, as you can see above in locals.tf . This makes an array of cidrblocks based on var.cidr using a built in function cidrsubnet. This array then gets used with the indexer to give the CIDR ranges for each subnet. cidr_block = local . public_cidrs [ count . index ] Merging tags tags = merge ( var . common_tags , map ( \"Type\", \"Public\" ) This is just the syntax to a a new variable to a map, so this map now has an extra key/value pair Type=Public. So its time to test that syntax, with terraform init and plan So thats a VPC and and 3 \"Public\" subnets with 8192 IPS in each. There's a bit more to being Public Subnet So the Subnets may be called Public, but they still aren't. Routing So what make a subnet public? The subnet need to be connected to the Internet. A common way is to connect and route an Internet Gateway. Add in aws_internet_gateway.gw.tf resource \"aws_internet_gateway\" \"gw\" { vpc_id = aws_vpc . main . id } and then create a route and a route table with aws_route_table.public.tf resource \"aws_route_table\" \"public\" { vpc_id = aws_vpc . main . id tags = var . common_tags } resource \"aws_route\" \"public\" { route_table_id = aws_route_table . public . id destination_cidr_block = \"0.0.0.0/0\" gateway_id = aws_internet_gateway . gw . id } That's a complete set of public subnets. The next step would be to make a set of private subnets. But... Not only can you get Design patterns to create your base networking, but you can get the Terraform as well, written by the Platform itself, so as setting up the basic VPC structure in AWS is a solved problem, you can use one of a number of tried and tested designs from the registry: Note https://registry.terraform.io/modules/terraform-aws-modules/vpc/aws/1.60.0 has nearly 900k uses and rising, thats a lots of field testing and it saves a tonne of typing. https://docs.aws.amazon.com/vpc/latest/userguide/VPC_Scenario2.html","title":"AWS"},{"location":"aws-subnet/#creating-a-subnet-in-aws","text":"The Terraform below is almost the most minimal Terraform configuration to create one subnet. A subnet is a division of a VPC in one Availability Zone. There is therefore a dependency to a VPC & its vpc_id and it has a smaller CIDR block, here, of 256 IPs. Add this file aws_subnet.main.tf to your existing terraform in aws_vpc . resource \"aws_subnet\" \"main\" { vpc_id = aws_vpc . main . id cidr_block = \"10.0.1.0/24\" tags = var . common_tags } $ terraform apply ... Making one just one subnet is an unusual activity, as is not specifying the AvailabilityZone it is in or the Routes. It is more common to see (if your in a 3 zone region) a Private and Public Subnet for each availability zone in a Region. How many Availability Zones are there in this region? You could hard-code this a variable and put the strings in your Terraform.tfvars, fortunately there's a better dynamic way. Add data.tf to aws_vpc template. data \"aws_availability_zones\" \"available\" {} This data object captures a list of the availability zones in your current region. This can be used in other templates: data . aws_availability_zones . available . names Now lets replace the previous subnet file with: aws_subnets.public.tf resource \"aws_subnet\" \"public\" { count = length ( data . aws_availability_zones . available . names ) vpc_id = aws_vpc . main . id cidr_block = local . public_cidrs [ count . index ] availability_zone = data . aws_availability_zones . available . names [ count . index ] tags = merge ( var . common_tags , map ( \"Type\", \"Public\" ) } and add: locals.tf locals { public_cidrs = [ \"${cidrsubnet(\"${var.cidr}\", 3, 0)}\", \"${cidrsubnet(\"${var.cidr}\", 3, 1)}\", \"${cidrsubnet(\"${var.cidr}\", 3, 2)}\" ] } And Append variables.tf with: variable \"cidr\" { default = \"10.0.0.0/16\" } And update the vpc object to use the cidr variable cidr_block = var . cidr That's quite and lot different and dropped a whole heap of new stuff, so time for a review:","title":"Creating a Subnet in AWS"},{"location":"aws-subnet/#count","text":"count = length ( data . aws_availability_zones . available . names ) This makes as many of the object aws_subnet.public as length(data.aws_availability_zones.available.names) evaluates to. That'll depends on how many Availability Zones are in your region, but it'll probably be 3.","title":"Count"},{"location":"aws-subnet/#locals","text":"What is a local? You can't currently set the value of a variable as something dynamic or for that matter one that's calculated, but you can achieve the same thing with a local, as you can see above in locals.tf . This makes an array of cidrblocks based on var.cidr using a built in function cidrsubnet. This array then gets used with the indexer to give the CIDR ranges for each subnet. cidr_block = local . public_cidrs [ count . index ]","title":"Locals"},{"location":"aws-subnet/#merging-tags","text":"tags = merge ( var . common_tags , map ( \"Type\", \"Public\" ) This is just the syntax to a a new variable to a map, so this map now has an extra key/value pair Type=Public. So its time to test that syntax, with terraform init and plan So thats a VPC and and 3 \"Public\" subnets with 8192 IPS in each.","title":"Merging tags"},{"location":"aws-subnet/#theres-a-bit-more-to-being-public-subnet","text":"So the Subnets may be called Public, but they still aren't.","title":"There's a bit more to being Public Subnet"},{"location":"aws-subnet/#routing","text":"So what make a subnet public? The subnet need to be connected to the Internet. A common way is to connect and route an Internet Gateway. Add in aws_internet_gateway.gw.tf resource \"aws_internet_gateway\" \"gw\" { vpc_id = aws_vpc . main . id } and then create a route and a route table with aws_route_table.public.tf resource \"aws_route_table\" \"public\" { vpc_id = aws_vpc . main . id tags = var . common_tags } resource \"aws_route\" \"public\" { route_table_id = aws_route_table . public . id destination_cidr_block = \"0.0.0.0/0\" gateway_id = aws_internet_gateway . gw . id } That's a complete set of public subnets. The next step would be to make a set of private subnets. But... Not only can you get Design patterns to create your base networking, but you can get the Terraform as well, written by the Platform itself, so as setting up the basic VPC structure in AWS is a solved problem, you can use one of a number of tried and tested designs from the registry: Note https://registry.terraform.io/modules/terraform-aws-modules/vpc/aws/1.60.0 has nearly 900k uses and rising, thats a lots of field testing and it saves a tonne of typing. https://docs.aws.amazon.com/vpc/latest/userguide/VPC_Scenario2.html","title":"Routing"},{"location":"aws-vpc/","text":"Creating a Virtual Private Cloud Creating an Amazon VPC Creating A VPC with Terraform is fairly straight forward. A minimal functional example configuration is just: resource \"aws_vpc\" \"main\" { cidr_block = \"10.0.0.0/16\" tags = var . common_tags } Clone the terraform scaffold into aws_vpc . $ scaffold aws_vpc ... Add this file aws_vpc.main.tf to the a scaffold in aws_vpc. The only variable set, is your CIDR block, 10.0.0.0/16. 10.0.0.0/16 is a large range of ip addresses, it is more than adequate at 65536 IP addresses. https://www.ipaddressguide.com/cidr . Add the following environmental variables to your shell, replacing < yourregion > and either specify a profile or leave it as default. AWS_REGION = \"<yourregion>\" AWS_PROFILE = default Check the configuration with $ terraform init ... and then open your shell at ./aws_vpc : $ terraform plan ... An execution plan has been generated and is shown below . Resource actions are indicated with the following symbols: + create Terraform will perform the following actions: + aws_vpc . main id: <computed> arn: <computed> assign_generated_ipv 6 _cidr_block: \"false\" cidr_block: \"10.0.0.0/16\" default_network_acl_id: <computed> default_route_table_id: <computed> default_security_group_id: <computed> dhcp_options_id: <computed> enable_classiclink: <computed> enable_classiclink_dns_support: <computed> enable_dns_hostnames: <computed> enable_dns_support: \"true\" instance_tenancy: \"default\" ipv 6 _association_id: <computed> ipv 6 _cidr_block: <computed> main_route_table_id: <computed> owner_id: <computed> tags . %: \"1\" tags . createdby: \"Terraform\" Plan: 1 to add , 0 to change , 0 to destroy . If your plan looks like above then you can process with terraform apply, by default this now repeats a plan first and then asks you if you want to proceed: An execution plan has been generated and is shown below . Resource actions are indicated with the following symbols: + create Terraform will perform the following actions: + aws_vpc . main id: <computed> arn: <computed> assign_generated_ipv 6 _cidr_block: \"false\" cidr_block: \"10.0.0.0/16\" default_network_acl_id: <computed> default_route_table_id: <computed> default_security_group_id: <computed> dhcp_options_id: <computed> enable_classiclink: <computed> enable_classiclink_dns_support: <computed> enable_dns_hostnames: <computed> enable_dns_support: \"true\" instance_tenancy: \"dedicated\" ipv 6 _association_id: <computed> ipv 6 _cidr_block: <computed> main_route_table_id: <computed> owner_id: <computed> tags . %: \"1\" tags . Name: \"Terraform\" Plan: 1 to add , 0 to change , 0 to destroy . Do you want to perform these actions? Terraform will perform the actions described above . Only 'yes' will be accepted to approve . Enter a value: Enter yes if you want to make the VPC . Enter a value: yes aws_vpc . main: Creating ... arn: \"\" = > \"<computed>\" assign_generated_ipv6_cidr_block: \"\" = > \"false\" cidr_block: \"\" = > \"10.0.0.0/16\" default_network_acl_id: \"\" = > \"<computed>\" default_route_table_id: \"\" = > \"<computed>\" default_security_group_id: \"\" = > \"<computed>\" dhcp_options_id: \"\" = > \"<computed>\" enable_classiclink: \"\" = > \"<computed>\" enable_classiclink_dns_support: \"\" = > \"<computed>\" enable_dns_hostnames: \"\" = > \"<computed>\" enable_dns_support: \"\" = > \"true\" instance_tenancy: \"\" = > \"dedicated\" ipv6_association_id: \"\" = > \"<computed>\" ipv6_cidr_block: \"\" = > \"<computed>\" main_route_table_id: \"\" = > \"<computed>\" owner_id: \"\" = > \"<computed>\" tags.%: \"\" = > \"1\" tags.Name: \"\" = > \"Terraform\" aws_vpc . main: Creation complete after 4 s ( ID: vpc- 0382578 ed 3 cd 51 dcc ) Apply complete! Resources: 1 added , 0 changed , 0 destroyed . Now you have a VPC, and not much else. Open up the AWS console vpc page: https://eu-west-1.console.aws.amazon.com/vpc/home?region=eu-west-1#vpcs:sort=VpcId Add key createby with a value - your full name. Now rerun and verify the desired state. $ terraform plan aws_vpc . main: Refreshing state ... ( ID: vpc- 0382578 ed 3 cd 51 dcc ) ------------------------------------------------------------------------ An execution plan has been generated and is shown below . Resource actions are indicated with the following symbols: ~ update in-place Terraform will perform the following actions: ~ aws_vpc . main tags.%: \"2\" = > \"1\" tags.createdby: \"JamesWoolfenden\" = > \"\" Plan: 0 to add , 1 to change , 0 to destroy . ------------------------------------------------------------------------ Note: You didn't specify an \"-out\" parameter to save this plan , so Terraform can't guarantee that exactly these actions will be performed if \"terraform apply\" is subsequently run . The plan tells us that there is 1 more tags on the infrastructure than in our TF \"desired state\". We have a choice, enforce the desired state or update the state. $ Terraform apply ... Eliminates the drift so there is only 1 tag. Now that we are done with the example we should tidy up and remove what's provisioned. This is straight forward enough, when your finished with this VPC run: $ terraform destroy aws_vpc . main: Refreshing state ... ( ID: vpc- 0382578 ed 3 cd 51 dcc ) An execution plan has been generated and is shown below . Resource actions are indicated with the following symbols: - destroy Terraform will perform the following actions: - aws_vpc . main Plan: 0 to add , 0 to change , 1 to destroy . Do you really want to destroy all resources? Terraform will destroy all your managed infrastructure , as shown above . There is no undo . Only 'yes' will be accepted to confirm . Enter a value: Then enter yes Enter a value: yes aws_vpc . main: Destroying ... ( ID: vpc- 0382578 ed 3 cd 51 dcc ) aws_vpc . main: Destruction complete after 0 s Destroy complete! Resources: 1 destroyed . Now in AWS were back to as if we hadn't started. So to recap, we made a VPC, checked for drift, fixed the drift and then cleaned up our environment by destroying all our provisioned infrastructure. Scaffold revisited Along with the structure for the template a couple of other files arrived. These are useful if you are going to turn the folder into a git repository. .gitignore This contains a minimal gitignore with Terraform customizations. .pre-commit-config.yaml The is the config file to support the pre-commit framework, it can help enforce good repository security and health. This config contains rules to protect your secrets. This is this repos pre-commit configuration. --- # yamllint disable rule:indentation repos: - repo: git://github.com/pre-commit/pre-commit-hooks rev: v 2.4 . 0 hooks: - id: trailing-whitespace - id: end-of-file-fixer - id: check-added-large-files - repo: git://github.com/Lucas-C/pre-commit-hooks rev: v 1.1 . 7 hooks: - id: forbid-tabs exclude_types: [ python , javascript , dtd , markdown , makefile ] exclude: binary|\\.bin$ - repo: git://github.com/kintoandar/pre-commit.git rev: v 2.1 . 0 hooks: - id: terraform_fmt - repo: git://github.com/pre-commit/pre-commit-hooks rev: v 2.4 . 0 hooks: - id: detect-aws-credentials - id: detect-private-key - repo: https://github.com/detailyang/pre-commit-shell rev: 1.0 . 5 hooks: - id: shell-lint - repo: git://github.com/igorshubovych/markdownlint-cli rev: v 0.19 . 0 hooks: - id: markdownlint - repo: git://github.com/adrienverge/yamllint rev: v 1.18 . 0 hooks: - id: yamllint name: yamllint description: This hook runs yamllint. entry: yamllint language: python types: [ file , yaml ] - repo: git://github.com/prettier/prettier rev: 1.18 . 2 hooks: - id: prettier Makefile There is also is a default Makefile for running Terraform #Makefile .PHONY : all all : init plan build init : rm -rf .terraform/modules/ terraform init -reconfigure plan : init terraform plan -refresh = true build : init terraform apply -auto-approve check : init terraform plan -detailed-exitcode destroy : init terraform destroy -force docs : terraform-docs md . > README.md valid : tflint terraform fmt -check = true -diff = true If you plan to turn this folder into a repo you need to install the config (at the root of the repo) with: $ pre-commit install pre-commit installed at . \\. git \\h ooks \\p re-commit Note Tf-scaffold https://github.com/JamesWoolfenden/tf-scaffold Help documents for Terraform AWS Virtual Private Cloud ( VPC ) object are here < https : // www . terraform . io / docs / providers / aws / r / vpc . html > VPC designs < https : // docs . aws . amazon . com / vpc / latest / userguide / VPC_Scenarios . html >","title":"AWS"},{"location":"aws-vpc/#creating-a-virtual-private-cloud","text":"","title":"Creating a Virtual Private Cloud"},{"location":"aws-vpc/#creating-an-amazon-vpc","text":"Creating A VPC with Terraform is fairly straight forward. A minimal functional example configuration is just: resource \"aws_vpc\" \"main\" { cidr_block = \"10.0.0.0/16\" tags = var . common_tags } Clone the terraform scaffold into aws_vpc . $ scaffold aws_vpc ... Add this file aws_vpc.main.tf to the a scaffold in aws_vpc. The only variable set, is your CIDR block, 10.0.0.0/16. 10.0.0.0/16 is a large range of ip addresses, it is more than adequate at 65536 IP addresses. https://www.ipaddressguide.com/cidr . Add the following environmental variables to your shell, replacing < yourregion > and either specify a profile or leave it as default. AWS_REGION = \"<yourregion>\" AWS_PROFILE = default Check the configuration with $ terraform init ... and then open your shell at ./aws_vpc : $ terraform plan ... An execution plan has been generated and is shown below . Resource actions are indicated with the following symbols: + create Terraform will perform the following actions: + aws_vpc . main id: <computed> arn: <computed> assign_generated_ipv 6 _cidr_block: \"false\" cidr_block: \"10.0.0.0/16\" default_network_acl_id: <computed> default_route_table_id: <computed> default_security_group_id: <computed> dhcp_options_id: <computed> enable_classiclink: <computed> enable_classiclink_dns_support: <computed> enable_dns_hostnames: <computed> enable_dns_support: \"true\" instance_tenancy: \"default\" ipv 6 _association_id: <computed> ipv 6 _cidr_block: <computed> main_route_table_id: <computed> owner_id: <computed> tags . %: \"1\" tags . createdby: \"Terraform\" Plan: 1 to add , 0 to change , 0 to destroy . If your plan looks like above then you can process with terraform apply, by default this now repeats a plan first and then asks you if you want to proceed: An execution plan has been generated and is shown below . Resource actions are indicated with the following symbols: + create Terraform will perform the following actions: + aws_vpc . main id: <computed> arn: <computed> assign_generated_ipv 6 _cidr_block: \"false\" cidr_block: \"10.0.0.0/16\" default_network_acl_id: <computed> default_route_table_id: <computed> default_security_group_id: <computed> dhcp_options_id: <computed> enable_classiclink: <computed> enable_classiclink_dns_support: <computed> enable_dns_hostnames: <computed> enable_dns_support: \"true\" instance_tenancy: \"dedicated\" ipv 6 _association_id: <computed> ipv 6 _cidr_block: <computed> main_route_table_id: <computed> owner_id: <computed> tags . %: \"1\" tags . Name: \"Terraform\" Plan: 1 to add , 0 to change , 0 to destroy . Do you want to perform these actions? Terraform will perform the actions described above . Only 'yes' will be accepted to approve . Enter a value: Enter yes if you want to make the VPC . Enter a value: yes aws_vpc . main: Creating ... arn: \"\" = > \"<computed>\" assign_generated_ipv6_cidr_block: \"\" = > \"false\" cidr_block: \"\" = > \"10.0.0.0/16\" default_network_acl_id: \"\" = > \"<computed>\" default_route_table_id: \"\" = > \"<computed>\" default_security_group_id: \"\" = > \"<computed>\" dhcp_options_id: \"\" = > \"<computed>\" enable_classiclink: \"\" = > \"<computed>\" enable_classiclink_dns_support: \"\" = > \"<computed>\" enable_dns_hostnames: \"\" = > \"<computed>\" enable_dns_support: \"\" = > \"true\" instance_tenancy: \"\" = > \"dedicated\" ipv6_association_id: \"\" = > \"<computed>\" ipv6_cidr_block: \"\" = > \"<computed>\" main_route_table_id: \"\" = > \"<computed>\" owner_id: \"\" = > \"<computed>\" tags.%: \"\" = > \"1\" tags.Name: \"\" = > \"Terraform\" aws_vpc . main: Creation complete after 4 s ( ID: vpc- 0382578 ed 3 cd 51 dcc ) Apply complete! Resources: 1 added , 0 changed , 0 destroyed . Now you have a VPC, and not much else. Open up the AWS console vpc page: https://eu-west-1.console.aws.amazon.com/vpc/home?region=eu-west-1#vpcs:sort=VpcId Add key createby with a value - your full name. Now rerun and verify the desired state. $ terraform plan aws_vpc . main: Refreshing state ... ( ID: vpc- 0382578 ed 3 cd 51 dcc ) ------------------------------------------------------------------------ An execution plan has been generated and is shown below . Resource actions are indicated with the following symbols: ~ update in-place Terraform will perform the following actions: ~ aws_vpc . main tags.%: \"2\" = > \"1\" tags.createdby: \"JamesWoolfenden\" = > \"\" Plan: 0 to add , 1 to change , 0 to destroy . ------------------------------------------------------------------------ Note: You didn't specify an \"-out\" parameter to save this plan , so Terraform can't guarantee that exactly these actions will be performed if \"terraform apply\" is subsequently run . The plan tells us that there is 1 more tags on the infrastructure than in our TF \"desired state\". We have a choice, enforce the desired state or update the state. $ Terraform apply ... Eliminates the drift so there is only 1 tag. Now that we are done with the example we should tidy up and remove what's provisioned. This is straight forward enough, when your finished with this VPC run: $ terraform destroy aws_vpc . main: Refreshing state ... ( ID: vpc- 0382578 ed 3 cd 51 dcc ) An execution plan has been generated and is shown below . Resource actions are indicated with the following symbols: - destroy Terraform will perform the following actions: - aws_vpc . main Plan: 0 to add , 0 to change , 1 to destroy . Do you really want to destroy all resources? Terraform will destroy all your managed infrastructure , as shown above . There is no undo . Only 'yes' will be accepted to confirm . Enter a value: Then enter yes Enter a value: yes aws_vpc . main: Destroying ... ( ID: vpc- 0382578 ed 3 cd 51 dcc ) aws_vpc . main: Destruction complete after 0 s Destroy complete! Resources: 1 destroyed . Now in AWS were back to as if we hadn't started. So to recap, we made a VPC, checked for drift, fixed the drift and then cleaned up our environment by destroying all our provisioned infrastructure.","title":"Creating an Amazon VPC"},{"location":"aws-vpc/#scaffold-revisited","text":"Along with the structure for the template a couple of other files arrived. These are useful if you are going to turn the folder into a git repository.","title":"Scaffold revisited"},{"location":"aws-vpc/#gitignore","text":"This contains a minimal gitignore with Terraform customizations.","title":".gitignore"},{"location":"aws-vpc/#pre-commit-configyaml","text":"The is the config file to support the pre-commit framework, it can help enforce good repository security and health. This config contains rules to protect your secrets. This is this repos pre-commit configuration. --- # yamllint disable rule:indentation repos: - repo: git://github.com/pre-commit/pre-commit-hooks rev: v 2.4 . 0 hooks: - id: trailing-whitespace - id: end-of-file-fixer - id: check-added-large-files - repo: git://github.com/Lucas-C/pre-commit-hooks rev: v 1.1 . 7 hooks: - id: forbid-tabs exclude_types: [ python , javascript , dtd , markdown , makefile ] exclude: binary|\\.bin$ - repo: git://github.com/kintoandar/pre-commit.git rev: v 2.1 . 0 hooks: - id: terraform_fmt - repo: git://github.com/pre-commit/pre-commit-hooks rev: v 2.4 . 0 hooks: - id: detect-aws-credentials - id: detect-private-key - repo: https://github.com/detailyang/pre-commit-shell rev: 1.0 . 5 hooks: - id: shell-lint - repo: git://github.com/igorshubovych/markdownlint-cli rev: v 0.19 . 0 hooks: - id: markdownlint - repo: git://github.com/adrienverge/yamllint rev: v 1.18 . 0 hooks: - id: yamllint name: yamllint description: This hook runs yamllint. entry: yamllint language: python types: [ file , yaml ] - repo: git://github.com/prettier/prettier rev: 1.18 . 2 hooks: - id: prettier","title":".pre-commit-config.yaml"},{"location":"aws-vpc/#makefile","text":"There is also is a default Makefile for running Terraform #Makefile .PHONY : all all : init plan build init : rm -rf .terraform/modules/ terraform init -reconfigure plan : init terraform plan -refresh = true build : init terraform apply -auto-approve check : init terraform plan -detailed-exitcode destroy : init terraform destroy -force docs : terraform-docs md . > README.md valid : tflint terraform fmt -check = true -diff = true If you plan to turn this folder into a repo you need to install the config (at the root of the repo) with: $ pre-commit install pre-commit installed at . \\. git \\h ooks \\p re-commit Note Tf-scaffold https://github.com/JamesWoolfenden/tf-scaffold Help documents for Terraform AWS Virtual Private Cloud ( VPC ) object are here < https : // www . terraform . io / docs / providers / aws / r / vpc . html > VPC designs < https : // docs . aws . amazon . com / vpc / latest / userguide / VPC_Scenarios . html >","title":"Makefile"},{"location":"consul/","text":"Consul TODO","title":"Consul"},{"location":"consul/#consul","text":"TODO","title":"Consul"},{"location":"control/","text":"Repository Patterns How should my Infra code be structured In Git permissions, access, branching and PRS are set-up on a repository basis. What can you reasonable manage as an owner/contributor should shape the structure. What is a \"manageable piece of infrastructure\"? There is no one answer, it depends on the project aims and the situation you start in. Your IAC will use a combination of these approaches.ld Each folder should be directly run-able by Terraform: environment\\eu-west-1\\test$ terraform apply ... Branching Code submitted to master via PRS on very short lived feature branches, or trunk based development. Don't branch by environment. Branching with state references is difficult/hazardous. Landing Zone Pattern When to use: To set up an account for use by applications, to control account level resources e.g. VPC, security. \u2514\u2500\u2500\u2500environments \u2514\u2500\u2500\u2500eu-west-1 \u251c\u2500\u2500\u2500dev \u2514\u2500\u2500\u2500test main.auto.tfvars main.tf Makefile outputs.tf provider.aws.tf README.md variables.tf Pros One project to rule them all. Simple in design. Cons Slow to apply, update, some account level infra is very slow to create, change or destroy. Partial destroying of an account is risky. Whole account apply is risky, unless you plan first. Destroying whole environments at this level can often make little sense. Harder for multiple people to work on at once Lack of isolation, 2 or more developers working on same environment. Not simple in practice. Ops like. Very Controlling. It's not really CI if you have a confirm an apply. For many account level objects destroying them, rarely practical makes sense (AD, IAM, AD, Cloudtrail and other Security related resources) Nuclear level blast radius. Note Should never contain module code. Separation Pattern When to use: Some objects are neither the landing Zone nor a single services application code. Each environment/workspace ' ' has a build process and life-cycle. \u251c\u2500\u2500\u2500eks \u2502 \u2514\u2500\u2500\u2500eu-west-1 \u2502 \u251c\u2500\u2500\u2500dev <eks-region-dev> \u2502 \u2502 main.auto.tfvars \u2502 \u2502 main.tf \u2502 \u2502 Makefile \u2502 \u2502 outputs.tf \u2502 \u2502 provider.aws.tf \u2502 \u2502 README.md \u2502 \u2502 variables.tf \u2502 \u2502 \u2502 \u2514\u2500\u2500\u2500test <eks-region-test> \u2514\u2500\u2500\u2500elasticsearch \u2514\u2500\u2500\u2500eu-west-1 \u251c\u2500\u2500\u2500dev <elasticsearch-region-dev> \u2502 main.auto.tfvars \u2502 main.tf \u2502 Makefile \u2502 outputs.tf \u2502 provider.aws.tf \u2502 README.md \u2502 variables.tf \u2502 \u2514\u2500\u2500\u2500test <elasticsearch-region-test> Pros Change is isolated Blast radius limited Cons Requires Invocation of multiple workspaces to make an environment. Duplication of properties. Note Should never contain module code. Workspace Builds can be chained. Application Pattern When to use: For development teams to manage their own applications infrastructure, infrastructure code lives alongside application code. In DevOps, we empower development teams, so for dev teams to modify and manage. It could be Terraform, Pulumi https://www.pulumi.com/ , Serverless https://serverless.com/https://serverless.com/ or SAM https://docs.aws.amazon.com/serverless-application-model/latest/developerguide/what-is-sam.html the structure should still be something like: \u251c\u2500\u2500\u2500iac \u2502 \u251c\u2500\u2500\u2500lambda \u2502 \u2502 \u251c\u2500\u2500\u2500dev \u2502 \u2502 \u2502 main.auto.tfvars \u2502 \u2502 \u2502 main.tf \u2502 \u2502 \u2502 Makefile \u2502 \u2502 \u2502 outputs.tf \u2502 \u2502 \u2502 provider.aws.tf \u2502 \u2502 \u2502 README.md \u2502 \u2502 \u2502 variables.tf \u2502 \u2502 \u2502 \u2502 \u2502 \u2514\u2500\u2500\u2500test \u2502 \u2514\u2500\u2500\u2500service \u2502 \u251c\u2500\u2500\u2500dev \u2502 \u2502 main.auto.tfvars \u2502 \u2502 main.tf \u2502 \u2502 Makefile \u2502 \u2502 outputs.tf \u2502 \u2502 provider.aws.tf \u2502 \u2502 README.md \u2502 \u2502 variables.tf \u2502 \u2502 \u2502 \u2514\u2500\u2500\u2500test \u2514\u2500\u2500\u2500src Pros Run infra provisioning as part of your deployment process. Isolated changes.n Access control. Cons Duplication of properties across multi application Note Should never contain module code. Module Pattern When to use: Once you've created a reusable module, it should reside in a separate repository, so that it is a manageable and reusable component with ots own life-cycle. A module should always contain an example implementation and documentation. Repositories are named after their purpose and technology terraform-<PROVIDER>-<NAME> . Versioning uses the Semantic scheme. Below is the layout for a module for activemq \u2514\u2500\u2500\u2500terraform-aws-activemq \u2502 .gitattributes \u2502 .gitignore \u2502 .markdownlint.json \u2502 .markdownlintrc \u2502 .pre-commit-config.yaml \u2502 .terraformignore \u2502 aws_mq_broker.broker.tf \u2502 aws_mq_configuration.broker.tf \u2502 aws_security_group.broker.tf \u2502 LICENSE \u2502 main.tf \u2502 outputs.tf \u2502 password.tf \u2502 README.md \u2502 validate.ps1 \u2502 validate.sh \u2502 variables.tf \u2502 \u251c\u2500\u2500\u2500.chglog \u2502 CHANGELOG.tpl.md \u2502 config.yml \u2502 \u251c\u2500\u2500\u2500.dependabot \u2502 config.yml \u2502 \u251c\u2500\u2500\u2500.github \u2502 \u2514\u2500\u2500\u2500workflows \u2502 main.yml \u2502 \u2514\u2500\u2500\u2500example \u2514\u2500\u2500\u2500examplea data.network.tf examplea.auto.tfvars Makefile module.broker.tf outputs.tf provider.aws.tf variables.tf Cons None Pros Simple. Module has own life-cycle, versioning and testing process. Re-use by design. Allows you to fix module versions across environments and promote a module through an applications stages.","title":"Structure"},{"location":"control/#repository-patterns","text":"","title":"Repository Patterns"},{"location":"control/#how-should-my-infra-code-be-structured","text":"In Git permissions, access, branching and PRS are set-up on a repository basis. What can you reasonable manage as an owner/contributor should shape the structure. What is a \"manageable piece of infrastructure\"? There is no one answer, it depends on the project aims and the situation you start in. Your IAC will use a combination of these approaches.ld Each folder should be directly run-able by Terraform: environment\\eu-west-1\\test$ terraform apply ...","title":"How should my Infra code be structured"},{"location":"control/#branching","text":"Code submitted to master via PRS on very short lived feature branches, or trunk based development. Don't branch by environment. Branching with state references is difficult/hazardous.","title":"Branching"},{"location":"control/#landing-zone-pattern","text":"When to use: To set up an account for use by applications, to control account level resources e.g. VPC, security. \u2514\u2500\u2500\u2500environments \u2514\u2500\u2500\u2500eu-west-1 \u251c\u2500\u2500\u2500dev \u2514\u2500\u2500\u2500test main.auto.tfvars main.tf Makefile outputs.tf provider.aws.tf README.md variables.tf","title":"Landing Zone Pattern"},{"location":"control/#pros","text":"One project to rule them all. Simple in design.","title":"Pros"},{"location":"control/#cons","text":"Slow to apply, update, some account level infra is very slow to create, change or destroy. Partial destroying of an account is risky. Whole account apply is risky, unless you plan first. Destroying whole environments at this level can often make little sense. Harder for multiple people to work on at once Lack of isolation, 2 or more developers working on same environment. Not simple in practice. Ops like. Very Controlling. It's not really CI if you have a confirm an apply. For many account level objects destroying them, rarely practical makes sense (AD, IAM, AD, Cloudtrail and other Security related resources) Nuclear level blast radius. Note Should never contain module code.","title":"Cons"},{"location":"control/#separation-pattern","text":"When to use: Some objects are neither the landing Zone nor a single services application code. Each environment/workspace ' ' has a build process and life-cycle. \u251c\u2500\u2500\u2500eks \u2502 \u2514\u2500\u2500\u2500eu-west-1 \u2502 \u251c\u2500\u2500\u2500dev <eks-region-dev> \u2502 \u2502 main.auto.tfvars \u2502 \u2502 main.tf \u2502 \u2502 Makefile \u2502 \u2502 outputs.tf \u2502 \u2502 provider.aws.tf \u2502 \u2502 README.md \u2502 \u2502 variables.tf \u2502 \u2502 \u2502 \u2514\u2500\u2500\u2500test <eks-region-test> \u2514\u2500\u2500\u2500elasticsearch \u2514\u2500\u2500\u2500eu-west-1 \u251c\u2500\u2500\u2500dev <elasticsearch-region-dev> \u2502 main.auto.tfvars \u2502 main.tf \u2502 Makefile \u2502 outputs.tf \u2502 provider.aws.tf \u2502 README.md \u2502 variables.tf \u2502 \u2514\u2500\u2500\u2500test <elasticsearch-region-test>","title":"Separation Pattern"},{"location":"control/#pros_1","text":"Change is isolated Blast radius limited","title":"Pros"},{"location":"control/#cons_1","text":"Requires Invocation of multiple workspaces to make an environment. Duplication of properties. Note Should never contain module code. Workspace Builds can be chained.","title":"Cons"},{"location":"control/#application-pattern","text":"When to use: For development teams to manage their own applications infrastructure, infrastructure code lives alongside application code. In DevOps, we empower development teams, so for dev teams to modify and manage. It could be Terraform, Pulumi https://www.pulumi.com/ , Serverless https://serverless.com/https://serverless.com/ or SAM https://docs.aws.amazon.com/serverless-application-model/latest/developerguide/what-is-sam.html the structure should still be something like: \u251c\u2500\u2500\u2500iac \u2502 \u251c\u2500\u2500\u2500lambda \u2502 \u2502 \u251c\u2500\u2500\u2500dev \u2502 \u2502 \u2502 main.auto.tfvars \u2502 \u2502 \u2502 main.tf \u2502 \u2502 \u2502 Makefile \u2502 \u2502 \u2502 outputs.tf \u2502 \u2502 \u2502 provider.aws.tf \u2502 \u2502 \u2502 README.md \u2502 \u2502 \u2502 variables.tf \u2502 \u2502 \u2502 \u2502 \u2502 \u2514\u2500\u2500\u2500test \u2502 \u2514\u2500\u2500\u2500service \u2502 \u251c\u2500\u2500\u2500dev \u2502 \u2502 main.auto.tfvars \u2502 \u2502 main.tf \u2502 \u2502 Makefile \u2502 \u2502 outputs.tf \u2502 \u2502 provider.aws.tf \u2502 \u2502 README.md \u2502 \u2502 variables.tf \u2502 \u2502 \u2502 \u2514\u2500\u2500\u2500test \u2514\u2500\u2500\u2500src","title":"Application Pattern"},{"location":"control/#pros_2","text":"Run infra provisioning as part of your deployment process. Isolated changes.n Access control.","title":"Pros"},{"location":"control/#cons_2","text":"Duplication of properties across multi application Note Should never contain module code.","title":"Cons"},{"location":"control/#module-pattern","text":"When to use: Once you've created a reusable module, it should reside in a separate repository, so that it is a manageable and reusable component with ots own life-cycle. A module should always contain an example implementation and documentation. Repositories are named after their purpose and technology terraform-<PROVIDER>-<NAME> . Versioning uses the Semantic scheme. Below is the layout for a module for activemq \u2514\u2500\u2500\u2500terraform-aws-activemq \u2502 .gitattributes \u2502 .gitignore \u2502 .markdownlint.json \u2502 .markdownlintrc \u2502 .pre-commit-config.yaml \u2502 .terraformignore \u2502 aws_mq_broker.broker.tf \u2502 aws_mq_configuration.broker.tf \u2502 aws_security_group.broker.tf \u2502 LICENSE \u2502 main.tf \u2502 outputs.tf \u2502 password.tf \u2502 README.md \u2502 validate.ps1 \u2502 validate.sh \u2502 variables.tf \u2502 \u251c\u2500\u2500\u2500.chglog \u2502 CHANGELOG.tpl.md \u2502 config.yml \u2502 \u251c\u2500\u2500\u2500.dependabot \u2502 config.yml \u2502 \u251c\u2500\u2500\u2500.github \u2502 \u2514\u2500\u2500\u2500workflows \u2502 main.yml \u2502 \u2514\u2500\u2500\u2500example \u2514\u2500\u2500\u2500examplea data.network.tf examplea.auto.tfvars Makefile module.broker.tf outputs.tf provider.aws.tf variables.tf","title":"Module Pattern"},{"location":"control/#cons_3","text":"None","title":"Cons"},{"location":"control/#pros_3","text":"Simple. Module has own life-cycle, versioning and testing process. Re-use by design. Allows you to fix module versions across environments and promote a module through an applications stages.","title":"Pros"},{"location":"dns/","text":"DNS TODO","title":"DNS"},{"location":"dns/#dns","text":"TODO","title":"DNS"},{"location":"docker/","text":"Docker TODO","title":"Docker"},{"location":"docker/#docker","text":"TODO","title":"Docker"},{"location":"examples/","text":"Examples All the examples in this site are available from the Source Repo: https://github.com/JamesWoolfenden/learn-terraform/tree/master/examples git clone --depth 1 git@github.com:JamesWoolfenden/learn-terraform.git The Examples are in the Examples Sub-directory. ```powershell tab=\"Powershell\" $ls .\\examples\\ Directory: C:\\code\\mkdocs\\terraform\\examples Mode LastWriteTime Length Name ---- ------------- ------ ---- d----- 22/10/2019 10:13 aws_alb d----- 22/10/2019 10:13 aws_bucket d----- 05/11/2019 10:34 aws_instance d----- 22/10/2019 10:13 aws_vpc d----- 01/11/2019 14:41 aws_vpc_subnet d----- 03/11/2019 18:04 basic-aws-auth d----- 03/11/2019 17:53 basic-gcp-auth d----- 04/11/2019 22:41 gcp_vpc d----- 03/11/2019 16:36 gcp_vpc_with_subnet d----- 22/10/2019 10:13 iam_policy d----- 22/10/2019 10:13 inline_policy d----- 22/10/2019 10:13 RDS-starter d----- 22/10/2019 10:13 trust_relationship ```bash tab=\"*nix\" $ ls -l total 0 drwxrwxrwx 1 jim jim 512 Oct 22 10:13 RDS-starter drwxrwxrwx 1 jim jim 512 Oct 22 10:13 aws_alb drwxrwxrwx 1 jim jim 512 Oct 22 10:13 aws_bucket drwxrwxrwx 1 jim jim 512 Nov 5 10:34 aws_instance drwxrwxrwx 1 jim jim 512 Oct 22 10:13 aws_vpc drwxrwxrwx 1 jim jim 512 Nov 1 14:41 aws_vpc_subnet drwxrwxrwx 1 jim jim 512 Nov 3 18:04 basic-aws-auth drwxrwxrwx 1 jim jim 512 Nov 3 17:53 basic-gcp-auth drwxrwxrwx 1 jim jim 512 Nov 4 22:41 gcp_vpc drwxrwxrwx 1 jim jim 512 Nov 3 16:36 gcp_vpc_with_subnet drwxrwxrwx 1 jim jim 512 Oct 22 10:13 iam_policy drwxrwxrwx 1 jim jim 512 Oct 22 10:13 inline_policy drwxrwxrwx 1 jim jim 512 Oct 22 10:13 trust_relationship","title":"Examples"},{"location":"examples/#examples","text":"All the examples in this site are available from the Source Repo: https://github.com/JamesWoolfenden/learn-terraform/tree/master/examples git clone --depth 1 git@github.com:JamesWoolfenden/learn-terraform.git The Examples are in the Examples Sub-directory. ```powershell tab=\"Powershell\" $ls .\\examples\\ Directory: C:\\code\\mkdocs\\terraform\\examples Mode LastWriteTime Length Name ---- ------------- ------ ---- d----- 22/10/2019 10:13 aws_alb d----- 22/10/2019 10:13 aws_bucket d----- 05/11/2019 10:34 aws_instance d----- 22/10/2019 10:13 aws_vpc d----- 01/11/2019 14:41 aws_vpc_subnet d----- 03/11/2019 18:04 basic-aws-auth d----- 03/11/2019 17:53 basic-gcp-auth d----- 04/11/2019 22:41 gcp_vpc d----- 03/11/2019 16:36 gcp_vpc_with_subnet d----- 22/10/2019 10:13 iam_policy d----- 22/10/2019 10:13 inline_policy d----- 22/10/2019 10:13 RDS-starter d----- 22/10/2019 10:13 trust_relationship ```bash tab=\"*nix\" $ ls -l total 0 drwxrwxrwx 1 jim jim 512 Oct 22 10:13 RDS-starter drwxrwxrwx 1 jim jim 512 Oct 22 10:13 aws_alb drwxrwxrwx 1 jim jim 512 Oct 22 10:13 aws_bucket drwxrwxrwx 1 jim jim 512 Nov 5 10:34 aws_instance drwxrwxrwx 1 jim jim 512 Oct 22 10:13 aws_vpc drwxrwxrwx 1 jim jim 512 Nov 1 14:41 aws_vpc_subnet drwxrwxrwx 1 jim jim 512 Nov 3 18:04 basic-aws-auth drwxrwxrwx 1 jim jim 512 Nov 3 17:53 basic-gcp-auth drwxrwxrwx 1 jim jim 512 Nov 4 22:41 gcp_vpc drwxrwxrwx 1 jim jim 512 Nov 3 16:36 gcp_vpc_with_subnet drwxrwxrwx 1 jim jim 512 Oct 22 10:13 iam_policy drwxrwxrwx 1 jim jim 512 Oct 22 10:13 inline_policy drwxrwxrwx 1 jim jim 512 Oct 22 10:13 trust_relationship","title":"Examples"},{"location":"extending/","text":"Custom Terraform How to use an unapproved provider Get the binary (i.e. from Github). Unzip the zip file. Then move exe binary to $HOME/.terraform.d/plugins directory. Ensure that you have the cache folder. mkdir -p $HOME/.terraform.d/plugins Unapproved providers snowflake https://github.com/chanzuckerberg/terraform-provider-snowflake Extending Terraform How to write a provider https://www.terraform.io/docs/extend/writing-custom-providers.html http://blog.jfabre.net/2017/01/22/writing-terraform-provider/ https://medium.com/spaceapetech/creating-a-terraform-provider-part-1-ed12884e06d7 https://medium.com/spaceapetech/creating-a-terraform-provider-part-2-1346f89f082c https://petersouter.xyz/writing-and-playing-with-custom-terraform-providers/","title":"Extending"},{"location":"extending/#custom-terraform","text":"","title":"Custom Terraform"},{"location":"extending/#how-to-use-an-unapproved-provider","text":"Get the binary (i.e. from Github). Unzip the zip file. Then move exe binary to $HOME/.terraform.d/plugins directory. Ensure that you have the cache folder. mkdir -p $HOME/.terraform.d/plugins","title":"How to use an unapproved provider"},{"location":"extending/#unapproved-providers","text":"snowflake https://github.com/chanzuckerberg/terraform-provider-snowflake","title":"Unapproved providers"},{"location":"extending/#extending-terraform","text":"How to write a provider https://www.terraform.io/docs/extend/writing-custom-providers.html http://blog.jfabre.net/2017/01/22/writing-terraform-provider/ https://medium.com/spaceapetech/creating-a-terraform-provider-part-1-ed12884e06d7 https://medium.com/spaceapetech/creating-a-terraform-provider-part-2-1346f89f082c https://petersouter.xyz/writing-and-playing-with-custom-terraform-providers/","title":"Extending Terraform"},{"location":"failings/","text":"Failings When Terraform isn't great Objects that take a long time to create are suitable candidates. Active Directory integrations, Elastic search clusters, Kubernetes clusters can all take > 15 to 30 minutes to create. Objects that are fragile. Some AWS resources are built with Cloudformation behind the scenes, any changes, even minor can take forever. Objects with significant cascading effects. Creating and modifying Active Directory Naming [aws fault] or recreating objects that have just been destroyed API Gateway has its' own concept of environments/layers and can create a complex structure in Terraform that varies according to the code where no obvious model to make a module exists.","title":"Failings"},{"location":"failings/#failings","text":"","title":"Failings"},{"location":"failings/#when-terraform-isnt-great","text":"Objects that take a long time to create are suitable candidates. Active Directory integrations, Elastic search clusters, Kubernetes clusters can all take > 15 to 30 minutes to create. Objects that are fragile. Some AWS resources are built with Cloudformation behind the scenes, any changes, even minor can take forever. Objects with significant cascading effects. Creating and modifying Active Directory Naming [aws fault] or recreating objects that have just been destroyed API Gateway has its' own concept of environments/layers and can create a complex structure in Terraform that varies according to the code where no obvious model to make a module exists.","title":"When Terraform isn't great"},{"location":"gcp-cloudsql/","text":"CloudSQL A pre-requisite is to have enabled the API's for this to work if you haven't used this part of GCP before: servicenetworking.googleapis.com sqladmin.googleapis.com Once the API's are enabled you have grant these roles: Storage Admin Cloud SQL Admin To your Terraform Service user [hopefully]. Private Instance Create a database instance, x databases with x number of users. This instance is created privately within your selected VPC. Add module.cloudsql.tf to your code see other objects :- module cloudsql { source = \"JamesWoolfenden/cloudsql/gcp\" version = \"0.1.13\" name = var . name project = var . project network_name = var . network_name database = var . database users = var . users } This creates any number of databases through the the variable \"database\": variable \"database\" { type=list(object({ name = string })) default=[] } Setting database to database=[{ name= \"my-database\" }, { name= \"your-database\" }] Will create 2 databases. The \"Users\" variable and resource follows the same pattern.","title":"CloudSQL"},{"location":"gcp-cloudsql/#cloudsql","text":"A pre-requisite is to have enabled the API's for this to work if you haven't used this part of GCP before: servicenetworking.googleapis.com sqladmin.googleapis.com Once the API's are enabled you have grant these roles: Storage Admin Cloud SQL Admin To your Terraform Service user [hopefully].","title":"CloudSQL"},{"location":"gcp-cloudsql/#private-instance","text":"Create a database instance, x databases with x number of users. This instance is created privately within your selected VPC. Add module.cloudsql.tf to your code see other objects :- module cloudsql { source = \"JamesWoolfenden/cloudsql/gcp\" version = \"0.1.13\" name = var . name project = var . project network_name = var . network_name database = var . database users = var . users } This creates any number of databases through the the variable \"database\": variable \"database\" { type=list(object({ name = string })) default=[] } Setting database to database=[{ name= \"my-database\" }, { name= \"your-database\" }] Will create 2 databases. The \"Users\" variable and resource follows the same pattern.","title":"Private Instance"},{"location":"gcp-cloudstorage/","text":"Cloud Storage Using Cloud storage for a Helm repository The first to create a test repo from the charts folder helm serve --repo-path ./charts This supplies a sample index.yaml , which is added as part of the repo creation process [it's in the template folder for the example]. When you provision the example it will create a public helm repo. You will have to change the name as they are required to be globally unique. https://helm-repo-examplea.storage.googleapis.com/ This example has a mininal index.yaml Adding the repo to your Helm helm repo add baby-steps https://helm-repo-examplea.storage.googleapis.com/ \"baby-steps\" has been added to your repositories Verify: $helm repo list NAME URL stable https://kubernetes-charts.storage.googleapis.com baby-steps https://helm-repo-examplea.storage.googleapis.com/ Usage Add module.storage.tf to your code:- module \"storage\" { source = \"JamesWoolfenden/storage/gcp\" version = \"0.2.3\" binding = var . binding bucket_name = var . bucket_name project = var . project location = var . location } Permissions This being GCP you'll get this error when was making this project, your service account will need these permissions, Included in the \"Cloud Storage Admin\" role. examplea@examplea.iam.gserviceaccount.com does not have storage.buckets.create access to project XXXXXX, forbidden Note https://github.com/JamesWoolfenden/terraform-gcp-storage","title":"Cloud Storage"},{"location":"gcp-cloudstorage/#cloud-storage","text":"","title":"Cloud Storage"},{"location":"gcp-cloudstorage/#using-cloud-storage-for-a-helm-repository","text":"The first to create a test repo from the charts folder helm serve --repo-path ./charts This supplies a sample index.yaml , which is added as part of the repo creation process [it's in the template folder for the example]. When you provision the example it will create a public helm repo. You will have to change the name as they are required to be globally unique. https://helm-repo-examplea.storage.googleapis.com/ This example has a mininal index.yaml","title":"Using Cloud storage for a Helm repository"},{"location":"gcp-cloudstorage/#adding-the-repo-to-your-helm","text":"helm repo add baby-steps https://helm-repo-examplea.storage.googleapis.com/ \"baby-steps\" has been added to your repositories Verify: $helm repo list NAME URL stable https://kubernetes-charts.storage.googleapis.com baby-steps https://helm-repo-examplea.storage.googleapis.com/","title":"Adding the repo to your Helm"},{"location":"gcp-cloudstorage/#usage","text":"Add module.storage.tf to your code:- module \"storage\" { source = \"JamesWoolfenden/storage/gcp\" version = \"0.2.3\" binding = var . binding bucket_name = var . bucket_name project = var . project location = var . location }","title":"Usage"},{"location":"gcp-cloudstorage/#permissions","text":"This being GCP you'll get this error when was making this project, your service account will need these permissions, Included in the \"Cloud Storage Admin\" role. examplea@examplea.iam.gserviceaccount.com does not have storage.buckets.create access to project XXXXXX, forbidden Note https://github.com/JamesWoolfenden/terraform-gcp-storage","title":"Permissions"},{"location":"gcp-dns/","text":"GCP DNS todo","title":"gcp"},{"location":"gcp-dns/#gcp-dns","text":"todo","title":"GCP DNS"},{"location":"gcp-iam/","text":"Managing IAM with Terraform GCP IAM TODO","title":"GCP"},{"location":"gcp-iam/#managing-iam-with-terraform","text":"","title":"Managing IAM with Terraform"},{"location":"gcp-iam/#gcp-iam","text":"TODO","title":"GCP IAM"},{"location":"gcp-kubernetes/","text":"Kubernetes TODO https://google.qwiklabs.com/focuses/8067?parent=catalog","title":"GKE"},{"location":"gcp-kubernetes/#kubernetes","text":"TODO https://google.qwiklabs.com/focuses/8067?parent=catalog","title":"Kubernetes"},{"location":"gcp-vpc/","text":"Creating a Virtual Private Cloud Creating an GCP VPC Creating A VPC with Terraform is fairly straight forward. A minimal functional example configuration is just: resource \"google_compute_network\" \"vpc_network\" { name = \"lovelyhorse\" } Clone the terraform scaffold into gcp_vpc . $ scaffold gcp_vpc --provider GCP ... Add this file google_compute_network.vpc_network.tf to the a scaffold in gcp_vpc. This is example only requires a name. Open your shell at ./gcp_vpc and check the configuration with: terraform init terraform apply If your plan looks like above then you can proceed by approving. Now you have a VPC, and not much else. Open up the GCP console GCP VPC Scroll down and you'll find your new VPC. Select your new VPC and edit. Clean up We can clean up by destroying created VPC: terraform destroy Now everything that's been created has been removed. Complex example TODO Shared VPC toDo","title":"GCP"},{"location":"gcp-vpc/#creating-a-virtual-private-cloud","text":"","title":"Creating a Virtual Private Cloud"},{"location":"gcp-vpc/#creating-an-gcp-vpc","text":"Creating A VPC with Terraform is fairly straight forward. A minimal functional example configuration is just: resource \"google_compute_network\" \"vpc_network\" { name = \"lovelyhorse\" } Clone the terraform scaffold into gcp_vpc . $ scaffold gcp_vpc --provider GCP ... Add this file google_compute_network.vpc_network.tf to the a scaffold in gcp_vpc. This is example only requires a name. Open your shell at ./gcp_vpc and check the configuration with: terraform init terraform apply If your plan looks like above then you can proceed by approving. Now you have a VPC, and not much else. Open up the GCP console GCP VPC Scroll down and you'll find your new VPC. Select your new VPC and edit.","title":"Creating an GCP VPC"},{"location":"gcp-vpc/#clean-up","text":"We can clean up by destroying created VPC: terraform destroy Now everything that's been created has been removed.","title":"Clean up"},{"location":"gcp-vpc/#complex-example","text":"TODO","title":"Complex example"},{"location":"gcp-vpc/#shared-vpc","text":"toDo","title":"Shared VPC"},{"location":"github-actions/","text":"Github actions Github Actions now supports many pre-built actions and workflows. To build a module, the existing simple workflow can be added to your Github repo. A minimal module build process is: init validate bump and version More details on the available syntax for actions is here https://help.github.com/en/actions/automating-your-workflow-with-github-actions/workflow-syntax-for-github-actions . This example is based on this example Add a file called main.yml to the folder .github/workflows/ name : Verify and Bump on : push : branches : - master jobs : examples : name : \"Terraform (examples)\" runs-on : ubuntu-latest steps : - name : \"Checkout\" uses : actions/checkout@master - name : Run a Terraform init uses : docker://hashicorp/terraform:0.12.13 with : entrypoint : terraform args : init example/examplea - name : \"Terraform Validate\" uses : docker://hashicorp/terraform:0.12.13 with : entrypoint : terraform args : validate example/examplea build : name : versioning runs-on : ubuntu-latest steps : - uses : actions/checkout@master - name : Bump version and push tag uses : anothrNick/github-tag-action@master env : GITHUB_TOKEN : ${{ secrets.GITHUB_TOKEN }} DEFAULT_BUMP : patch WITH_V : \"true\" needs : examples Then when you commit a change to master this action will init and validate on the folder example/examplea and then if successful tags the version number. Note This example extends: https://github.com/marketplace/actions/github-tag-bump https://www.hashicorp.com/blog/continuous-integration-for-terraform-modules-with-github-actions/ and https://github.com/hashicorp/terraform-github-actions","title":"Github Actions"},{"location":"github-actions/#github-actions","text":"Github Actions now supports many pre-built actions and workflows. To build a module, the existing simple workflow can be added to your Github repo. A minimal module build process is: init validate bump and version More details on the available syntax for actions is here https://help.github.com/en/actions/automating-your-workflow-with-github-actions/workflow-syntax-for-github-actions . This example is based on this example Add a file called main.yml to the folder .github/workflows/ name : Verify and Bump on : push : branches : - master jobs : examples : name : \"Terraform (examples)\" runs-on : ubuntu-latest steps : - name : \"Checkout\" uses : actions/checkout@master - name : Run a Terraform init uses : docker://hashicorp/terraform:0.12.13 with : entrypoint : terraform args : init example/examplea - name : \"Terraform Validate\" uses : docker://hashicorp/terraform:0.12.13 with : entrypoint : terraform args : validate example/examplea build : name : versioning runs-on : ubuntu-latest steps : - uses : actions/checkout@master - name : Bump version and push tag uses : anothrNick/github-tag-action@master env : GITHUB_TOKEN : ${{ secrets.GITHUB_TOKEN }} DEFAULT_BUMP : patch WITH_V : \"true\" needs : examples Then when you commit a change to master this action will init and validate on the folder example/examplea and then if successful tags the version number. Note This example extends: https://github.com/marketplace/actions/github-tag-bump https://www.hashicorp.com/blog/continuous-integration-for-terraform-modules-with-github-actions/ and https://github.com/hashicorp/terraform-github-actions","title":"Github actions"},{"location":"github/","text":"Github Provider Needs an organization todo users teams repo","title":"Github"},{"location":"github/#github-provider","text":"Needs an organization todo","title":"Github Provider"},{"location":"github/#users","text":"","title":"users"},{"location":"github/#teams","text":"","title":"teams"},{"location":"github/#repo","text":"","title":"repo"},{"location":"gitlab/","text":"gitlab TODO","title":"Gitlab"},{"location":"gitlab/#gitlab","text":"TODO","title":"gitlab"},{"location":"help/","text":"Help If its been useful, let me know. If it's out of date or broken also. I'll appreciate it. Or If you think something is missing or contribute? Got a question? File a GitHub issue . Contributing Bug Reports & Feature Requests Please use the issue tracker to report any bugs or file feature requests. Copyrights Copyright \u00a9 2019-2020 James Woolfenden License Licensed to the Apache Software Foundation (ASF) under one or more contributor license agreements. See the NOTICE file distributed with this work for additional information regarding copyright ownership. The ASF licenses this file to you under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with the License. You may obtain a copy of the License at https://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License. Contributors James Woolfenden","title":"Help"},{"location":"help/#help","text":"If its been useful, let me know. If it's out of date or broken also. I'll appreciate it. Or If you think something is missing or contribute? Got a question? File a GitHub issue .","title":"Help"},{"location":"help/#contributing","text":"","title":"Contributing"},{"location":"help/#bug-reports-feature-requests","text":"Please use the issue tracker to report any bugs or file feature requests.","title":"Bug Reports &amp; Feature Requests"},{"location":"help/#copyrights","text":"Copyright \u00a9 2019-2020 James Woolfenden","title":"Copyrights"},{"location":"help/#license","text":"Licensed to the Apache Software Foundation (ASF) under one or more contributor license agreements. See the NOTICE file distributed with this work for additional information regarding copyright ownership. The ASF licenses this file to you under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with the License. You may obtain a copy of the License at https://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.","title":"License"},{"location":"help/#contributors","text":"James Woolfenden","title":"Contributors"},{"location":"install/","text":"Installing Terraform is available from the popular platform package managers for Macs and Windows. ```mac tab=\"mac\" brew install terraform ```powershell tab=\"Powershell\" cinst Terraform ```bash tab=\"linux\" export TERRAFORM_VERSION= (curl -s https://checkpoint-api.hashicorp.com/v1/check/terraform | jq -r -M '.current_version') curl --silent --output terraform.zip \"https://releases.hashicorp.com/terraform/ (curl -s https://checkpoint-api.hashicorp.com/v1/check/terraform | jq -r -M '.current_version') curl --silent --output terraform.zip \"https://releases.hashicorp.com/terraform/ {TERRAFORM_VERSION}/terraform_ {TERRAFORM_VERSION}_linux_amd64.zip\" unzip terraform.zip ; rm -f terraform.zip; chmod +x terraform mkdir -p {HOME}/bin ; export PATH= {HOME}/bin ; export PATH= {PATH}:{PATH}: {TERRAFORM_VERSION}_linux_amd64.zip\" unzip terraform.zip ; rm -f terraform.zip; chmod +x terraform mkdir -p <span><span class=\"MathJax_Preview\">{HOME}/bin ; export PATH=</span><script type=\"math/tex\">{HOME}/bin ; export PATH= {PATH}:{PATH}: {HOME}/bin; mv terraform ${HOME}/bin/ terraform -v You'll need to update your path to pick up the exe on Windows. There's still no official package manager support on Linux <https://github.com/hashicorp/terraform/issues/17794>, so it's just the binaries and getting them in your path. Verify you have Terraform set-up with: ```cli $ terraform --version Terraform v0.12.20 Now we have Terraform now installed, the next step is to try running it. To do any useful work, this would be against and using a Cloud provider, [e.g. AWS] and for that we require Authentication. Authentication Basic Authentication with the AWS Provider Install the AWS Cli and add your Key and Secret.You can also use the new Cli too https://docs.aws.amazon.com/cli/latest/userguide/install-cliv2.html . ```mac tab=\"mac\" brew install aws-cli ```powershell tab=\"Powershell\" cinst aws-cli Verify that with: $ aws --version aws-cli/1.16.303 Python/3.6.0 Windows/10 botocore/1.13.39 You will either be supplied you Cli credentials by your AWS administrator or you can obtain your own from your own user IAM section. $ aws configure AWS Access Key ID [********************]: AWS Secret Access Key [********************]: Default region name [eu-west-1]: Default output format [json]: There are many more way to provide AWS Authentication than just this. Old examples may show the hard-coding of secrets or the use of vars to then pass them in. Do not. provider \"aws\" { region = \"eu-west-1\" access_key = \"givemymoneyaway\" secret_key = \"to-bitcoin-miners\" } Open the sub-folder basic-aws-auth in your console. Validate your authentation set-up by executing terraform init and then terraform apply : with the GCP Provider Basic auth with GCP is pretty similar, create a service account in your GCP project, create a key file and download into your profile, create an environmental variable that points to it e.g. : export GOOGLE_CLOUD_KEYFILE_JSON={{path}} Open basic-gcp-auth in your console, and update your provider.gcp.tf to have the name of your project. provider \"google\" { project = \"examplea\" region = \"us-central1\" version = \"2.17\" } Run Terraform init and then apply: You now have your GCP auth set-up. Tip - Create a GCP project called examplea All the GCP examples are based around a project called examplea. Instead of updating your providers, save yourself some time and create yourself a project called examplea. Terraform commands Terraform is a command line tool, to see its usage, just Type Terraform at your console now. $ terraform Usage: terraform [ -version ] [ -help ] <command> [ args ] The available commands for execution are listed below. The most common, useful commands are shown first, followed by less common or more advanced commands. If you ' re just getting started with Terraform, stick with the common commands. For the other commands, please read the help and docs before usage. Common commands: apply Builds or changes infrastructure console Interactive console for Terraform interpolations destroy Destroy Terraform-managed infrastructure env Workspace management fmt Rewrites config files to canonical format get Download and install modules for the configuration graph Create a visual graph of Terraform resources import Import existing infrastructure into Terraform init Initialize a Terraform working directory output Read an output from a state file plan Generate and show an execution plan providers Prints a tree of the providers used in the configuration push Upload this Terraform module to Atlas to run refresh Update local state file against real resources show Inspect Terraform state or plan taint Manually mark a resource for recreation untaint Manually unmark a resource as tainted validate Validates the Terraform files version Prints the Terraform version workspace Workspace management All other commands: debug Debug output management ( experimental ) force-unlock Manually unlock the terraform state state Advanced state management That's a lot of commands, however there are only handful of actually common commands that you really use, 90% of the time it is an just Terraform and: Init This command sets up the project, gets providers and connects any defined back-ends. terraform init Initializing the backend... Initializing provider plugins... Terraform has been successfully initialized! You may now begin working with Terraform. Try running \"terraform plan\" to see any changes that are required for your infrastructure. All Terraform commands should now work. If you ever set or change modules or backend configuration for Terraform, rerun this command to reinitialize your working directory. If you forget, other commands will detect it and remind you to do so if necessary. Terraform init can be thought of an equivalent to git init, it downloads the provider executable, modules and does an initial syntax check, all into a .terraform folder. For the full description its: terraform init --help if you open a .terraform folder you find $ ls -l total 0 drwxrwxrwx 1 jim jim 512 Nov 4 23 :00 modules drwxrwxrwx 1 jim jim 512 Nov 4 22 :18 plugins The modules folder hold a copy of the terraform modules that you are using. The plugins hold the downloaded copies of the executable providers. Plan What would happen on an Apply. The command is a hangover from older versions of Terraform, the apply command now includes a plan stage by default. $ terraform plan Refreshing Terraform state in-memory prior to plan... The refreshed state will be used to calculate this plan, but will not be persisted to local or remote state storage. ------------------------------------------------------------------------ An execution plan has been generated and is shown below. Resource actions are indicated with the following symbols: + create Terraform will perform the following actions: # aws_vpc.main will be created + resource \"aws_vpc\" \"main\" { + arn = (known after apply) + assign_generated_ipv6_cidr_block = false + cidr_block = \"10.0.0.0/16\" + default_network_acl_id = (known after apply) + default_route_table_id = (known after apply) + default_security_group_id = (known after apply) + dhcp_options_id = (known after apply) + enable_classiclink = (known after apply) + enable_classiclink_dns_support = (known after apply) + enable_dns_hostnames = (known after apply) + enable_dns_support = true + id = (known after apply) + instance_tenancy = \"default\" + ipv6_association_id = (known after apply) + ipv6_cidr_block = (known after apply) + main_route_table_id = (known after apply) + owner_id = (known after apply) + tags = { + \"createdby\" = \"Terraform\" } } Plan: 1 to add, 0 to change, 0 to destroy. ------------------------------------------------------------------------ Note: You didn't specify an \"-out\" parameter to save this plan, so Terraform can't guarantee that exactly these actions will be performed if \"terraform apply\" is subsequently run. Apply The actual doing. This can create and destroy, infrastructure will be modified to follow your definitions and compared to your state. terraform apply An execution plan has been generated and is shown below. Resource actions are indicated with the following symbols: + create Terraform will perform the following actions: # aws_vpc.main will be created + resource \"aws_vpc\" \"main\" { + arn = (known after apply) + assign_generated_ipv6_cidr_block = false + cidr_block = \"10.0.0.0/16\" + default_network_acl_id = (known after apply) + default_route_table_id = (known after apply) + default_security_group_id = (known after apply) + dhcp_options_id = (known after apply) + enable_classiclink = (known after apply) + enable_classiclink_dns_support = (known after apply) + enable_dns_hostnames = (known after apply) + enable_dns_support = true + id = (known after apply) + instance_tenancy = \"default\" + ipv6_association_id = (known after apply) + ipv6_cidr_block = (known after apply) + main_route_table_id = (known after apply) + owner_id = (known after apply) + tags = { + \"createdby\" = \"Terraform\" } } Plan: 1 to add, 0 to change, 0 to destroy. Do you want to perform these actions? Terraform will perform the actions described above. Only 'yes' will be accepted to approve. Enter a value: Targeted Apply With a Targeted Apply you can cherry pick the apply, this is especially useful when were developing or debugging: terraform apply --target aws_vpc.main This command will only make the VPC, and any of its dependant objects. Destroy What does it destroy, the definition or the state reference? $ terraform destroy ... Taint To force the recreation of an object you can taint it, to force it to be changed even if there's no drift. terraform taint aws_instance.web Targeting It can be very useful to just target one resource at a time, in the previous example just one resource was tainted and a similar method can be used with apply: terraform apply --target module . webbfarm . aws_instance . web Which would only target module.webbfarm.aws_instance.web and ITS' DEPENDENCIES . Modifying existing infrastructure If the definition differs from the existing state captured. Some properties changing causes existing objects to be modified others the recreation. How can I tell what which will happen? TODO:show where changes/destroyed And usually in this order. Speeding up your Terraform builds and development When you use Terraform The first step and command in the Terraform init this process cuases the appropriate provider executables to be downloaded. When you have multiple Terraform projects and environments, that can end up being a lot of copying and downloading, even if you don't terraform init that often. A better way is to set up and use a provider cache. Setting up a Windows plug-in cache ``powershell tab=\"powershell\" ni $env:APPDATA\\terraform.rc Add-Content $env:APPDATA\\terraform.rc \"plugin_cache_dir = \" HOME\\\\.terraform.d\\\\plugin-cache`\"\" mkdir \" HOME\\\\.terraform.d\\\\plugin-cache`\"\" mkdir \" HOME/.terraform.d/plugin-cache\" ```shell tab=\"*nix\" touch ~/.terraformrc echo plugin_cache_dir = \\\"$HOME/.terraform.d/plugin-cache\\\" >> ~/.terraformrc mkdir \"$HOME/.terraform.d/plugin-cache\" Note WSL Windows sub-system for Linux How to set up WSL","title":"Install"},{"location":"install/#installing","text":"Terraform is available from the popular platform package managers for Macs and Windows. ```mac tab=\"mac\" brew install terraform ```powershell tab=\"Powershell\" cinst Terraform ```bash tab=\"linux\" export TERRAFORM_VERSION= (curl -s https://checkpoint-api.hashicorp.com/v1/check/terraform | jq -r -M '.current_version') curl --silent --output terraform.zip \"https://releases.hashicorp.com/terraform/ (curl -s https://checkpoint-api.hashicorp.com/v1/check/terraform | jq -r -M '.current_version') curl --silent --output terraform.zip \"https://releases.hashicorp.com/terraform/ {TERRAFORM_VERSION}/terraform_ {TERRAFORM_VERSION}_linux_amd64.zip\" unzip terraform.zip ; rm -f terraform.zip; chmod +x terraform mkdir -p {HOME}/bin ; export PATH= {HOME}/bin ; export PATH= {PATH}:{PATH}: {TERRAFORM_VERSION}_linux_amd64.zip\" unzip terraform.zip ; rm -f terraform.zip; chmod +x terraform mkdir -p <span><span class=\"MathJax_Preview\">{HOME}/bin ; export PATH=</span><script type=\"math/tex\">{HOME}/bin ; export PATH= {PATH}:{PATH}: {HOME}/bin; mv terraform ${HOME}/bin/ terraform -v You'll need to update your path to pick up the exe on Windows. There's still no official package manager support on Linux <https://github.com/hashicorp/terraform/issues/17794>, so it's just the binaries and getting them in your path. Verify you have Terraform set-up with: ```cli $ terraform --version Terraform v0.12.20 Now we have Terraform now installed, the next step is to try running it. To do any useful work, this would be against and using a Cloud provider, [e.g. AWS] and for that we require Authentication.","title":"Installing"},{"location":"install/#authentication","text":"","title":"Authentication"},{"location":"install/#basic-authentication-with-the-aws-provider","text":"Install the AWS Cli and add your Key and Secret.You can also use the new Cli too https://docs.aws.amazon.com/cli/latest/userguide/install-cliv2.html . ```mac tab=\"mac\" brew install aws-cli ```powershell tab=\"Powershell\" cinst aws-cli Verify that with: $ aws --version aws-cli/1.16.303 Python/3.6.0 Windows/10 botocore/1.13.39 You will either be supplied you Cli credentials by your AWS administrator or you can obtain your own from your own user IAM section. $ aws configure AWS Access Key ID [********************]: AWS Secret Access Key [********************]: Default region name [eu-west-1]: Default output format [json]: There are many more way to provide AWS Authentication than just this. Old examples may show the hard-coding of secrets or the use of vars to then pass them in. Do not. provider \"aws\" { region = \"eu-west-1\" access_key = \"givemymoneyaway\" secret_key = \"to-bitcoin-miners\" } Open the sub-folder basic-aws-auth in your console. Validate your authentation set-up by executing terraform init and then terraform apply :","title":"Basic Authentication with the AWS Provider"},{"location":"install/#with-the-gcp-provider","text":"Basic auth with GCP is pretty similar, create a service account in your GCP project, create a key file and download into your profile, create an environmental variable that points to it e.g. : export GOOGLE_CLOUD_KEYFILE_JSON={{path}} Open basic-gcp-auth in your console, and update your provider.gcp.tf to have the name of your project. provider \"google\" { project = \"examplea\" region = \"us-central1\" version = \"2.17\" } Run Terraform init and then apply: You now have your GCP auth set-up. Tip - Create a GCP project called examplea All the GCP examples are based around a project called examplea. Instead of updating your providers, save yourself some time and create yourself a project called examplea.","title":"with the GCP Provider"},{"location":"install/#terraform-commands","text":"Terraform is a command line tool, to see its usage, just Type Terraform at your console now. $ terraform Usage: terraform [ -version ] [ -help ] <command> [ args ] The available commands for execution are listed below. The most common, useful commands are shown first, followed by less common or more advanced commands. If you ' re just getting started with Terraform, stick with the common commands. For the other commands, please read the help and docs before usage. Common commands: apply Builds or changes infrastructure console Interactive console for Terraform interpolations destroy Destroy Terraform-managed infrastructure env Workspace management fmt Rewrites config files to canonical format get Download and install modules for the configuration graph Create a visual graph of Terraform resources import Import existing infrastructure into Terraform init Initialize a Terraform working directory output Read an output from a state file plan Generate and show an execution plan providers Prints a tree of the providers used in the configuration push Upload this Terraform module to Atlas to run refresh Update local state file against real resources show Inspect Terraform state or plan taint Manually mark a resource for recreation untaint Manually unmark a resource as tainted validate Validates the Terraform files version Prints the Terraform version workspace Workspace management All other commands: debug Debug output management ( experimental ) force-unlock Manually unlock the terraform state state Advanced state management That's a lot of commands, however there are only handful of actually common commands that you really use, 90% of the time it is an just Terraform and:","title":"Terraform commands"},{"location":"install/#init","text":"This command sets up the project, gets providers and connects any defined back-ends. terraform init Initializing the backend... Initializing provider plugins... Terraform has been successfully initialized! You may now begin working with Terraform. Try running \"terraform plan\" to see any changes that are required for your infrastructure. All Terraform commands should now work. If you ever set or change modules or backend configuration for Terraform, rerun this command to reinitialize your working directory. If you forget, other commands will detect it and remind you to do so if necessary. Terraform init can be thought of an equivalent to git init, it downloads the provider executable, modules and does an initial syntax check, all into a .terraform folder. For the full description its: terraform init --help if you open a .terraform folder you find $ ls -l total 0 drwxrwxrwx 1 jim jim 512 Nov 4 23 :00 modules drwxrwxrwx 1 jim jim 512 Nov 4 22 :18 plugins The modules folder hold a copy of the terraform modules that you are using. The plugins hold the downloaded copies of the executable providers.","title":"Init"},{"location":"install/#plan","text":"What would happen on an Apply. The command is a hangover from older versions of Terraform, the apply command now includes a plan stage by default. $ terraform plan Refreshing Terraform state in-memory prior to plan... The refreshed state will be used to calculate this plan, but will not be persisted to local or remote state storage. ------------------------------------------------------------------------ An execution plan has been generated and is shown below. Resource actions are indicated with the following symbols: + create Terraform will perform the following actions: # aws_vpc.main will be created + resource \"aws_vpc\" \"main\" { + arn = (known after apply) + assign_generated_ipv6_cidr_block = false + cidr_block = \"10.0.0.0/16\" + default_network_acl_id = (known after apply) + default_route_table_id = (known after apply) + default_security_group_id = (known after apply) + dhcp_options_id = (known after apply) + enable_classiclink = (known after apply) + enable_classiclink_dns_support = (known after apply) + enable_dns_hostnames = (known after apply) + enable_dns_support = true + id = (known after apply) + instance_tenancy = \"default\" + ipv6_association_id = (known after apply) + ipv6_cidr_block = (known after apply) + main_route_table_id = (known after apply) + owner_id = (known after apply) + tags = { + \"createdby\" = \"Terraform\" } } Plan: 1 to add, 0 to change, 0 to destroy. ------------------------------------------------------------------------ Note: You didn't specify an \"-out\" parameter to save this plan, so Terraform can't guarantee that exactly these actions will be performed if \"terraform apply\" is subsequently run.","title":"Plan"},{"location":"install/#apply","text":"The actual doing. This can create and destroy, infrastructure will be modified to follow your definitions and compared to your state. terraform apply An execution plan has been generated and is shown below. Resource actions are indicated with the following symbols: + create Terraform will perform the following actions: # aws_vpc.main will be created + resource \"aws_vpc\" \"main\" { + arn = (known after apply) + assign_generated_ipv6_cidr_block = false + cidr_block = \"10.0.0.0/16\" + default_network_acl_id = (known after apply) + default_route_table_id = (known after apply) + default_security_group_id = (known after apply) + dhcp_options_id = (known after apply) + enable_classiclink = (known after apply) + enable_classiclink_dns_support = (known after apply) + enable_dns_hostnames = (known after apply) + enable_dns_support = true + id = (known after apply) + instance_tenancy = \"default\" + ipv6_association_id = (known after apply) + ipv6_cidr_block = (known after apply) + main_route_table_id = (known after apply) + owner_id = (known after apply) + tags = { + \"createdby\" = \"Terraform\" } } Plan: 1 to add, 0 to change, 0 to destroy. Do you want to perform these actions? Terraform will perform the actions described above. Only 'yes' will be accepted to approve. Enter a value:","title":"Apply"},{"location":"install/#targeted-apply","text":"With a Targeted Apply you can cherry pick the apply, this is especially useful when were developing or debugging: terraform apply --target aws_vpc.main This command will only make the VPC, and any of its dependant objects.","title":"Targeted Apply"},{"location":"install/#destroy","text":"What does it destroy, the definition or the state reference? $ terraform destroy ...","title":"Destroy"},{"location":"install/#taint","text":"To force the recreation of an object you can taint it, to force it to be changed even if there's no drift. terraform taint aws_instance.web","title":"Taint"},{"location":"install/#targeting","text":"It can be very useful to just target one resource at a time, in the previous example just one resource was tainted and a similar method can be used with apply: terraform apply --target module . webbfarm . aws_instance . web Which would only target module.webbfarm.aws_instance.web and ITS' DEPENDENCIES .","title":"Targeting"},{"location":"install/#modifying-existing-infrastructure","text":"If the definition differs from the existing state captured. Some properties changing causes existing objects to be modified others the recreation. How can I tell what which will happen? TODO:show where changes/destroyed And usually in this order. Speeding up your Terraform builds and development When you use Terraform The first step and command in the Terraform init this process cuases the appropriate provider executables to be downloaded. When you have multiple Terraform projects and environments, that can end up being a lot of copying and downloading, even if you don't terraform init that often. A better way is to set up and use a provider cache.","title":"Modifying existing infrastructure"},{"location":"install/#setting-up-a-windows-plug-in-cache","text":"``powershell tab=\"powershell\" ni $env:APPDATA\\terraform.rc Add-Content $env:APPDATA\\terraform.rc \"plugin_cache_dir = \" HOME\\\\.terraform.d\\\\plugin-cache`\"\" mkdir \" HOME\\\\.terraform.d\\\\plugin-cache`\"\" mkdir \" HOME/.terraform.d/plugin-cache\" ```shell tab=\"*nix\" touch ~/.terraformrc echo plugin_cache_dir = \\\"$HOME/.terraform.d/plugin-cache\\\" >> ~/.terraformrc mkdir \"$HOME/.terraform.d/plugin-cache\" Note WSL Windows sub-system for Linux How to set up WSL","title":"Setting up a Windows plug-in cache"},{"location":"local_file/","text":"Local file Data source Gets the contents of a file. data \"local_file\" \"public_key\" { filename = \"${path.module}/id_rsa.pub\" } You now have the content of the file in data.local_file.public_key.content Resource For Making files To write templated files to disk resource \"local_file\" \"remote_state\" { content = data . template_file . remote_state . rendered filename = \"remote_state.tf\" } Write ssh keys to disk for TLS provider resource \"tls_private_key\" \"vpn\" { algorithm = \"RSA\" rsa_bits = \"2048\" } resource \"local_file\" \"public\" { content = tls_private_key . vpn . public_key_openssh filename = \"id_rsa.public\" } resource \"local_file\" \"private\" { content = tls_private_key . vpn . private_key_pem filename = \"id_rsa\" } This will write out private and public keys for a SSH key that are generated.","title":"Local file"},{"location":"local_file/#local-file","text":"","title":"Local file"},{"location":"local_file/#data-source","text":"Gets the contents of a file. data \"local_file\" \"public_key\" { filename = \"${path.module}/id_rsa.pub\" } You now have the content of the file in data.local_file.public_key.content","title":"Data source"},{"location":"local_file/#resource","text":"","title":"Resource"},{"location":"local_file/#for-making-files","text":"To write templated files to disk resource \"local_file\" \"remote_state\" { content = data . template_file . remote_state . rendered filename = \"remote_state.tf\" } Write ssh keys to disk for TLS provider resource \"tls_private_key\" \"vpn\" { algorithm = \"RSA\" rsa_bits = \"2048\" } resource \"local_file\" \"public\" { content = tls_private_key . vpn . public_key_openssh filename = \"id_rsa.public\" } resource \"local_file\" \"private\" { content = tls_private_key . vpn . private_key_pem filename = \"id_rsa\" } This will write out private and public keys for a SSH key that are generated.","title":"For Making files"},{"location":"module/","text":"Creating and using a Terraform module So far all the examples you have made are Terraform templates/Layers, that is, environmental specific implementations. After a short time writing Terraform you'll realise that you can save time and effort by re-using parts of your own code or by using field tested code of others. Terraform can be written for re-use by defining your code as a module. Modules describe a model of infrastructure but without any environment specific information. Terraform Modules Principles for module creation: designed for re-use. environmental agnostic. has utility not found in resources, - must add something. uses sensible defaults. enables overrides for defaults. includes a readme with usage conforms to the standard module structure layout https://www.terraform.io/docs/modules/index.html versioning of modules. contains examples. defines inputs in variables.tf with descriptions. defines outputs in outputs.tf with descriptions. one module, one repository. And if public: A LICENSE.TXT Referencing and Versioning If you consume a module it's important that you target a Version, otherwise you can expose yourself to unexpected changes and failures. The version you consume can be defined in 2 main ways: To use a module you need to reference its source. module.s3.tf Local references You would use these if you were nesting modules in your folder structure or if you are developing the modules yourself. module \"S3\" { source = \"../../terraform-aws-s3/\" } Git references You can refer to your git in your modules source, this will always get the Head revision of the default branch - Master usually. module \"S3\" { source = \"git::git@github.com:JamesWoolfenden/terraform-aws-s3.git\" } You can use the Git CLI, to tag your modules, when inside the Repository at the CLI/console: git tag -a \"0.0.1\" -m \"Initial commit\" git push --follow-tags Or have your own CI process for your modules. You need to tag and then push the tag to the upstream repository. Git and tags You can also set your git config to always follow tags: git config --global push.followTags true With the tags set and pushed, you can now set the source reference to link to the tag: module \"S3\" { source = \"git::git@github.com:JamesWoolfenden/terraform-aws-s3.git?ref=0.0.1\" } Github reference Terraform is smart enough to infer some of the source if it starts with github. module \"S3\" { source = \"github.com/JamesWoolfenden/terraform-aws-s3\" } Terraform registry This is the next level up, defining and publishing your module to the Public Terraform registry. I use Semantic version for my public modules, and every buildable module gets a tag at the end of its build, in this case the module release I want is 0.0.5: module \"S3\" { source = \"jameswoolfenden/s3/aws\" version = \"0.0.5\" } There are a number of other less common ways to reference your source https://www.terraform.io/docs/modules/sources.html Testing your modules Terraform lacks an established/comprehensive unit testing framework. There are some efforts in this area: https://github.com/gruntwork-io/terratest Enforcing fmt I use tf_scaffold to create new modules and this always adds a pre-commit file. This fails the commit if Terraform fmt fails, other Terraform hooks also exist. Test/reference implementation I have a build/integration test that builds and destroys one of my modules examples before it tags the module. I am currently using Travis for building, testing and labelling my modules, other CI tools would also work https://github.com/JamesWoolfenden/terraform-gcp-bastion/blob/master/.travis.yml dist : trusty sudo : required services : - docker branches : only : - master env : - VERSION=\"0.1.$TRAVIS_BUILD_NUMBER\" addons : apt : packages : - git - curl before_script : - export TERRAFORM_VERSION=$(curl -s https://checkpoint-api.hashicorp.com/v1/check/terraform | jq -r -M '.current_version') - curl --silent --output terraform.zip \"https://releases.hashicorp.com/terraform/${TERRAFORM_VERSION}/terraform_${TERRAFORM_VERSION}_linux_amd64.zip\" - unzip terraform.zip ; rm -f terraform.zip; chmod +x terraform - mkdir -p ${HOME}/bin ; export PATH=${PATH}:${HOME}/bin; mv terraform ${HOME}/bin/ - terraform -v script : - terraform init -get-plugins -backend=false -input=false - terraform init -get -backend=false -input=false - terraform fmt - bash validate.sh after_success : - git config --global user.email \"builds@travis-ci.com\" - git config --global user.name \"Travis CI\" - export GIT_TAG=$VERSION - git tag $GIT_TAG -a -m \"Generated tag from TravisCI build $VERSION\" - git push --quiet https://$TAGAUTH@github.com/jameswoolfenden/terraform-gcp-bastion $GIT_TAG > /dev/null 2>& Scaffold Add a function to your profile to add a function to your shell. That's $PROFILE on Windows or ~/.bashrc on Linix. ```powershell tab=\"powershell\" function scaffold { param( [parameter(mandatory= true)] [string] true)] [string] name) if (!(test-path .$name)) { git clone --depth=1 git@github.com :JamesWoolfenden/tf-scaffold.git \"$name\" } else{ write-warning \"Path $name already exists\" return } rm \"$name.git\" -recurse -force cd $name git init|git add -A } ```bash tab=\"bash\" function scaffold() { if [ -z \"$1\" ] then name=\"scaffold\" else name=$1 fi if [ -z \"$2\" ] then branch=\"master\" else branch=$2 fi echo \"git clone --depth=1 --branch $branch git@github.com:JamesWoolfenden/tf-scaffold.git $name\" git clone --depth=1 --branch $branch git@github.com:JamesWoolfenden/tf-scaffold.git $name rm $name/.git -rf } Making a module Deploy a Scaffold In your shell: $ scaffold terraform-aws-s3 Cloning into 'terraform-aws-s3' ... remote: Enumerating objects: 14 , done . remote: Counting objects: 100 % ( 14 /14 ) , done . remote: Compressing objects: 100 % ( 8 /8 ) , done . remote: Total 14 ( delta 0 ) , reused 8 ( delta 0 ) , pack-reused 0 Receiving objects: 100 % ( 14 /14 ) , done . Enable the pre-commit Pre-commit needs to be installed just the one time, following their instructions Pre-commit pip install pre - commit The .pre-commit.config.yaml in the root: repos : - repo : https://github.com/pre-commit/pre-commit-hooks rev : v2.1.0 hooks : - id : trailing-whitespace - id : end-of-file-fixer - id : check-yaml - id : check-added-large-files - repo : git://github.com/Lucas-C/pre-commit-hooks rev : v1.1.6 hooks : - id : forbid-tabs exclude_types : [ python , javascript , dtd , markdown , makefile ] exclude : binary|\\.bin$ - repo : git://github.com/kintoandar/pre-commit.git rev : v2.1.0 hooks : - id : terraform_fmt - repo : https://github.com/pre-commit/pre-commit-hooks.git rev : v2.1.0 hooks : - id : detect-aws-credentials - id : detect-private-key - repo : https://github.com/detailyang/pre-commit-shell rev : 1.0.4 hooks : - id : shell-lint - repo : git://github.com/igorshubovych/markdownlint-cli rev : v0.14.0 hooks : - id : markdownlint In the root of terraform-aws-s3 : pre-commit install Now any edits and the subsequent commits will trigger the hook. Add an aws_s3_bucket resource Add the following as aws_s3_bucket.bucket.tf resource \"aws_s3_bucket\" \"bucket\" { bucket = var . s 3 _bucket_name policy = var . s 3 _bucket_policy acl = var . s 3 _bucket_acl force_destroy = var . s 3 _bucket_force_destroy tags = var . common_tags } Update variables.tf variable \"common_tags\" { description = \"This is a map type for applying tags on resources\" type = map } variable \"s3_bucket_name\" { description = \"The name of the bucket\" type = string } variable \"s3_bucket_force_destroy\" { description = \"String Boolean to set bucket to be undeletable (well more difficult anyway)\" type = string } variable \"s3_bucket_acl\" { default = \"private\" description = \"Acl on the bucket\" type = string } variable \"s3_bucket_policy\" { description = \"The IAM policy for the bucket\" type = string } locals { env = substr ( var . common_tags [ \"environment\" ], 0 , 1 ) } Update outputs.tf output s3_id { value = aws_s 3 _bucket . bucket . id description = \"The id of the bucket\" } output bucket_domain_name { value = aws_s 3 _bucket . bucket . bucket_domain_name description = \"The full domain name of the bucket\" } output account_id { value = data . aws_caller_identity . current . account_id description = \"The AWS account number in use\" } Add example The example serves 2 purposes, as a test and as a reference implementation. In the root, add a folder example/exampleA In there you'll need a provider.aws.tf provider \"aws\" { version = \"3.11.0\" } and a module.S3.tf module \"S3\" { source = \"../../terraform-aws-s3/\" } Test example init apply Add a readme Add in a file called README.md into the root. Add to a new git repo and push Add all the contents to your new repository you created. There is a naming format for Registries . Note Publish and make it public, see standard structure Connect up your Github account with the Terraform registry Select a repository and publish Add build to Gitlab/Travis/Circleci Tag it Advanced Module composition","title":"Creating"},{"location":"module/#creating-and-using-a-terraform-module","text":"So far all the examples you have made are Terraform templates/Layers, that is, environmental specific implementations. After a short time writing Terraform you'll realise that you can save time and effort by re-using parts of your own code or by using field tested code of others. Terraform can be written for re-use by defining your code as a module. Modules describe a model of infrastructure but without any environment specific information.","title":"Creating and using a Terraform module"},{"location":"module/#terraform-modules","text":"Principles for module creation: designed for re-use. environmental agnostic. has utility not found in resources, - must add something. uses sensible defaults. enables overrides for defaults. includes a readme with usage conforms to the standard module structure layout https://www.terraform.io/docs/modules/index.html versioning of modules. contains examples. defines inputs in variables.tf with descriptions. defines outputs in outputs.tf with descriptions. one module, one repository. And if public: A LICENSE.TXT","title":"Terraform Modules"},{"location":"module/#referencing-and-versioning","text":"If you consume a module it's important that you target a Version, otherwise you can expose yourself to unexpected changes and failures. The version you consume can be defined in 2 main ways: To use a module you need to reference its source. module.s3.tf","title":"Referencing and Versioning"},{"location":"module/#local-references","text":"You would use these if you were nesting modules in your folder structure or if you are developing the modules yourself. module \"S3\" { source = \"../../terraform-aws-s3/\" }","title":"Local references"},{"location":"module/#git-references","text":"You can refer to your git in your modules source, this will always get the Head revision of the default branch - Master usually. module \"S3\" { source = \"git::git@github.com:JamesWoolfenden/terraform-aws-s3.git\" } You can use the Git CLI, to tag your modules, when inside the Repository at the CLI/console: git tag -a \"0.0.1\" -m \"Initial commit\" git push --follow-tags Or have your own CI process for your modules. You need to tag and then push the tag to the upstream repository. Git and tags You can also set your git config to always follow tags: git config --global push.followTags true With the tags set and pushed, you can now set the source reference to link to the tag: module \"S3\" { source = \"git::git@github.com:JamesWoolfenden/terraform-aws-s3.git?ref=0.0.1\" }","title":"Git references"},{"location":"module/#github-reference","text":"Terraform is smart enough to infer some of the source if it starts with github. module \"S3\" { source = \"github.com/JamesWoolfenden/terraform-aws-s3\" }","title":"Github reference"},{"location":"module/#terraform-registry","text":"This is the next level up, defining and publishing your module to the Public Terraform registry. I use Semantic version for my public modules, and every buildable module gets a tag at the end of its build, in this case the module release I want is 0.0.5: module \"S3\" { source = \"jameswoolfenden/s3/aws\" version = \"0.0.5\" } There are a number of other less common ways to reference your source https://www.terraform.io/docs/modules/sources.html","title":"Terraform registry"},{"location":"module/#testing-your-modules","text":"Terraform lacks an established/comprehensive unit testing framework. There are some efforts in this area: https://github.com/gruntwork-io/terratest","title":"Testing your modules"},{"location":"module/#enforcing-fmt","text":"I use tf_scaffold to create new modules and this always adds a pre-commit file. This fails the commit if Terraform fmt fails, other Terraform hooks also exist.","title":"Enforcing fmt"},{"location":"module/#testreference-implementation","text":"I have a build/integration test that builds and destroys one of my modules examples before it tags the module. I am currently using Travis for building, testing and labelling my modules, other CI tools would also work https://github.com/JamesWoolfenden/terraform-gcp-bastion/blob/master/.travis.yml dist : trusty sudo : required services : - docker branches : only : - master env : - VERSION=\"0.1.$TRAVIS_BUILD_NUMBER\" addons : apt : packages : - git - curl before_script : - export TERRAFORM_VERSION=$(curl -s https://checkpoint-api.hashicorp.com/v1/check/terraform | jq -r -M '.current_version') - curl --silent --output terraform.zip \"https://releases.hashicorp.com/terraform/${TERRAFORM_VERSION}/terraform_${TERRAFORM_VERSION}_linux_amd64.zip\" - unzip terraform.zip ; rm -f terraform.zip; chmod +x terraform - mkdir -p ${HOME}/bin ; export PATH=${PATH}:${HOME}/bin; mv terraform ${HOME}/bin/ - terraform -v script : - terraform init -get-plugins -backend=false -input=false - terraform init -get -backend=false -input=false - terraform fmt - bash validate.sh after_success : - git config --global user.email \"builds@travis-ci.com\" - git config --global user.name \"Travis CI\" - export GIT_TAG=$VERSION - git tag $GIT_TAG -a -m \"Generated tag from TravisCI build $VERSION\" - git push --quiet https://$TAGAUTH@github.com/jameswoolfenden/terraform-gcp-bastion $GIT_TAG > /dev/null 2>&","title":"Test/reference implementation"},{"location":"module/#scaffold","text":"Add a function to your profile to add a function to your shell. That's $PROFILE on Windows or ~/.bashrc on Linix. ```powershell tab=\"powershell\" function scaffold { param( [parameter(mandatory= true)] [string] true)] [string] name) if (!(test-path .$name)) { git clone --depth=1 git@github.com :JamesWoolfenden/tf-scaffold.git \"$name\" } else{ write-warning \"Path $name already exists\" return } rm \"$name.git\" -recurse -force cd $name git init|git add -A } ```bash tab=\"bash\" function scaffold() { if [ -z \"$1\" ] then name=\"scaffold\" else name=$1 fi if [ -z \"$2\" ] then branch=\"master\" else branch=$2 fi echo \"git clone --depth=1 --branch $branch git@github.com:JamesWoolfenden/tf-scaffold.git $name\" git clone --depth=1 --branch $branch git@github.com:JamesWoolfenden/tf-scaffold.git $name rm $name/.git -rf }","title":"Scaffold"},{"location":"module/#making-a-module","text":"","title":"Making a module"},{"location":"module/#deploy-a-scaffold","text":"In your shell: $ scaffold terraform-aws-s3 Cloning into 'terraform-aws-s3' ... remote: Enumerating objects: 14 , done . remote: Counting objects: 100 % ( 14 /14 ) , done . remote: Compressing objects: 100 % ( 8 /8 ) , done . remote: Total 14 ( delta 0 ) , reused 8 ( delta 0 ) , pack-reused 0 Receiving objects: 100 % ( 14 /14 ) , done .","title":"Deploy a Scaffold"},{"location":"module/#enable-the-pre-commit","text":"Pre-commit needs to be installed just the one time, following their instructions Pre-commit pip install pre - commit The .pre-commit.config.yaml in the root: repos : - repo : https://github.com/pre-commit/pre-commit-hooks rev : v2.1.0 hooks : - id : trailing-whitespace - id : end-of-file-fixer - id : check-yaml - id : check-added-large-files - repo : git://github.com/Lucas-C/pre-commit-hooks rev : v1.1.6 hooks : - id : forbid-tabs exclude_types : [ python , javascript , dtd , markdown , makefile ] exclude : binary|\\.bin$ - repo : git://github.com/kintoandar/pre-commit.git rev : v2.1.0 hooks : - id : terraform_fmt - repo : https://github.com/pre-commit/pre-commit-hooks.git rev : v2.1.0 hooks : - id : detect-aws-credentials - id : detect-private-key - repo : https://github.com/detailyang/pre-commit-shell rev : 1.0.4 hooks : - id : shell-lint - repo : git://github.com/igorshubovych/markdownlint-cli rev : v0.14.0 hooks : - id : markdownlint In the root of terraform-aws-s3 : pre-commit install Now any edits and the subsequent commits will trigger the hook.","title":"Enable the pre-commit"},{"location":"module/#add-an-aws_s3_bucket-resource","text":"Add the following as aws_s3_bucket.bucket.tf resource \"aws_s3_bucket\" \"bucket\" { bucket = var . s 3 _bucket_name policy = var . s 3 _bucket_policy acl = var . s 3 _bucket_acl force_destroy = var . s 3 _bucket_force_destroy tags = var . common_tags }","title":"Add an aws_s3_bucket resource"},{"location":"module/#update-variablestf","text":"variable \"common_tags\" { description = \"This is a map type for applying tags on resources\" type = map } variable \"s3_bucket_name\" { description = \"The name of the bucket\" type = string } variable \"s3_bucket_force_destroy\" { description = \"String Boolean to set bucket to be undeletable (well more difficult anyway)\" type = string } variable \"s3_bucket_acl\" { default = \"private\" description = \"Acl on the bucket\" type = string } variable \"s3_bucket_policy\" { description = \"The IAM policy for the bucket\" type = string } locals { env = substr ( var . common_tags [ \"environment\" ], 0 , 1 ) }","title":"Update variables.tf"},{"location":"module/#update-outputstf","text":"output s3_id { value = aws_s 3 _bucket . bucket . id description = \"The id of the bucket\" } output bucket_domain_name { value = aws_s 3 _bucket . bucket . bucket_domain_name description = \"The full domain name of the bucket\" } output account_id { value = data . aws_caller_identity . current . account_id description = \"The AWS account number in use\" }","title":"Update outputs.tf"},{"location":"module/#add-example","text":"The example serves 2 purposes, as a test and as a reference implementation. In the root, add a folder example/exampleA In there you'll need a provider.aws.tf provider \"aws\" { version = \"3.11.0\" } and a module.S3.tf module \"S3\" { source = \"../../terraform-aws-s3/\" }","title":"Add example"},{"location":"module/#test-example","text":"init apply","title":"Test example"},{"location":"module/#add-a-readme","text":"Add in a file called README.md into the root.","title":"Add a readme"},{"location":"module/#add-to-a-new-git-repo-and-push","text":"Add all the contents to your new repository you created. There is a naming format for Registries . Note Publish and make it public, see standard structure Connect up your Github account with the Terraform registry Select a repository and publish Add build to Gitlab/Travis/Circleci Tag it Advanced Module composition","title":"Add to a new git repo and push"},{"location":"null/","text":"Null We'll here's something to be really proud of. resource \"null_resource\" \"waiter\" { depends_on = [ \"aws_iam_instance_profile.ec2profile\" ] provisioner \"local-exec\" { command = \"sleep 15\" } }","title":"Null"},{"location":"null/#null","text":"We'll here's something to be really proud of. resource \"null_resource\" \"waiter\" { depends_on = [ \"aws_iam_instance_profile.ec2profile\" ] provisioner \"local-exec\" { command = \"sleep 15\" } }","title":"Null"},{"location":"pagerduty/","text":"Pagerduty TODO","title":"Pager Duty"},{"location":"pagerduty/#pagerduty","text":"TODO","title":"Pagerduty"},{"location":"random/","text":"Random keepers random password random uuid","title":"Random"},{"location":"random/#random","text":"","title":"Random"},{"location":"random/#keepers","text":"","title":"keepers"},{"location":"random/#random-password","text":"","title":"random password"},{"location":"random/#random-uuid","text":"","title":"random uuid"},{"location":"state/","text":"STATE What is this terraform.tfstate file When you have run a terraform apply a state file is created terraform.tfstate . A simple one looks like this: { \"version\": 4, \"terraform_version\": \"0.12.10\", \"serial\": 1, \"lineage\": \"c00de4dd-b230-5181-5799-847ec00a257a\", \"outputs\": { \"account_id\": { \"value\": \"999999999999\", \"type\": \"string\" } }, \"resources\": [ { \"mode\": \"data\", \"type\": \"aws_caller_identity\", \"name\": \"current\", \"provider\": \"provider.aws\", \"instances\": [ { \"schema_version\": 0, \"attributes\": { \"account_id\": \"999999999999\", \"arn\": \"arn:aws:iam::999999999999:user/jameswoolfenden\", \"id\": \"2019-10-12 10:24:39.2137408 +0000 UTC\", \"user_id\": \"AAAAAAAAAAAAAAAAA\" } } ] } ] } The state file holds a record of inputs, outputs and resources created. A state file is a record of what infrastructure was made or that existed at the last run. A typical setup is to create an S3 bucket and configure that to store state, this is called a remote backend. With-in that bucket multiple state files from many different project would exist from One AWS/GCP account/project. Each projects' remote backend would look similar to remote_state.tf below: terraform { backend \"s3\" { encrypt = true bucket = \"121334234343-terraform-state\" key = \"aws-lambda-wilbur/lambda/terraform.tfstate\" dynamodb_table = \"dynamodb-state-lock\" region = \"eu-west-1\" } } Where we have an S3 bucket s3://121334234343-terraform-state with a folder aws-lambda-wilbur/lambda/ as this is a environment called lambda for the template aws-lambda-wilbur . Importance of setting version The state file is written with the version number - see the line above \"terraform_version\": \"0.12.10\" , The Golden Laws of State Don't ever delete your terraform.tfstate Don't check-in terraform.tfstate Add a terraform.state to your .gitignore to ensure this doesn't happen. Don't try to edit state files You'll mess it up. Yes you will. It's like editing a SQL DB by hand. That is also a sub-optimal idea. Do use a locking backend More than one person trying to modify the same infrastructure at the same time? That doesn't work. In the long term you'll be controlling terraform and your infrastructure via a CI/CD process, but locking state is essential. If your state is in S3 use Dynamo . DONT PANIC At times like these cooler head prevail, your second idea is probably wiser than your first. Don't compound your mistakes. Fix your Terraform version as Team in your Terraform Block Add a File to your templates ( terraform.tf ) with content like: terraform { required_version = \"12.10\" } You'll probably forget this at some point and one of you will make the state file incompatible for the team. If you are adding this code to git. You are? no you are. Then add a .gitignore to the root of your repo based from https://github.com/github/gitignore/blob/master/Terraform.gitignore . Also copy the pre-commit file and install it. State recovery/import Ok so you broke your state file? Or you have a tonne of existing estate? Logging on S3 buckets to find out who broke it. Import existing infra basics Most (BUT NOT ALL) resources have support for the import keyword, this can create a lot of work. If your doing a load it will be better to look at Terraforming. This gives you the terraform, this gives you the state: $ terraforming s3 --tfstate { \"version\": 1, \"serial\": 1, \"modules\": [ { \"path\": [ \"root\" ], \"outputs\": { }, \"resources\": { \"aws_s3_bucket.whosebucketisitanyway\": { \"type\": \"aws_s3_bucket\", \"primary\": { \"id\": \"whosebucketisitanyway\", \"attributes\": { \"acl\": \"private\", \"bucket\": \"whosebucketisitanyway\", \"force_destroy\": \"false\", \"id\": \"whosebucketisitanyway\", \"policy\": \"\" } } } } } ] }","title":"State"},{"location":"state/#state","text":"","title":"STATE"},{"location":"state/#what-is-this-terraformtfstate-file","text":"When you have run a terraform apply a state file is created terraform.tfstate . A simple one looks like this: { \"version\": 4, \"terraform_version\": \"0.12.10\", \"serial\": 1, \"lineage\": \"c00de4dd-b230-5181-5799-847ec00a257a\", \"outputs\": { \"account_id\": { \"value\": \"999999999999\", \"type\": \"string\" } }, \"resources\": [ { \"mode\": \"data\", \"type\": \"aws_caller_identity\", \"name\": \"current\", \"provider\": \"provider.aws\", \"instances\": [ { \"schema_version\": 0, \"attributes\": { \"account_id\": \"999999999999\", \"arn\": \"arn:aws:iam::999999999999:user/jameswoolfenden\", \"id\": \"2019-10-12 10:24:39.2137408 +0000 UTC\", \"user_id\": \"AAAAAAAAAAAAAAAAA\" } } ] } ] } The state file holds a record of inputs, outputs and resources created. A state file is a record of what infrastructure was made or that existed at the last run. A typical setup is to create an S3 bucket and configure that to store state, this is called a remote backend. With-in that bucket multiple state files from many different project would exist from One AWS/GCP account/project. Each projects' remote backend would look similar to remote_state.tf below: terraform { backend \"s3\" { encrypt = true bucket = \"121334234343-terraform-state\" key = \"aws-lambda-wilbur/lambda/terraform.tfstate\" dynamodb_table = \"dynamodb-state-lock\" region = \"eu-west-1\" } } Where we have an S3 bucket s3://121334234343-terraform-state with a folder aws-lambda-wilbur/lambda/ as this is a environment called lambda for the template aws-lambda-wilbur .","title":"What is this terraform.tfstate file"},{"location":"state/#importance-of-setting-version","text":"The state file is written with the version number - see the line above \"terraform_version\": \"0.12.10\" ,","title":"Importance of setting version"},{"location":"state/#the-golden-laws-of-state","text":"","title":"The Golden Laws of State"},{"location":"state/#dont-ever-delete-your-terraformtfstate","text":"","title":"Don't ever delete your terraform.tfstate"},{"location":"state/#dont-check-in-terraformtfstate","text":"Add a terraform.state to your .gitignore to ensure this doesn't happen.","title":"Don't check-in terraform.tfstate"},{"location":"state/#dont-try-to-edit-state-files","text":"You'll mess it up. Yes you will. It's like editing a SQL DB by hand. That is also a sub-optimal idea.","title":"Don't try to edit state files"},{"location":"state/#do-use-a-locking-backend","text":"More than one person trying to modify the same infrastructure at the same time? That doesn't work. In the long term you'll be controlling terraform and your infrastructure via a CI/CD process, but locking state is essential. If your state is in S3 use Dynamo .","title":"Do use a locking backend"},{"location":"state/#dont-panic","text":"At times like these cooler head prevail, your second idea is probably wiser than your first. Don't compound your mistakes.","title":"DONT PANIC"},{"location":"state/#fix-your-terraform-version-as-team-in-your-terraform-block","text":"Add a File to your templates ( terraform.tf ) with content like: terraform { required_version = \"12.10\" } You'll probably forget this at some point and one of you will make the state file incompatible for the team. If you are adding this code to git. You are? no you are. Then add a .gitignore to the root of your repo based from https://github.com/github/gitignore/blob/master/Terraform.gitignore . Also copy the pre-commit file and install it.","title":"Fix your Terraform version as Team in your Terraform Block"},{"location":"state/#state-recoveryimport","text":"Ok so you broke your state file? Or you have a tonne of existing estate? Logging on S3 buckets to find out who broke it. Import existing infra basics Most (BUT NOT ALL) resources have support for the import keyword, this can create a lot of work. If your doing a load it will be better to look at Terraforming. This gives you the terraform, this gives you the state: $ terraforming s3 --tfstate { \"version\": 1, \"serial\": 1, \"modules\": [ { \"path\": [ \"root\" ], \"outputs\": { }, \"resources\": { \"aws_s3_bucket.whosebucketisitanyway\": { \"type\": \"aws_s3_bucket\", \"primary\": { \"id\": \"whosebucketisitanyway\", \"attributes\": { \"acl\": \"private\", \"bucket\": \"whosebucketisitanyway\", \"force_destroy\": \"false\", \"id\": \"whosebucketisitanyway\", \"policy\": \"\" } } } } } ] }","title":"State recovery/import"},{"location":"statuscake/","text":"Statuscake","title":"Status Cake"},{"location":"statuscake/#statuscake","text":"","title":"Statuscake"},{"location":"style-guide/","text":"Style Guide Naming Use Lowercase names for resources. Use \"_\" as a separator for resource names. Name must be self explanatory containing several lowercase words if needed separated by \"_\". Use descriptive and non environment specific names to identify resources. Avoid Tautologies: resource \"aws_iam_policy\" \"ec2_policy\" { ... } Hard-coding Don't hard-code values in resources. Add variables and set defaults. You can avoid limiting yourself with policies and resources by making resources optional or over-ridable. resource \"aws_iam_role\" \"codebuild\" { name = \"codebuildrole-${var.name}\" count = \"${var.role == \"\" ? 1 : 0}\" assume_role_policy = <<HERE { \"Version\": \"2012-10-17\" , \"Statement\" : [ { \"Effect\": \"Allow\" , \"Principal\" : { \"Service\": \"codebuild.amazonaws.com\" } , \"Action\": \"sts:AssumeRole\" } ] } HERE tags = var . common_tags } And avoid HEREDOCS like the one above, and use data.aws_iam_policy_documents objects, as practical. Templates This is the Terraform code that is environment specific. If your Templates are application specific the code should live with the code that requires it, create a folder in the root of the repository and call it IAC , similar to this for the repository aws-lexbot-handlers: 23043 -5510:/mnt/c/aws-lexbot-handler# ls -l total 64 -rwxrwxrwx 1 jimw jimw 1719 Mar 7 11 :02 README.MD -rwxrwxrwx 1 jimw jimw 411 Mar 7 11 :02 buildno.sh -rwxrwxrwx 1 jimw jimw 1136 Mar 18 15 :43 buildspec.yml -rwxrwxrwx 1 jimw jimw 489 Mar 18 15 :40 getlatest.ps1 -rwxrwxrwx 1 jimw jimw 479 Mar 7 11 :02 getlatest.sh drwxrwxrwx 1 jimw jimw 512 Feb 26 16 :22 iac drwxrwxrwx 1 1000 1000 512 Mar 18 15 :41 node_modules -rwxrwxrwx 1 jimw jimw 49979 Mar 18 15 :41 package-lock.json -rwxrwxrwx 1 jimw jimw 1579 Mar 18 15 :41 package.json drwxrwxrwx 1 jimw jimw 512 Feb 5 11 :51 powershell -rwxrwxrwx 1 jimw jimw 147 Mar 7 11 :02 setlatest.sh Inside the iac I breakdown the templates used: total 0 drwxrwxrwx 1 jimw jimw 512 May 28 11 :22 codebuild drwxrwxrwx 1 jimw jimw 512 Apr 2 11 :00 repository This example has an AWS CodeCommit repository (self describing) and an AWS Codebuild, that has multiple environments: total 0 drwxrwxrwx 1 jimw jimw 512 Apr 24 23 :28 dev drwxrwxrwx 1 jimw jimw 512 Apr 24 23 :29 prod Inside each of these folder is an environmental specific template: total 19 -rwxrwxrwx 1 jimw jimw 800 May 28 11 :21 Makefile -rwxrwxrwx 1 jimw jimw 1324 Mar 7 11 :02 README.md -rwxrwxrwx 1 jimw jimw 709 Mar 7 11 :02 aws_iam_policy.additionalneeds.tf -rwxrwxrwx 1 jimw jimw 40 Mar 7 11 :02 data.aws_current.region.current.tf -rwxrwxrwx 1 jimw jimw 579 May 28 11 :23 module.codebuild.tf -rwxrwxrwx 1 jimw jimw 239 Mar 7 11 :02 outputs.tf -rwxrwxrwx 1 jimw jimw 208 Apr 24 23 :30 provider.tf -rwxrwxrwx 1 jimw jimw 349 Mar 7 11 :02 remote_state.tf -rwxrwxrwx 1 jimw jimw 1531 May 28 11 :25 terraform.tfvars -rwxrwxrwx 1 jimw jimw 618 May 28 11 :20 variables.tf There's a lot of files here and some repetition - that violates DRY principles, but with IAC, favour on being explicit. Each template is directly runnable, using the Terraform CLI with no wrapper script required. Use a generator like tf-scaffold to automate template creation. Tf-Scaffold creates: .gitignore Has good defaults for working with Terraform. terraform.tfplan terraform.tfstate .terraform/ ./*.tfstate *.backup *.DS_Store *.log *.bak *~ .*.swp .project .pre-commit-config.yaml Has a standard set of pre-commit hooks for working with Terraform and AWS. You'll need to install the pre-commit framework https://pre-commit.com/#install . And after that you need to add this file to your new repository pre-commit-config.yaml , in the root: --- # yamllint disable rule:line-length default_language_version: python: python3 repos: - repo: git://github.com/pre-commit/pre-commit-hooks rev: v2.5.0 hooks: - id: check-json - id: check-merge-conflict - id: trailing-whitespace - id: end-of-file-fixer - id: check-yaml - id: check-added-large-files - id: pretty-format-json args: - --autofix - id: detect-aws-credentials - id: detect-private-key - repo: git://github.com/Lucas-C/pre-commit-hooks rev: v1.1.7 hooks: - id: forbid-tabs exclude_types: - python - javascript - dtd - markdown - makefile - xml exclude: binary|\\.bin$ - repo: git://github.com/jameswoolfenden/pre-commit-shell rev: 0.0.2 hooks: - id: shell-lint - repo: git://github.com/igorshubovych/markdownlint-cli rev: v0.22.0 hooks: - id: markdownlint - repo: git://github.com/adrienverge/yamllint rev: v1.20.0 hooks: - id: yamllint name: yamllint description: This hook runs yamllint. entry: yamllint language: python types: [file, yaml] - repo: git://github.com/jameswoolfenden/pre-commit rev: 0.1.23 hooks: - id: terraform-fmt - id: checkov-scan language_version: python3.7 - id: tf2docs language_version: python3.7 pre-commit install Hooks choices are a matter for each project, but if your are using Terraform or AWS the credentials and private key hooks or equivalent are required. main.tf This is an expected file for Terraform modules. Remove it if this a template and add a module.tf . Makefile A helper file. This is just to make like easier for you. Problematic if you are cross platform as make isn't very good/awful at that. If you use Windows update the PowerShell profile with equivalent helper functions instead. #Makefile ifdef OS RM = $( powershell -noprofile rm . \\. terraform \\m odules -force -recurse ) BLAT = $( powershell -noprofile rm . \\. terraform \\ -force -recurse ) else ifeq ($(shell uname), Linux) RM = rm .terraform/modules/ -fr BLAT = rm .terraform/ -fr endif endif .PHONY : all all : init plan build init : $( RM ) terraform init -reconfigure plan : init terraform plan -refresh = true p : terraform plan -refresh = true | landscape build : init terraform apply -auto-approve check : init terraform plan -detailed-exitcode destroy : init terraform destroy -force docs : terraform-docs md . > README.md valid : tflint terraform fmt -check = true -diff = true target : @read -p \"Enter Module to target:\" MODULE ; terraform apply -target $$ MODULE purge : $( BLAT ) terraform init -reconfigure outputs.tf A standard place to return values, either to the screen or to pass back from a module. provider.aws.tf Or Whatever you provider is or are. Required. You are always going to be using these, included is this, the most basic provider for AWS. README.md Where all the information goes. example.auto.tfvars Files ending .auto.tfvars get picked by Terraform locally and in Terraform cloud. This is the standard file for setting your variables in, and is automatically picked up by Terraform. variables.tf For defining your variables and setting default values. Each variable should define its type and have an adeqate description. Also contains a map variable common_tags, which should be extended and used on every taggable object. .dependsabot/config.yml Sets the repository to be automatically dependency scanned in Github. Modules You've written some TF and your about to duplicate its' functionality, it's time to abstract to a module. A module should be more than just one resource, it should add something. Modules should be treated like applications services with a separate code repository for each module. Each module should have a least one example included that demonstrates its usage. This example can be used as a test for that module, here its called exampleA . examples/exampleA/ This is an example for AWS codecommit that conforms https://github.com/JamesWoolfenden/terraform-aws-codecommit Files Name your files after their contents For a security group called \"elastic\", the resource is then aws_security_group.elastic, so the file is aws_security_group.elastic.tf . Be explicit. It will save you time. Comments Use Markdown for this, as many fmt and parsers break when you add comments into your TF with hashes and slash star comments. One resource per file Exception : By all means group resources - where its really makes logical sense, security_group with rules, routes with route tables. Be Specific You have 2 choices with dependencies. Live on the bleeding edge, or fix your versions. I recommend being in control. Fix the version of Terraform you use The whole team needs to use the same version of the tool until you decide as a team to update. Create a file called terraform.tf in your template: terraform { required_version = \"0.12.21\" } Fix the version of the modules you consume In your module.tf file, set the version of the module. If you author modules, make sure you tag successful module builds. If your module comes from a registry, specify using the version property, if its only standard git source reference use a tag reference in your source statement. If it's using modules from the registry like modules.codebuild.tf : module codebuild { source = \"jameswoolfenden/codebuild/aws\" version = \"0.1.41\" root = var . root description = var . description } Fix the version of the providers you use Using shiny things is great, what's not great is code that worked yesterday breaking because a plugin/provider changed. Specify the version in your provider.tf file. provider \"aws\" { region = \"eu-west-1\" version = \"2.15.0\" } State Using remote state is not optional, use a locking state bucket or use the free state management layer in Terraform Enterprise. This new free tier is worth a look. Layout Mandate the use of the standard pre-commit, using that the command Terraform fmt is always run on Git commit. End of problem. Protecting Secrets Protect your secrets by installing using the pre-commit file and the hooks from the standard set: - id: detect-aws-credentials - id: detect-private-key Other options include using git-secrets, Husky or using Talisman. Use and mandate use of one, by all. Don't be that person. Configuration Convention over configuration is preferred. Use a data source over adding a configuration value. Set default values for your modules variables. Make resources optional with the count syntax. Unit Testing As yet to find a really satisfactory test approach or tool for testing Terraform other than: Include a test implementation with your modules - from your examples root folder. Run it for every change. Tag the successful outcomes. Destroy created resources Tagging Implement a tagging scheme from the start, and use a map type for extensibility. In variables.tf : variable \"common_tags\" { type = \"map\" description = \"Implements the common_tags scheme\" } And in your example.auto.tfvars common_tags = { name = \"sap-proxy-layer\" owner = \"James Woolfenden\" costcentre = \"development\" } and then have the common_tags used in your resources file: resource \"aws_codebuild_project\" \"project\" { name = \"${replace(var.name,\".\",\"-\")}\" description = var . description service_role = \"${var.role == \"\" ? element(concat(aws_iam_role.codebuild.*.arn, list(\"\")), 0) : element(concat(data.aws_iam_role.existing.*.arn, list(\"\")), 0) }\" build_timeout = \"var . build_timeout artifacts { type = var . type location = local . bucketname name = var . name namespace_type = var . namespace_type packaging = var . packaging encryption_disabled = var . encryption_disabled } environment = var . environment source = var . sourcecode tags = var . common_tags } So, use Readable Key value pairs. You don't have to name your like your still on premise. So naming a security group DEV_TEAM_WILBUR4873_APP_SG is not necessarily helpful but tags={ TEAM=\"Wilbur\" Purpose=\"App\" CostCode=\"4873} Is better. Names you can't update, tags you can. The longer you make the resource names the more bugs you will find/make. Ok I get it some resources don't have tag attributes or you have some \"Security\" policy or other that mean you must have a naming regime. If so I'd either use or copy the naming module from the Cloud Posse https://github.com/cloudposse/terraform-null-label . Recommended Tools Terraform-docs Run to help make your readmes, included with the build-harness. The Pre-commit framework So many different uses from linting to security, every git repo should have one. Beyond-Compare or equivalent A preference, for a comparison tool. The Cli Be it AWS, or whatever provider your using. VSCode and Extensions Free and really quite good editor, with awesome extensions. Use the Extensions sync extension to maintain your environment . AWS-Vault Helps with managing many AWS accounts at the CLI. SAML2AWS Generates temporary AWS credentials for AWS cmdline. Essential for running in Federated AD environment. build-harness A DevOps related collection of automated build processes, customised Slalom version Travis - or free for open source projects . There are many other good SAS CI/CD tools including Circle, GitLab and a few shockers.","title":"Style Guide"},{"location":"style-guide/#style-guide","text":"","title":"Style Guide"},{"location":"style-guide/#naming","text":"Use Lowercase names for resources. Use \"_\" as a separator for resource names. Name must be self explanatory containing several lowercase words if needed separated by \"_\". Use descriptive and non environment specific names to identify resources. Avoid Tautologies: resource \"aws_iam_policy\" \"ec2_policy\" { ... }","title":"Naming"},{"location":"style-guide/#hard-coding","text":"Don't hard-code values in resources. Add variables and set defaults. You can avoid limiting yourself with policies and resources by making resources optional or over-ridable. resource \"aws_iam_role\" \"codebuild\" { name = \"codebuildrole-${var.name}\" count = \"${var.role == \"\" ? 1 : 0}\" assume_role_policy = <<HERE { \"Version\": \"2012-10-17\" , \"Statement\" : [ { \"Effect\": \"Allow\" , \"Principal\" : { \"Service\": \"codebuild.amazonaws.com\" } , \"Action\": \"sts:AssumeRole\" } ] } HERE tags = var . common_tags } And avoid HEREDOCS like the one above, and use data.aws_iam_policy_documents objects, as practical.","title":"Hard-coding"},{"location":"style-guide/#templates","text":"This is the Terraform code that is environment specific. If your Templates are application specific the code should live with the code that requires it, create a folder in the root of the repository and call it IAC , similar to this for the repository aws-lexbot-handlers: 23043 -5510:/mnt/c/aws-lexbot-handler# ls -l total 64 -rwxrwxrwx 1 jimw jimw 1719 Mar 7 11 :02 README.MD -rwxrwxrwx 1 jimw jimw 411 Mar 7 11 :02 buildno.sh -rwxrwxrwx 1 jimw jimw 1136 Mar 18 15 :43 buildspec.yml -rwxrwxrwx 1 jimw jimw 489 Mar 18 15 :40 getlatest.ps1 -rwxrwxrwx 1 jimw jimw 479 Mar 7 11 :02 getlatest.sh drwxrwxrwx 1 jimw jimw 512 Feb 26 16 :22 iac drwxrwxrwx 1 1000 1000 512 Mar 18 15 :41 node_modules -rwxrwxrwx 1 jimw jimw 49979 Mar 18 15 :41 package-lock.json -rwxrwxrwx 1 jimw jimw 1579 Mar 18 15 :41 package.json drwxrwxrwx 1 jimw jimw 512 Feb 5 11 :51 powershell -rwxrwxrwx 1 jimw jimw 147 Mar 7 11 :02 setlatest.sh Inside the iac I breakdown the templates used: total 0 drwxrwxrwx 1 jimw jimw 512 May 28 11 :22 codebuild drwxrwxrwx 1 jimw jimw 512 Apr 2 11 :00 repository This example has an AWS CodeCommit repository (self describing) and an AWS Codebuild, that has multiple environments: total 0 drwxrwxrwx 1 jimw jimw 512 Apr 24 23 :28 dev drwxrwxrwx 1 jimw jimw 512 Apr 24 23 :29 prod Inside each of these folder is an environmental specific template: total 19 -rwxrwxrwx 1 jimw jimw 800 May 28 11 :21 Makefile -rwxrwxrwx 1 jimw jimw 1324 Mar 7 11 :02 README.md -rwxrwxrwx 1 jimw jimw 709 Mar 7 11 :02 aws_iam_policy.additionalneeds.tf -rwxrwxrwx 1 jimw jimw 40 Mar 7 11 :02 data.aws_current.region.current.tf -rwxrwxrwx 1 jimw jimw 579 May 28 11 :23 module.codebuild.tf -rwxrwxrwx 1 jimw jimw 239 Mar 7 11 :02 outputs.tf -rwxrwxrwx 1 jimw jimw 208 Apr 24 23 :30 provider.tf -rwxrwxrwx 1 jimw jimw 349 Mar 7 11 :02 remote_state.tf -rwxrwxrwx 1 jimw jimw 1531 May 28 11 :25 terraform.tfvars -rwxrwxrwx 1 jimw jimw 618 May 28 11 :20 variables.tf There's a lot of files here and some repetition - that violates DRY principles, but with IAC, favour on being explicit. Each template is directly runnable, using the Terraform CLI with no wrapper script required. Use a generator like tf-scaffold to automate template creation. Tf-Scaffold creates:","title":"Templates"},{"location":"style-guide/#gitignore","text":"Has good defaults for working with Terraform. terraform.tfplan terraform.tfstate .terraform/ ./*.tfstate *.backup *.DS_Store *.log *.bak *~ .*.swp .project","title":".gitignore"},{"location":"style-guide/#pre-commit-configyaml","text":"Has a standard set of pre-commit hooks for working with Terraform and AWS. You'll need to install the pre-commit framework https://pre-commit.com/#install . And after that you need to add this file to your new repository pre-commit-config.yaml , in the root: --- # yamllint disable rule:line-length default_language_version: python: python3 repos: - repo: git://github.com/pre-commit/pre-commit-hooks rev: v2.5.0 hooks: - id: check-json - id: check-merge-conflict - id: trailing-whitespace - id: end-of-file-fixer - id: check-yaml - id: check-added-large-files - id: pretty-format-json args: - --autofix - id: detect-aws-credentials - id: detect-private-key - repo: git://github.com/Lucas-C/pre-commit-hooks rev: v1.1.7 hooks: - id: forbid-tabs exclude_types: - python - javascript - dtd - markdown - makefile - xml exclude: binary|\\.bin$ - repo: git://github.com/jameswoolfenden/pre-commit-shell rev: 0.0.2 hooks: - id: shell-lint - repo: git://github.com/igorshubovych/markdownlint-cli rev: v0.22.0 hooks: - id: markdownlint - repo: git://github.com/adrienverge/yamllint rev: v1.20.0 hooks: - id: yamllint name: yamllint description: This hook runs yamllint. entry: yamllint language: python types: [file, yaml] - repo: git://github.com/jameswoolfenden/pre-commit rev: 0.1.23 hooks: - id: terraform-fmt - id: checkov-scan language_version: python3.7 - id: tf2docs language_version: python3.7 pre-commit install Hooks choices are a matter for each project, but if your are using Terraform or AWS the credentials and private key hooks or equivalent are required.","title":".pre-commit-config.yaml"},{"location":"style-guide/#maintf","text":"This is an expected file for Terraform modules. Remove it if this a template and add a module.tf .","title":"main.tf"},{"location":"style-guide/#makefile","text":"A helper file. This is just to make like easier for you. Problematic if you are cross platform as make isn't very good/awful at that. If you use Windows update the PowerShell profile with equivalent helper functions instead. #Makefile ifdef OS RM = $( powershell -noprofile rm . \\. terraform \\m odules -force -recurse ) BLAT = $( powershell -noprofile rm . \\. terraform \\ -force -recurse ) else ifeq ($(shell uname), Linux) RM = rm .terraform/modules/ -fr BLAT = rm .terraform/ -fr endif endif .PHONY : all all : init plan build init : $( RM ) terraform init -reconfigure plan : init terraform plan -refresh = true p : terraform plan -refresh = true | landscape build : init terraform apply -auto-approve check : init terraform plan -detailed-exitcode destroy : init terraform destroy -force docs : terraform-docs md . > README.md valid : tflint terraform fmt -check = true -diff = true target : @read -p \"Enter Module to target:\" MODULE ; terraform apply -target $$ MODULE purge : $( BLAT ) terraform init -reconfigure","title":"Makefile"},{"location":"style-guide/#outputstf","text":"A standard place to return values, either to the screen or to pass back from a module.","title":"outputs.tf"},{"location":"style-guide/#providerawstf","text":"Or Whatever you provider is or are. Required. You are always going to be using these, included is this, the most basic provider for AWS.","title":"provider.aws.tf"},{"location":"style-guide/#readmemd","text":"Where all the information goes.","title":"README.md"},{"location":"style-guide/#exampleautotfvars","text":"Files ending .auto.tfvars get picked by Terraform locally and in Terraform cloud. This is the standard file for setting your variables in, and is automatically picked up by Terraform.","title":"example.auto.tfvars"},{"location":"style-guide/#variablestf","text":"For defining your variables and setting default values. Each variable should define its type and have an adeqate description. Also contains a map variable common_tags, which should be extended and used on every taggable object.","title":"variables.tf"},{"location":"style-guide/#dependsabotconfigyml","text":"Sets the repository to be automatically dependency scanned in Github.","title":".dependsabot/config.yml"},{"location":"style-guide/#modules","text":"You've written some TF and your about to duplicate its' functionality, it's time to abstract to a module. A module should be more than just one resource, it should add something. Modules should be treated like applications services with a separate code repository for each module. Each module should have a least one example included that demonstrates its usage. This example can be used as a test for that module, here its called exampleA . examples/exampleA/ This is an example for AWS codecommit that conforms https://github.com/JamesWoolfenden/terraform-aws-codecommit","title":"Modules"},{"location":"style-guide/#files","text":"","title":"Files"},{"location":"style-guide/#name-your-files-after-their-contents","text":"For a security group called \"elastic\", the resource is then aws_security_group.elastic, so the file is aws_security_group.elastic.tf . Be explicit. It will save you time.","title":"Name your files after their contents"},{"location":"style-guide/#comments","text":"Use Markdown for this, as many fmt and parsers break when you add comments into your TF with hashes and slash star comments.","title":"Comments"},{"location":"style-guide/#one-resource-per-file","text":"Exception : By all means group resources - where its really makes logical sense, security_group with rules, routes with route tables.","title":"One resource per file"},{"location":"style-guide/#be-specific","text":"You have 2 choices with dependencies. Live on the bleeding edge, or fix your versions. I recommend being in control.","title":"Be Specific"},{"location":"style-guide/#fix-the-version-of-terraform-you-use","text":"The whole team needs to use the same version of the tool until you decide as a team to update. Create a file called terraform.tf in your template: terraform { required_version = \"0.12.21\" }","title":"Fix the version of Terraform you use"},{"location":"style-guide/#fix-the-version-of-the-modules-you-consume","text":"In your module.tf file, set the version of the module. If you author modules, make sure you tag successful module builds. If your module comes from a registry, specify using the version property, if its only standard git source reference use a tag reference in your source statement. If it's using modules from the registry like modules.codebuild.tf : module codebuild { source = \"jameswoolfenden/codebuild/aws\" version = \"0.1.41\" root = var . root description = var . description }","title":"Fix the version of the modules you consume"},{"location":"style-guide/#fix-the-version-of-the-providers-you-use","text":"Using shiny things is great, what's not great is code that worked yesterday breaking because a plugin/provider changed. Specify the version in your provider.tf file. provider \"aws\" { region = \"eu-west-1\" version = \"2.15.0\" }","title":"Fix the version of the providers you use"},{"location":"style-guide/#state","text":"Using remote state is not optional, use a locking state bucket or use the free state management layer in Terraform Enterprise. This new free tier is worth a look.","title":"State"},{"location":"style-guide/#layout","text":"Mandate the use of the standard pre-commit, using that the command Terraform fmt is always run on Git commit. End of problem.","title":"Layout"},{"location":"style-guide/#protecting-secrets","text":"Protect your secrets by installing using the pre-commit file and the hooks from the standard set: - id: detect-aws-credentials - id: detect-private-key Other options include using git-secrets, Husky or using Talisman. Use and mandate use of one, by all. Don't be that person.","title":"Protecting Secrets"},{"location":"style-guide/#configuration","text":"Convention over configuration is preferred. Use a data source over adding a configuration value. Set default values for your modules variables. Make resources optional with the count syntax.","title":"Configuration"},{"location":"style-guide/#unit-testing","text":"As yet to find a really satisfactory test approach or tool for testing Terraform other than: Include a test implementation with your modules - from your examples root folder. Run it for every change. Tag the successful outcomes. Destroy created resources","title":"Unit Testing"},{"location":"style-guide/#tagging","text":"Implement a tagging scheme from the start, and use a map type for extensibility. In variables.tf : variable \"common_tags\" { type = \"map\" description = \"Implements the common_tags scheme\" } And in your example.auto.tfvars common_tags = { name = \"sap-proxy-layer\" owner = \"James Woolfenden\" costcentre = \"development\" } and then have the common_tags used in your resources file: resource \"aws_codebuild_project\" \"project\" { name = \"${replace(var.name,\".\",\"-\")}\" description = var . description service_role = \"${var.role == \"\" ? element(concat(aws_iam_role.codebuild.*.arn, list(\"\")), 0) : element(concat(data.aws_iam_role.existing.*.arn, list(\"\")), 0) }\" build_timeout = \"var . build_timeout artifacts { type = var . type location = local . bucketname name = var . name namespace_type = var . namespace_type packaging = var . packaging encryption_disabled = var . encryption_disabled } environment = var . environment source = var . sourcecode tags = var . common_tags } So, use Readable Key value pairs. You don't have to name your like your still on premise. So naming a security group DEV_TEAM_WILBUR4873_APP_SG is not necessarily helpful but tags={ TEAM=\"Wilbur\" Purpose=\"App\" CostCode=\"4873} Is better. Names you can't update, tags you can. The longer you make the resource names the more bugs you will find/make. Ok I get it some resources don't have tag attributes or you have some \"Security\" policy or other that mean you must have a naming regime. If so I'd either use or copy the naming module from the Cloud Posse https://github.com/cloudposse/terraform-null-label .","title":"Tagging"},{"location":"style-guide/#recommended-tools","text":"Terraform-docs Run to help make your readmes, included with the build-harness. The Pre-commit framework So many different uses from linting to security, every git repo should have one. Beyond-Compare or equivalent A preference, for a comparison tool. The Cli Be it AWS, or whatever provider your using. VSCode and Extensions Free and really quite good editor, with awesome extensions. Use the Extensions sync extension to maintain your environment . AWS-Vault Helps with managing many AWS accounts at the CLI. SAML2AWS Generates temporary AWS credentials for AWS cmdline. Essential for running in Federated AD environment. build-harness A DevOps related collection of automated build processes, customised Slalom version Travis - or free for open source projects . There are many other good SAS CI/CD tools including Circle, GitLab and a few shockers.","title":"Recommended Tools"},{"location":"syntax/","text":"Terraform HCL syntax Primer Most of what you need to know is found on the Terraform site https://www.terraform.io/docs/configuration/variables.html . The information provided here is in addition. Provisioners As the Terraform Docs call out \"Provisioners are a Last Resort\" . Heed these words, there is, and there really should be a better way of doing what your trying to do. Provisioners don't do state and are a horror to make idempotent, so you have less control over when they run and what they do. You can use Triggers to control execution, but creating destroy time provisioners is a good way of wasting a lot of your time. If you find yourself wanting to install packages at launch with remote-exec ask yourself: Is this something better pre-prepared in Packer - Almost definitely If Packer is overkill then could this be done with your bootstrap load - maybe, see previous answer . The Bootstrap load should be the chance to add environment specific configuration at launch-time. Remember that Installing at launch is slow and could fail, so if you're spinning up because of a scaling request, you have no time to spare, and have zero room for failure. Remember pre-prepared always beats installing. With In-place updates there's always a risk of failed update and loss of use while changing, Downtime is to be avoided. Connections Remote Provisioner's need authentication, probably via SSH [God forbid it winrm ]. So you now have SSH key, password or certificate management issues. You also need to be on a network that allows it. You may have to connect through a bastion host. Connection forwarding TODO:Thru a Bastion When to use a Provisioner To overcome a bug in Terraform behaviour. No Terraform resource exists. When not Installing anything on a new instance. Terraform is for making infrastructure, and for managing \"Cattle\". If you find your self wanting to install a lot of components, you should be making new component via tools like Packer. Remote-Exec SSH onto a box after creation. Local-exec Make something/execute on the build box during provisioning. File Provisioning Triggers everytime triggers { build_number = \"${timestamp()}\" } when = \"destroy\" on create is the default when = \"destroy\" TODO on_failure = \"continue\" Note I have never used these provisioners, if you have some legacy scripts you want to exploit they may have be useful. Chef provisioner Puppet provisioner Habitat provisioner Salt-masterless Provisoner Resources This is the main component class in Terraform, resource are the infrastructure objects you're trying to create. Providers Passing Provider to Module How do I pass the provider and its configuration into a module? The default provider is passed in without you seeing anything, but a non default or extra one is very different. define a Provider provider.secondary.tf provider \"aws\" { alias = \"secondary\" region = \"us-east-1\" version = \"2.35.0\" } and then pass it in the module definition module.stuff.tf module \"stuff\" { ... providers = { aws = \"aws.secondary\" } } Easy enough. Passing multiple providers What happens if you need to pass 2 different defined providers? Then define one as the default, and one with a named alias and pass them to the module. module \"cassandra\" { source = \"../../\" instance_type = var . instance_type common_tags = var . common_tags providers = { aws = aws aws.secondary = \"aws.useast\" } } And then you can try and reference the providers: resource \"aws_instance\" \"remote-cassandra-node3\" { provider = aws . secondary key_name = element ( module . ssh-key-secondary . keys , 0 ) ami = data . aws_ami . ubuntu-secondary . image_id instance_type = var . instance_type root_block_device { volume_type = \"standard\" volume_size = 100 delete_on_termination = false } tags = var . common_tags } Now I almost thought it could just be that easy, but when you plan/apply you get: Error Error: missing provider module.cassandra.provider.aws.secondary The answer is to create an empty Provider in your module provider.secondary.tf and your golden: provider \"aws\" { alias = \"secondary\" } Note Samples from the module https://github.com/JamesWoolfenden/terraform-aws-cassandra Functions Are well covered here https://www.terraform.io/docs/configuration/functions.html Variables strings maps lists null passing blocks lists locals Terraform doesn't support interpolation of variables in variables. So although it would be AWESOME if this worked: variable \"name\" { default = \"James\" } variable \"fullname\" { default = \"${var.name} Woolfenden\" } It however does not. Coff. However something similar can be achieved with locals : variable \"name\" { default = \"James\" } locals { fullname = \"${var.name} Woolfenden\" } To reference the local you use: local.fullname instead of var.fullname See the Terraform docs here Outputs I use an Outputs.tf in my templates and modules, it helps with re-use and extensibility if you pass out complex data objects to your output. This is now valid: output \"function\" { value = google_cloudfunctions_function . lambda } new in TF 0.12 Listof todo Objects You can define lists of a type or multiple types. type = list ( map ( string )) or variable \"database\" { type = list ( object ( { name = string } )) default = [] } Setting the database variable: database=[{ name= \"my-database\" }, { name= \"your-database\" }] When used with google_sql_database.database.tf it will create 2 databases. resource \"google_sql_database\" \"database\" { count = length ( var . database ) name = var . database [ count . index ][ \"name\" ] instance = google_sql_database_instance . instance . name } This syntax enables optional creation of resources based on that object being populated, or not. Sets todo Dynamic The Dynamic keyword can be used to variable length blocks as used in this codepipeline module. dynamic \"stage\" { for_each = [ for s in var . stages : { name = s . name action = s . action } ] content { name = stage . value . name action { name = stage . value . action [ \"name\" ] owner = stage . value . action [ \"owner\" ] version = stage . value . action [ \"version\" ] category = stage . value . action [ \"category\" ] provider = stage . value . action [ \"provider\" ] input_artifacts = stage . value . action [ \"input_artifacts\" ] output_artifacts = stage . value . action [ \"output_artifacts\" ] configuration = stage . value . action [ \"configuration\" ] } } } Order One of the awesome things that Terraform normally just does correctly, nearly always. Sometimes it doesn't and usually thats poor design on out part, but sometimes not. depends_on You can set the depends_on keyword on a resource to force a dependency, it shouldn't be needed. resource \"aws_instance\" \"web\" { depends_on = [ aws . aws_iam_instance_profile . stuff ] # ... } I have had to use this in the past on objects, and while the provider said they were created, they were actually still in the process of being created, and being replicated across regions on their way to being consistent. depends_on with modules Depends_on became a keyword with Terraform 0.12, you can achieve the same with 0.12. variable \"vm_depends_on\" { type = any default = null } resource \"aws_instance\" \"web\" { depends_on = [ var . vm_depends_on ] # ... } If the file above becomes part of a module: module \"web\" { source = \"...\" vm_depends_on = [ module . anyobject . youchoose ] } Note After https://discuss.hashicorp.com/t/tips-howto-implement-module-depends-on-emulation/2305/2","title":"Syntax"},{"location":"syntax/#terraform-hcl-syntax-primer","text":"Most of what you need to know is found on the Terraform site https://www.terraform.io/docs/configuration/variables.html . The information provided here is in addition.","title":"Terraform HCL syntax Primer"},{"location":"syntax/#provisioners","text":"As the Terraform Docs call out \"Provisioners are a Last Resort\" . Heed these words, there is, and there really should be a better way of doing what your trying to do. Provisioners don't do state and are a horror to make idempotent, so you have less control over when they run and what they do. You can use Triggers to control execution, but creating destroy time provisioners is a good way of wasting a lot of your time. If you find yourself wanting to install packages at launch with remote-exec ask yourself: Is this something better pre-prepared in Packer - Almost definitely If Packer is overkill then could this be done with your bootstrap load - maybe, see previous answer . The Bootstrap load should be the chance to add environment specific configuration at launch-time. Remember that Installing at launch is slow and could fail, so if you're spinning up because of a scaling request, you have no time to spare, and have zero room for failure. Remember pre-prepared always beats installing. With In-place updates there's always a risk of failed update and loss of use while changing, Downtime is to be avoided.","title":"Provisioners"},{"location":"syntax/#connections","text":"Remote Provisioner's need authentication, probably via SSH [God forbid it winrm ]. So you now have SSH key, password or certificate management issues. You also need to be on a network that allows it. You may have to connect through a bastion host.","title":"Connections"},{"location":"syntax/#connection-forwarding","text":"TODO:Thru a Bastion When to use a Provisioner To overcome a bug in Terraform behaviour. No Terraform resource exists. When not Installing anything on a new instance. Terraform is for making infrastructure, and for managing \"Cattle\". If you find your self wanting to install a lot of components, you should be making new component via tools like Packer.","title":"Connection forwarding"},{"location":"syntax/#remote-exec","text":"SSH onto a box after creation.","title":"Remote-Exec"},{"location":"syntax/#local-exec","text":"Make something/execute on the build box during provisioning.","title":"Local-exec"},{"location":"syntax/#file-provisioning","text":"","title":"File Provisioning"},{"location":"syntax/#triggers","text":"everytime triggers { build_number = \"${timestamp()}\" } when = \"destroy\" on create is the default when = \"destroy\" TODO on_failure = \"continue\" Note I have never used these provisioners, if you have some legacy scripts you want to exploit they may have be useful. Chef provisioner Puppet provisioner Habitat provisioner Salt-masterless Provisoner","title":"Triggers"},{"location":"syntax/#resources","text":"This is the main component class in Terraform, resource are the infrastructure objects you're trying to create.","title":"Resources"},{"location":"syntax/#providers","text":"","title":"Providers"},{"location":"syntax/#passing-provider-to-module","text":"How do I pass the provider and its configuration into a module? The default provider is passed in without you seeing anything, but a non default or extra one is very different. define a Provider provider.secondary.tf provider \"aws\" { alias = \"secondary\" region = \"us-east-1\" version = \"2.35.0\" } and then pass it in the module definition module.stuff.tf module \"stuff\" { ... providers = { aws = \"aws.secondary\" } } Easy enough.","title":"Passing Provider to Module"},{"location":"syntax/#passing-multiple-providers","text":"What happens if you need to pass 2 different defined providers? Then define one as the default, and one with a named alias and pass them to the module. module \"cassandra\" { source = \"../../\" instance_type = var . instance_type common_tags = var . common_tags providers = { aws = aws aws.secondary = \"aws.useast\" } } And then you can try and reference the providers: resource \"aws_instance\" \"remote-cassandra-node3\" { provider = aws . secondary key_name = element ( module . ssh-key-secondary . keys , 0 ) ami = data . aws_ami . ubuntu-secondary . image_id instance_type = var . instance_type root_block_device { volume_type = \"standard\" volume_size = 100 delete_on_termination = false } tags = var . common_tags } Now I almost thought it could just be that easy, but when you plan/apply you get: Error Error: missing provider module.cassandra.provider.aws.secondary The answer is to create an empty Provider in your module provider.secondary.tf and your golden: provider \"aws\" { alias = \"secondary\" } Note Samples from the module https://github.com/JamesWoolfenden/terraform-aws-cassandra","title":"Passing multiple providers"},{"location":"syntax/#functions","text":"Are well covered here https://www.terraform.io/docs/configuration/functions.html","title":"Functions"},{"location":"syntax/#variables","text":"strings maps lists null passing blocks lists locals Terraform doesn't support interpolation of variables in variables. So although it would be AWESOME if this worked: variable \"name\" { default = \"James\" } variable \"fullname\" { default = \"${var.name} Woolfenden\" } It however does not. Coff. However something similar can be achieved with locals : variable \"name\" { default = \"James\" } locals { fullname = \"${var.name} Woolfenden\" } To reference the local you use: local.fullname instead of var.fullname See the Terraform docs here","title":"Variables"},{"location":"syntax/#outputs","text":"I use an Outputs.tf in my templates and modules, it helps with re-use and extensibility if you pass out complex data objects to your output. This is now valid: output \"function\" { value = google_cloudfunctions_function . lambda }","title":"Outputs"},{"location":"syntax/#new-in-tf-012","text":"","title":"new in TF 0.12"},{"location":"syntax/#listof","text":"todo","title":"Listof"},{"location":"syntax/#objects","text":"You can define lists of a type or multiple types. type = list ( map ( string )) or variable \"database\" { type = list ( object ( { name = string } )) default = [] } Setting the database variable: database=[{ name= \"my-database\" }, { name= \"your-database\" }] When used with google_sql_database.database.tf it will create 2 databases. resource \"google_sql_database\" \"database\" { count = length ( var . database ) name = var . database [ count . index ][ \"name\" ] instance = google_sql_database_instance . instance . name } This syntax enables optional creation of resources based on that object being populated, or not.","title":"Objects"},{"location":"syntax/#sets","text":"todo","title":"Sets"},{"location":"syntax/#dynamic","text":"The Dynamic keyword can be used to variable length blocks as used in this codepipeline module. dynamic \"stage\" { for_each = [ for s in var . stages : { name = s . name action = s . action } ] content { name = stage . value . name action { name = stage . value . action [ \"name\" ] owner = stage . value . action [ \"owner\" ] version = stage . value . action [ \"version\" ] category = stage . value . action [ \"category\" ] provider = stage . value . action [ \"provider\" ] input_artifacts = stage . value . action [ \"input_artifacts\" ] output_artifacts = stage . value . action [ \"output_artifacts\" ] configuration = stage . value . action [ \"configuration\" ] } } }","title":"Dynamic"},{"location":"syntax/#order","text":"One of the awesome things that Terraform normally just does correctly, nearly always. Sometimes it doesn't and usually thats poor design on out part, but sometimes not.","title":"Order"},{"location":"syntax/#depends_on","text":"You can set the depends_on keyword on a resource to force a dependency, it shouldn't be needed. resource \"aws_instance\" \"web\" { depends_on = [ aws . aws_iam_instance_profile . stuff ] # ... } I have had to use this in the past on objects, and while the provider said they were created, they were actually still in the process of being created, and being replicated across regions on their way to being consistent.","title":"depends_on"},{"location":"syntax/#depends_on-with-modules","text":"Depends_on became a keyword with Terraform 0.12, you can achieve the same with 0.12. variable \"vm_depends_on\" { type = any default = null } resource \"aws_instance\" \"web\" { depends_on = [ var . vm_depends_on ] # ... } If the file above becomes part of a module: module \"web\" { source = \"...\" vm_depends_on = [ module . anyobject . youchoose ] } Note After https://discuss.hashicorp.com/t/tips-howto-implement-module-depends-on-emulation/2305/2","title":"depends_on with modules"},{"location":"template/","text":"Template Used to transform template files with a selection of variables. In this case a templated IAM policy key_policy.json.tpl Templates replacements in this format- ${account_id}. { \"Version\" : \"2012-10-17\" , \"Statement\" : [ { \"Sid\" : \"Enable IAM User Permissions\" , \"Effect\" : \"Allow\" , \"Principal\" : { \"AWS\" : \"arn:aws:iam::${account_id}:root\" }, \"Action\" : \"kms:*\" , \"Resource\" : \"*\" }, { \"Sid\" : \"Allow access for Key Administrators\" , \"Effect\" : \"Allow\" , \"Principal\" : { \"AWS\" : [ \"${key_admin_arn}\" ] }, \"Action\" : [ \"kms:Create*\" , \"kms:Describe*\" , \"kms:Enable*\" , \"kms:List*\" , \"kms:Put*\" , \"kms:Update*\" , \"kms:Revoke*\" , \"kms:Disable*\" , \"kms:Get*\" , \"kms:Delete*\" , \"kms:ScheduleKeyDeletion\" , \"kms:CancelKeyDeletion\" ], \"Resource\" : \"*\" }, { \"Sid\" : \"Allow use of the key\" , \"Effect\" : \"Allow\" , \"Principal\" : { \"AWS\" : [ \"${key_admin_arn}\" ] }, \"Action\" : [ \"kms:Encrypt\" , \"kms:Decrypt\" , \"kms:ReEncrypt*\" , \"kms:GenerateDataKey*\" , \"kms:DescribeKey\" ], \"Resource\" : \"*\" }, { \"Sid\" : \"Allow attachment of persistent resources\" , \"Effect\" : \"Allow\" , \"Principal\" : { \"AWS\" : [ \"${key_admin_arn}\" ] }, \"Action\" : [ \"kms:CreateGrant\" , \"kms:ListGrants\" , \"kms:RevokeGrant\" ], \"Resource\" : \"*\" , \"Condition\" : { \"Bool\" : { \"kms:GrantIsForAWSResource\" : \"true\" } } } ] } Is transformed by: data \"template_file\" \"credstash_policy\" { template = file ( \"${path.module}/templates/key_policy.json.tpl\" ) vars { key_admin_arn = aws_iam_role . role . arn account_id = data . aws_caller_identity . current . account_id } } So that the rendered template can be used: resource \"aws_kms_key\" \"credstash\" { depends_on = [\"null_resource.waiter\"] policy = data.template_file.credstash_policy.rendered deletion_window_in_days = 7 is_enabled = true enable_key_rotation = true tags = var.common_tags }","title":"Template"},{"location":"template/#template","text":"Used to transform template files with a selection of variables. In this case a templated IAM policy key_policy.json.tpl Templates replacements in this format- ${account_id}. { \"Version\" : \"2012-10-17\" , \"Statement\" : [ { \"Sid\" : \"Enable IAM User Permissions\" , \"Effect\" : \"Allow\" , \"Principal\" : { \"AWS\" : \"arn:aws:iam::${account_id}:root\" }, \"Action\" : \"kms:*\" , \"Resource\" : \"*\" }, { \"Sid\" : \"Allow access for Key Administrators\" , \"Effect\" : \"Allow\" , \"Principal\" : { \"AWS\" : [ \"${key_admin_arn}\" ] }, \"Action\" : [ \"kms:Create*\" , \"kms:Describe*\" , \"kms:Enable*\" , \"kms:List*\" , \"kms:Put*\" , \"kms:Update*\" , \"kms:Revoke*\" , \"kms:Disable*\" , \"kms:Get*\" , \"kms:Delete*\" , \"kms:ScheduleKeyDeletion\" , \"kms:CancelKeyDeletion\" ], \"Resource\" : \"*\" }, { \"Sid\" : \"Allow use of the key\" , \"Effect\" : \"Allow\" , \"Principal\" : { \"AWS\" : [ \"${key_admin_arn}\" ] }, \"Action\" : [ \"kms:Encrypt\" , \"kms:Decrypt\" , \"kms:ReEncrypt*\" , \"kms:GenerateDataKey*\" , \"kms:DescribeKey\" ], \"Resource\" : \"*\" }, { \"Sid\" : \"Allow attachment of persistent resources\" , \"Effect\" : \"Allow\" , \"Principal\" : { \"AWS\" : [ \"${key_admin_arn}\" ] }, \"Action\" : [ \"kms:CreateGrant\" , \"kms:ListGrants\" , \"kms:RevokeGrant\" ], \"Resource\" : \"*\" , \"Condition\" : { \"Bool\" : { \"kms:GrantIsForAWSResource\" : \"true\" } } } ] } Is transformed by: data \"template_file\" \"credstash_policy\" { template = file ( \"${path.module}/templates/key_policy.json.tpl\" ) vars { key_admin_arn = aws_iam_role . role . arn account_id = data . aws_caller_identity . current . account_id } } So that the rendered template can be used: resource \"aws_kms_key\" \"credstash\" { depends_on = [\"null_resource.waiter\"] policy = data.template_file.credstash_policy.rendered deletion_window_in_days = 7 is_enabled = true enable_key_rotation = true tags = var.common_tags }","title":"Template"},{"location":"terraform/","text":"Terraform The Old fashioned way of finding results from other Terraform projects output. data \"terraform_remote_state\" \"vpc\" { backend = \"remote\" config = { bucket = \"1234567890-terraform-state\" key = \"vpc/terraform.tfstate\" region = \"us-east-1\" } } A Better and more independent way now is to use datasources - these didn't use to exist.","title":"Terraform"},{"location":"terraform/#terraform","text":"The Old fashioned way of finding results from other Terraform projects output. data \"terraform_remote_state\" \"vpc\" { backend = \"remote\" config = { bucket = \"1234567890-terraform-state\" key = \"vpc/terraform.tfstate\" region = \"us-east-1\" } } A Better and more independent way now is to use datasources - these didn't use to exist.","title":"Terraform"},{"location":"tfe/","text":"Terraform Cloud TODO Setup TODO Mananged state TODO Costing TODO Sentinel TOD","title":"Terraform cloud"},{"location":"tfe/#terraform-cloud","text":"TODO","title":"Terraform Cloud"},{"location":"tfe/#setup","text":"TODO","title":"Setup"},{"location":"tfe/#mananged-state","text":"TODO","title":"Mananged state"},{"location":"tfe/#costing","text":"TODO","title":"Costing"},{"location":"tfe/#sentinel","text":"TOD","title":"Sentinel"},{"location":"tls/","text":"Transport Layer Security - TLS The TLS provider can be used to generate SSH keys, CSR's and self signed certs for SSL. SSH keys resource \"tls_private_key\" \"ssh\" { count = length ( var . key_names ) algorithm = \"RSA\" rsa_bits = \"2048\" } Applying the full example in the ./examples/tls gives: Outputs: ssh = [ { \"algorithm\" = \"RSA\" \"ecdsa_curve\" = \"P224\" \"id\" = \"f64e9d90fea972869fed88ea8f0323bd47cb66b1\" \"private_key_pem\" = \"-----BEGIN RSA PRIVATE KEY-----xxx-----END RSA PRIVATE KEY-----\\n\" \"public_key_fingerprint_md5\" = \"f6:4b:3d:cc:0a:f6:28:d4:d1:5d:8d:87:05:2d:51:ab\" \"public_key_openssh\" = \"ssh-rsa xxx\" \"public_key_pem\" = \"-----BEGIN PUBLIC KEY-----xxx-----END PUBLIC KEY-----\\n\" \"rsa_bits\" = 2048 } , ]","title":"TLS"},{"location":"tls/#transport-layer-security-tls","text":"The TLS provider can be used to generate SSH keys, CSR's and self signed certs for SSL.","title":"Transport Layer Security - TLS"},{"location":"tls/#ssh-keys","text":"resource \"tls_private_key\" \"ssh\" { count = length ( var . key_names ) algorithm = \"RSA\" rsa_bits = \"2048\" } Applying the full example in the ./examples/tls gives: Outputs: ssh = [ { \"algorithm\" = \"RSA\" \"ecdsa_curve\" = \"P224\" \"id\" = \"f64e9d90fea972869fed88ea8f0323bd47cb66b1\" \"private_key_pem\" = \"-----BEGIN RSA PRIVATE KEY-----xxx-----END RSA PRIVATE KEY-----\\n\" \"public_key_fingerprint_md5\" = \"f6:4b:3d:cc:0a:f6:28:d4:d1:5d:8d:87:05:2d:51:ab\" \"public_key_openssh\" = \"ssh-rsa xxx\" \"public_key_pem\" = \"-----BEGIN PUBLIC KEY-----xxx-----END PUBLIC KEY-----\\n\" \"rsa_bits\" = 2048 } , ]","title":"SSH keys"},{"location":"vault/","text":"Vault Provider","title":"Vault"},{"location":"vault/#vault-provider","text":"","title":"Vault Provider"},{"location":"workspaces/","text":"Workspaces todo Handling environments versus workspaces workspaces low level objects can't be made difficult to make dynamic complex modules and templates different usage in terraform cloud","title":"Workspaces"},{"location":"workspaces/#workspaces","text":"todo Handling environments versus workspaces workspaces low level objects can't be made difficult to make dynamic complex modules and templates different usage in terraform cloud","title":"Workspaces"},{"location":"assets/images/build/readme/","text":"for jpg,png amd ico files","title":"Readme"}]}